{
	"cells": [
		{
			"cell_type": "code",
			"execution_count": 1,
			"metadata": {},
			"outputs": [],
			"source": [
				"import warnings\n",
				"from pprint import pprint\n",
				"\n",
				"import pandas as pd\n",
				"import mlflow\n",
				"import matplotlib.pyplot as plt\n",
				"from mlflow.models import infer_signature\n",
				"import seaborn as sns\n",
				"from dotenv import load_dotenv\n",
				"import os\n",
				"from datetime import datetime\n",
				"from imblearn.over_sampling import SMOTENC\n",
				"from imblearn.under_sampling import RandomUnderSampler\n",
				"from typing import List\n",
				"import boto3\n",
				"\n",
				"\n",
				"warnings.filterwarnings(\"ignore\")\n",
				"warnings.simplefilter(\"ignore\")"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# Environment Variables\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 2,
			"metadata": {},
			"outputs": [],
			"source": [
				"dotenv_path = \"../.env\"\n",
				"load_dotenv(dotenv_path)\n",
				"\n",
				"MLFLOW_TRACKING_SERVER_HOST = os.getenv(\"MLFLOW_TRACKING_SERVER_HOST\")\n",
				"MLFLOW_TRACKING_SERVER_PORT = os.getenv(\"MLFLOW_TRACKING_SERVER_PORT\")\n",
				"MLFLOW_MODEL_NAME = os.getenv(\"MLFLOW_MODEL_NAME\")\n",
				"MLFLOW_MODEL_ALIAS = os.getenv(\"MLFLOW_MODEL_ALIAS\")\n",
				"\n",
				"MINIO_HOST = os.getenv(\"MINIO_HOST\")\n",
				"MINIO_API_PORT = os.getenv(\"MINIO_API_PORT\")\n"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# Tool Setup\n"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## Minio\n",
				"\n",
				"This helps with storing MLFlow data\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 3,
			"metadata": {},
			"outputs": [],
			"source": [
				"# Set MinIO Credentials\n",
				"os.environ[\"AWS_ACCESS_KEY_ID\"] = os.getenv(\"MINIO_ACCESS_KEY\")\n",
				"os.environ[\"AWS_SECRET_ACCESS_KEY\"] = os.getenv(\"MINIO_SECRET_ACCESS_KEY\")\n",
				"os.environ[\"AWS_DEFAULT_REGION\"] = os.getenv(\"AWS_REGION\")\n",
				"\n",
				"os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = f\"http://{MINIO_HOST}:{MINIO_API_PORT}\"\n",
				"\n",
				"\n",
				"# Test if credentials are set correctly\n",
				"s3 = boto3.client(\n",
				"    \"s3\",\n",
				"    endpoint_url=os.getenv(\"MLFLOW_S3_ENDPOINT_URL\"),\n",
				")"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## MLFlow\n",
				"\n",
				"MLOps tool that helps keep track of ML models, encoders, training data and more\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 4,
			"metadata": {},
			"outputs": [
				{
					"data": {
						"text/plain": [
							"<Experiment: artifact_location='s3://mlflow/1', creation_time=1741121925903, experiment_id='1', last_update_time=1741121925903, lifecycle_stage='active', name='4th year project', tags={}>"
						]
					},
					"execution_count": 4,
					"metadata": {},
					"output_type": "execute_result"
				}
			],
			"source": [
				"mlflow.set_tracking_uri(\n",
				"    uri=f\"http://{MLFLOW_TRACKING_SERVER_HOST}:{MLFLOW_TRACKING_SERVER_PORT}\"\n",
				")\n",
				"mlflow.set_experiment(\"4th year project\")"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# Reading Data\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 5,
			"metadata": {},
			"outputs": [],
			"source": [
				"df = pd.read_csv(\"data.csv\")"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# Grouping of columns based on data type\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 6,
			"metadata": {},
			"outputs": [],
			"source": [
				"categorical_columns = [\n",
				"    \"known_allergy\",\n",
				"    # \"description_of_reaction\",\n",
				"    \"dechallenge\",\n",
				"    \"rechallenge\",\n",
				"    \"severity\",\n",
				"    \"is_serious\",\n",
				"    \"criteria_for_seriousness\",\n",
				"    \"action_taken\",\n",
				"    \"outcome\",\n",
				"]\n",
				"\n",
				"for column in categorical_columns:\n",
				"    df[column] = df[column].astype(\"category\")\n",
				"\n",
				"\n",
				"numerical_columns = [\n",
				"    \"patient_age\",\n",
				"    # \"patient_weight_kg\",\n",
				"    # \"patient_height_cm\",\n",
				"]\n",
				"\n",
				"df[\"patient_bmi\"] = df[\"patient_weight_kg\"] / (\n",
				"    df[\"patient_height_cm\"] * df[\"patient_height_cm\"]\n",
				")\n",
				"\n",
				"numerical_columns.append(\"patient_bmi\")\n",
				"\n",
				"\n",
				"date_columns = [\n",
				"    \"patient_date_of_birth\",\n",
				"    \"date_of_onset_of_reaction\",\n",
				"    \"rifampicin_start_date\",\n",
				"    \"rifampicin_stop_date\",\n",
				"    \"isoniazid_start_date\",\n",
				"    \"isoniazid_stop_date\",\n",
				"    \"pyrazinamide_start_date\",\n",
				"    \"pyrazinamide_stop_date\",\n",
				"    \"ethambutol_start_date\",\n",
				"    \"ethambutol_stop_date\",\n",
				"    \"created_at\",\n",
				"]\n",
				"\n",
				"for column in date_columns:\n",
				"    df[column] = pd.to_datetime(df[column], errors=\"coerce\")\n",
				"\n",
				"\n",
				"# Current date for age calculation\n",
				"today = pd.to_datetime(\"today\")\n",
				"\n",
				"# Calculate age only where it's missing and dob is available\n",
				"missing_age_mask = df[\"patient_age\"].isnull() & df[\"patient_date_of_birth\"].notnull()\n",
				"\n",
				"df.loc[missing_age_mask, \"patient_age\"] = (\n",
				"    today - df.loc[missing_age_mask, \"patient_date_of_birth\"]\n",
				").dt.days // 365\n",
				"\n",
				"# Now fill any remaining missing ages (where dob was also missing) with median\n",
				"df[\"patient_age\"] = df[\"patient_age\"].fillna(df[\"patient_age\"].median())\n",
				"\n",
				"# Define drug prefixes for iteration\n",
				"drug_names = [\"rifampicin\", \"isoniazid\", \"pyrazinamide\", \"ethambutol\"]\n",
				"\n",
				"# Compute date differences in days for each drug\n",
				"for drug in drug_names:\n",
				"    start_col = f\"{drug}_start_to_onset_days\"\n",
				"    stop_col = f\"{drug}_stop_to_onset_days\"\n",
				"    start_stop_col = f\"{drug}_start_stop_difference\"\n",
				"\n",
				"    df[start_col] = (df[\"date_of_onset_of_reaction\"] - df[f\"{drug}_start_date\"]).dt.days\n",
				"    df[stop_col] = (df[\"date_of_onset_of_reaction\"] - df[f\"{drug}_stop_date\"]).dt.days\n",
				"    df[start_stop_col] = (df[f\"{drug}_stop_date\"] - df[f\"{drug}_start_date\"]).dt.days\n",
				"\n",
				"    # Add these as numerical columns\n",
				"    numerical_columns.extend([start_col, stop_col, start_stop_col])\n",
				"\n",
				"# Drop date columns\n",
				"df = df.drop(columns=date_columns)\n",
				"\n",
				"boolean_columns = [\n",
				"    \"rifampicin_suspected\",\n",
				"    \"isoniazid_suspected\",\n",
				"    \"pyrazinamide_suspected\",\n",
				"    \"ethambutol_suspected\",\n",
				"]\n",
				"\n",
				"df[\"num_suspected_drugs\"] = df[boolean_columns].sum(axis=1)\n",
				"categorical_columns.append(\"num_suspected_drugs\")\n",
				"\n",
				"target_column = \"causality_assessment_level\"\n",
				"df[target_column] = df[target_column].astype(\"category\")\n"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## Dropping unnecessary columns\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 7,
			"metadata": {},
			"outputs": [],
			"source": [
				"columns_to_drop = [\n",
				"    # Patient Info\n",
				"    \"patient_name\",\n",
				"    \"inpatient_or_outpatient_number\",\n",
				"    \"patient_address\",\n",
				"    \"ward_or_clinic\",\n",
				"    \"patient_gender\",\n",
				"    \"pregnancy_status\",\n",
				"    # Rifampicin\n",
				"    \"rifampicin_frequency_number\",\n",
				"    \"rifampicin_route\",\n",
				"    \"rifampicin_batch_no\",\n",
				"    \"rifampicin_manufacturer\",\n",
				"    \"rifampicin_dose_amount\",\n",
				"    # Isoniazid\n",
				"    \"isoniazid_frequency_number\",\n",
				"    \"isoniazid_route\",\n",
				"    \"isoniazid_batch_no\",\n",
				"    \"isoniazid_manufacturer\",\n",
				"    \"isoniazid_dose_amount\",\n",
				"    # Pyrazinamide\n",
				"    \"pyrazinamide_frequency_number\",\n",
				"    \"pyrazinamide_route\",\n",
				"    \"pyrazinamide_batch_no\",\n",
				"    \"pyrazinamide_manufacturer\",\n",
				"    \"pyrazinamide_dose_amount\",\n",
				"    # Ethambutol\n",
				"    \"ethambutol_frequency_number\",\n",
				"    \"ethambutol_route\",\n",
				"    \"ethambutol_batch_no\",\n",
				"    \"ethambutol_manufacturer\",\n",
				"    \"ethambutol_dose_amount\",\n",
				"]\n",
				"\n",
				"\n",
				"df = df.drop(columns=columns_to_drop)"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## Checking for null values\n",
				"\n",
				"ℹ️ If a row does not have `patient_date_of_birth`, it has `patient_age`\n",
				"<br>\n",
				"\n",
				"ℹ️ For the drugs, a null value might mean data is missing or not. It is not an error automatically\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 8,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"<class 'pandas.core.frame.DataFrame'>\n",
						"RangeIndex: 1000 entries, 0 to 999\n",
						"Data columns (total 31 columns):\n",
						" #   Column                              Non-Null Count  Dtype   \n",
						"---  ------                              --------------  -----   \n",
						" 0   patient_age                         1000 non-null   float64 \n",
						" 1   known_allergy                       1000 non-null   category\n",
						" 2   patient_weight_kg                   1000 non-null   float64 \n",
						" 3   patient_height_cm                   1000 non-null   float64 \n",
						" 4   description_of_reaction             1000 non-null   object  \n",
						" 5   rifampicin_suspected                1000 non-null   bool    \n",
						" 6   isoniazid_suspected                 1000 non-null   bool    \n",
						" 7   pyrazinamide_suspected              1000 non-null   bool    \n",
						" 8   ethambutol_suspected                1000 non-null   bool    \n",
						" 9   dechallenge                         1000 non-null   category\n",
						" 10  rechallenge                         1000 non-null   category\n",
						" 11  severity                            1000 non-null   category\n",
						" 12  is_serious                          1000 non-null   category\n",
						" 13  criteria_for_seriousness            1000 non-null   category\n",
						" 14  action_taken                        1000 non-null   category\n",
						" 15  outcome                             1000 non-null   category\n",
						" 16  causality_assessment_level          1000 non-null   category\n",
						" 17  patient_bmi                         1000 non-null   float64 \n",
						" 18  rifampicin_start_to_onset_days      404 non-null    float64 \n",
						" 19  rifampicin_stop_to_onset_days       404 non-null    float64 \n",
						" 20  rifampicin_start_stop_difference    404 non-null    float64 \n",
						" 21  isoniazid_start_to_onset_days       427 non-null    float64 \n",
						" 22  isoniazid_stop_to_onset_days        427 non-null    float64 \n",
						" 23  isoniazid_start_stop_difference     427 non-null    float64 \n",
						" 24  pyrazinamide_start_to_onset_days    385 non-null    float64 \n",
						" 25  pyrazinamide_stop_to_onset_days     385 non-null    float64 \n",
						" 26  pyrazinamide_start_stop_difference  385 non-null    float64 \n",
						" 27  ethambutol_start_to_onset_days      413 non-null    float64 \n",
						" 28  ethambutol_stop_to_onset_days       413 non-null    float64 \n",
						" 29  ethambutol_start_stop_difference    413 non-null    float64 \n",
						" 30  num_suspected_drugs                 1000 non-null   int64   \n",
						"dtypes: bool(4), category(9), float64(16), int64(1), object(1)\n",
						"memory usage: 155.1+ KB\n"
					]
				}
			],
			"source": [
				"df.info()"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 9,
			"metadata": {},
			"outputs": [],
			"source": [
				"df[numerical_columns] = df[numerical_columns].fillna(-1)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 10,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"<class 'pandas.core.frame.DataFrame'>\n",
						"RangeIndex: 1000 entries, 0 to 999\n",
						"Data columns (total 31 columns):\n",
						" #   Column                              Non-Null Count  Dtype   \n",
						"---  ------                              --------------  -----   \n",
						" 0   patient_age                         1000 non-null   float64 \n",
						" 1   known_allergy                       1000 non-null   category\n",
						" 2   patient_weight_kg                   1000 non-null   float64 \n",
						" 3   patient_height_cm                   1000 non-null   float64 \n",
						" 4   description_of_reaction             1000 non-null   object  \n",
						" 5   rifampicin_suspected                1000 non-null   bool    \n",
						" 6   isoniazid_suspected                 1000 non-null   bool    \n",
						" 7   pyrazinamide_suspected              1000 non-null   bool    \n",
						" 8   ethambutol_suspected                1000 non-null   bool    \n",
						" 9   dechallenge                         1000 non-null   category\n",
						" 10  rechallenge                         1000 non-null   category\n",
						" 11  severity                            1000 non-null   category\n",
						" 12  is_serious                          1000 non-null   category\n",
						" 13  criteria_for_seriousness            1000 non-null   category\n",
						" 14  action_taken                        1000 non-null   category\n",
						" 15  outcome                             1000 non-null   category\n",
						" 16  causality_assessment_level          1000 non-null   category\n",
						" 17  patient_bmi                         1000 non-null   float64 \n",
						" 18  rifampicin_start_to_onset_days      1000 non-null   float64 \n",
						" 19  rifampicin_stop_to_onset_days       1000 non-null   float64 \n",
						" 20  rifampicin_start_stop_difference    1000 non-null   float64 \n",
						" 21  isoniazid_start_to_onset_days       1000 non-null   float64 \n",
						" 22  isoniazid_stop_to_onset_days        1000 non-null   float64 \n",
						" 23  isoniazid_start_stop_difference     1000 non-null   float64 \n",
						" 24  pyrazinamide_start_to_onset_days    1000 non-null   float64 \n",
						" 25  pyrazinamide_stop_to_onset_days     1000 non-null   float64 \n",
						" 26  pyrazinamide_start_stop_difference  1000 non-null   float64 \n",
						" 27  ethambutol_start_to_onset_days      1000 non-null   float64 \n",
						" 28  ethambutol_stop_to_onset_days       1000 non-null   float64 \n",
						" 29  ethambutol_start_stop_difference    1000 non-null   float64 \n",
						" 30  num_suspected_drugs                 1000 non-null   int64   \n",
						"dtypes: bool(4), category(9), float64(16), int64(1), object(1)\n",
						"memory usage: 155.1+ KB\n"
					]
				}
			],
			"source": [
				"df.info()"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 11,
			"metadata": {},
			"outputs": [
				{
					"data": {
						"text/html": [
							"<div>\n",
							"<style scoped>\n",
							"    .dataframe tbody tr th:only-of-type {\n",
							"        vertical-align: middle;\n",
							"    }\n",
							"\n",
							"    .dataframe tbody tr th {\n",
							"        vertical-align: top;\n",
							"    }\n",
							"\n",
							"    .dataframe thead th {\n",
							"        text-align: right;\n",
							"    }\n",
							"</style>\n",
							"<table border=\"1\" class=\"dataframe\">\n",
							"  <thead>\n",
							"    <tr style=\"text-align: right;\">\n",
							"      <th></th>\n",
							"      <th>patient_age</th>\n",
							"      <th>known_allergy</th>\n",
							"      <th>patient_weight_kg</th>\n",
							"      <th>patient_height_cm</th>\n",
							"      <th>description_of_reaction</th>\n",
							"      <th>rifampicin_suspected</th>\n",
							"      <th>isoniazid_suspected</th>\n",
							"      <th>pyrazinamide_suspected</th>\n",
							"      <th>ethambutol_suspected</th>\n",
							"      <th>dechallenge</th>\n",
							"      <th>...</th>\n",
							"      <th>isoniazid_start_to_onset_days</th>\n",
							"      <th>isoniazid_stop_to_onset_days</th>\n",
							"      <th>isoniazid_start_stop_difference</th>\n",
							"      <th>pyrazinamide_start_to_onset_days</th>\n",
							"      <th>pyrazinamide_stop_to_onset_days</th>\n",
							"      <th>pyrazinamide_start_stop_difference</th>\n",
							"      <th>ethambutol_start_to_onset_days</th>\n",
							"      <th>ethambutol_stop_to_onset_days</th>\n",
							"      <th>ethambutol_start_stop_difference</th>\n",
							"      <th>num_suspected_drugs</th>\n",
							"    </tr>\n",
							"  </thead>\n",
							"  <tbody>\n",
							"    <tr>\n",
							"      <th>0</th>\n",
							"      <td>29.0</td>\n",
							"      <td>no</td>\n",
							"      <td>67.2</td>\n",
							"      <td>170.6</td>\n",
							"      <td>fever</td>\n",
							"      <td>True</td>\n",
							"      <td>False</td>\n",
							"      <td>False</td>\n",
							"      <td>False</td>\n",
							"      <td>yes</td>\n",
							"      <td>...</td>\n",
							"      <td>-1.0</td>\n",
							"      <td>-1.0</td>\n",
							"      <td>-1.0</td>\n",
							"      <td>-1.0</td>\n",
							"      <td>-1.0</td>\n",
							"      <td>-1.0</td>\n",
							"      <td>-1.0</td>\n",
							"      <td>-1.0</td>\n",
							"      <td>-1.0</td>\n",
							"      <td>1</td>\n",
							"    </tr>\n",
							"    <tr>\n",
							"      <th>1</th>\n",
							"      <td>28.0</td>\n",
							"      <td>no</td>\n",
							"      <td>63.0</td>\n",
							"      <td>170.0</td>\n",
							"      <td>headache, numbness</td>\n",
							"      <td>True</td>\n",
							"      <td>True</td>\n",
							"      <td>False</td>\n",
							"      <td>False</td>\n",
							"      <td>yes</td>\n",
							"      <td>...</td>\n",
							"      <td>71.0</td>\n",
							"      <td>10.0</td>\n",
							"      <td>61.0</td>\n",
							"      <td>-1.0</td>\n",
							"      <td>-1.0</td>\n",
							"      <td>-1.0</td>\n",
							"      <td>-1.0</td>\n",
							"      <td>-1.0</td>\n",
							"      <td>-1.0</td>\n",
							"      <td>2</td>\n",
							"    </tr>\n",
							"    <tr>\n",
							"      <th>2</th>\n",
							"      <td>41.0</td>\n",
							"      <td>no</td>\n",
							"      <td>71.0</td>\n",
							"      <td>168.2</td>\n",
							"      <td>color blindness, eye pain</td>\n",
							"      <td>False</td>\n",
							"      <td>False</td>\n",
							"      <td>False</td>\n",
							"      <td>True</td>\n",
							"      <td>no</td>\n",
							"      <td>...</td>\n",
							"      <td>-1.0</td>\n",
							"      <td>-1.0</td>\n",
							"      <td>-1.0</td>\n",
							"      <td>-1.0</td>\n",
							"      <td>-1.0</td>\n",
							"      <td>-1.0</td>\n",
							"      <td>14.0</td>\n",
							"      <td>-5.0</td>\n",
							"      <td>19.0</td>\n",
							"      <td>1</td>\n",
							"    </tr>\n",
							"    <tr>\n",
							"      <th>3</th>\n",
							"      <td>9.0</td>\n",
							"      <td>no</td>\n",
							"      <td>27.8</td>\n",
							"      <td>125.8</td>\n",
							"      <td>joint pain, nausea, loss of appetite</td>\n",
							"      <td>False</td>\n",
							"      <td>False</td>\n",
							"      <td>True</td>\n",
							"      <td>False</td>\n",
							"      <td>no</td>\n",
							"      <td>...</td>\n",
							"      <td>-1.0</td>\n",
							"      <td>-1.0</td>\n",
							"      <td>-1.0</td>\n",
							"      <td>89.0</td>\n",
							"      <td>16.0</td>\n",
							"      <td>73.0</td>\n",
							"      <td>-1.0</td>\n",
							"      <td>-1.0</td>\n",
							"      <td>-1.0</td>\n",
							"      <td>1</td>\n",
							"    </tr>\n",
							"    <tr>\n",
							"      <th>4</th>\n",
							"      <td>4.0</td>\n",
							"      <td>yes</td>\n",
							"      <td>17.3</td>\n",
							"      <td>90.1</td>\n",
							"      <td>optic neuritis, blurred vision, color blindness</td>\n",
							"      <td>False</td>\n",
							"      <td>True</td>\n",
							"      <td>True</td>\n",
							"      <td>True</td>\n",
							"      <td>no</td>\n",
							"      <td>...</td>\n",
							"      <td>3.0</td>\n",
							"      <td>1.0</td>\n",
							"      <td>2.0</td>\n",
							"      <td>10.0</td>\n",
							"      <td>-8.0</td>\n",
							"      <td>18.0</td>\n",
							"      <td>10.0</td>\n",
							"      <td>-3.0</td>\n",
							"      <td>13.0</td>\n",
							"      <td>3</td>\n",
							"    </tr>\n",
							"  </tbody>\n",
							"</table>\n",
							"<p>5 rows × 31 columns</p>\n",
							"</div>"
						],
						"text/plain": [
							"   patient_age known_allergy  patient_weight_kg  patient_height_cm  \\\n",
							"0         29.0            no               67.2              170.6   \n",
							"1         28.0            no               63.0              170.0   \n",
							"2         41.0            no               71.0              168.2   \n",
							"3          9.0            no               27.8              125.8   \n",
							"4          4.0           yes               17.3               90.1   \n",
							"\n",
							"                           description_of_reaction  rifampicin_suspected  \\\n",
							"0                                            fever                  True   \n",
							"1                               headache, numbness                  True   \n",
							"2                        color blindness, eye pain                 False   \n",
							"3             joint pain, nausea, loss of appetite                 False   \n",
							"4  optic neuritis, blurred vision, color blindness                 False   \n",
							"\n",
							"   isoniazid_suspected  pyrazinamide_suspected  ethambutol_suspected  \\\n",
							"0                False                   False                 False   \n",
							"1                 True                   False                 False   \n",
							"2                False                   False                  True   \n",
							"3                False                    True                 False   \n",
							"4                 True                    True                  True   \n",
							"\n",
							"  dechallenge  ... isoniazid_start_to_onset_days isoniazid_stop_to_onset_days  \\\n",
							"0         yes  ...                          -1.0                         -1.0   \n",
							"1         yes  ...                          71.0                         10.0   \n",
							"2          no  ...                          -1.0                         -1.0   \n",
							"3          no  ...                          -1.0                         -1.0   \n",
							"4          no  ...                           3.0                          1.0   \n",
							"\n",
							"  isoniazid_start_stop_difference pyrazinamide_start_to_onset_days  \\\n",
							"0                            -1.0                             -1.0   \n",
							"1                            61.0                             -1.0   \n",
							"2                            -1.0                             -1.0   \n",
							"3                            -1.0                             89.0   \n",
							"4                             2.0                             10.0   \n",
							"\n",
							"  pyrazinamide_stop_to_onset_days pyrazinamide_start_stop_difference  \\\n",
							"0                            -1.0                               -1.0   \n",
							"1                            -1.0                               -1.0   \n",
							"2                            -1.0                               -1.0   \n",
							"3                            16.0                               73.0   \n",
							"4                            -8.0                               18.0   \n",
							"\n",
							"  ethambutol_start_to_onset_days  ethambutol_stop_to_onset_days  \\\n",
							"0                           -1.0                           -1.0   \n",
							"1                           -1.0                           -1.0   \n",
							"2                           14.0                           -5.0   \n",
							"3                           -1.0                           -1.0   \n",
							"4                           10.0                           -3.0   \n",
							"\n",
							"   ethambutol_start_stop_difference  num_suspected_drugs  \n",
							"0                              -1.0                    1  \n",
							"1                              -1.0                    2  \n",
							"2                              19.0                    1  \n",
							"3                              -1.0                    1  \n",
							"4                              13.0                    3  \n",
							"\n",
							"[5 rows x 31 columns]"
						]
					},
					"execution_count": 11,
					"metadata": {},
					"output_type": "execute_result"
				}
			],
			"source": [
				"df.head()"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# Train/Val/Test Split\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 12,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"train_df.shape=(600, 28)\n",
						"test_df.shape=(250, 28)\n",
						"val_df.shape=(150, 28)\n"
					]
				}
			],
			"source": [
				"from sklearn.model_selection import train_test_split\n",
				"\n",
				"X_full = df[[*categorical_columns, *boolean_columns, *numerical_columns]]\n",
				"y_full = df[target_column]\n",
				"\n",
				"X_train_and_val, X_test, y_train_and_val, y_test = train_test_split(\n",
				"    X_full, y_full, stratify=y_full, test_size=0.25\n",
				")\n",
				"\n",
				"\n",
				"X_train, X_val, y_train, y_val = train_test_split(\n",
				"    X_train_and_val,\n",
				"    y_train_and_val,\n",
				"    stratify=y_train_and_val,\n",
				"    test_size=0.2,\n",
				"    random_state=42,\n",
				")\n",
				"\n",
				"# Create the final train and validation DataFrames\n",
				"train_df = pd.concat([X_train, y_train], axis=1)\n",
				"\n",
				"val_df = pd.concat([X_val, y_val], axis=1)\n",
				"\n",
				"test_df = pd.concat([X_test, y_test], axis=1)\n",
				"\n",
				"del X_full\n",
				"del y_full\n",
				"del X_train\n",
				"del X_test\n",
				"del y_train\n",
				"del y_test\n",
				"\n",
				"print(f\"{train_df.shape=}\")\n",
				"print(f\"{test_df.shape=}\")\n",
				"print(f\"{val_df.shape=}\")\n"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# Target Class Distribution\n",
				"\n",
				"❗ Class imbalance exists. SMOTENC will be used\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 13,
			"metadata": {},
			"outputs": [
				{
					"data": {
						"text/plain": [
							"causality_assessment_level\n",
							"likely      0.444\n",
							"possible    0.290\n",
							"unlikely    0.214\n",
							"certain     0.052\n",
							"Name: proportion, dtype: float64"
						]
					},
					"execution_count": 13,
					"metadata": {},
					"output_type": "execute_result"
				}
			],
			"source": [
				"df[target_column].value_counts(normalize=True)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 14,
			"metadata": {},
			"outputs": [
				{
					"data": {
						"text/plain": [
							"causality_assessment_level\n",
							"certain     266\n",
							"likely      266\n",
							"possible    266\n",
							"unlikely    266\n",
							"Name: count, dtype: int64"
						]
					},
					"execution_count": 14,
					"metadata": {},
					"output_type": "execute_result"
				}
			],
			"source": [
				"X = train_df[[*categorical_columns, *boolean_columns, *numerical_columns]]\n",
				"y = train_df[target_column]\n",
				"\n",
				"smote_nc = SMOTENC(categorical_features=categorical_columns, random_state=42)\n",
				"\n",
				"X_smote, y_smote = smote_nc.fit_resample(X, y)\n",
				"\n",
				"\n",
				"# # Have now a dataframe with even data\n",
				"# under = RandomUnderSampler(random_state=42, sampling_strategy=0.5)\n",
				"# X_balanced, y_balanced = under.fit_resample(X_smote, y_smote)\n",
				"\n",
				"train_df = pd.concat([X_smote, y_smote], axis=1)\n",
				"\n",
				"train_df[target_column].value_counts()"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# Scale numerical columns\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 15,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"train_df.shape=(1064, 28)\n",
						"test_df.shape=(250, 28)\n",
						"val_df.shape=(150, 28)\n"
					]
				}
			],
			"source": [
				"from sklearn.preprocessing import MinMaxScaler\n",
				"\n",
				"\n",
				"scaler = MinMaxScaler()\n",
				"\n",
				"train_df[numerical_columns] = scaler.fit_transform(train_df[numerical_columns])\n",
				"val_df[numerical_columns] = scaler.transform(val_df[numerical_columns])\n",
				"test_df[numerical_columns] = scaler.transform(test_df[numerical_columns])\n",
				"\n",
				"print(f\"{train_df.shape=}\")\n",
				"print(f\"{test_df.shape=}\")\n",
				"print(f\"{val_df.shape=}\")\n"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# EDA\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 16,
			"metadata": {},
			"outputs": [],
			"source": [
				"df_for_eda = train_df"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 17,
			"metadata": {},
			"outputs": [],
			"source": [
				"def categorical_eda(df: pd.DataFrame, columns: List[str], target_column=str):\n",
				"    for column in columns:\n",
				"        df__categorical_count = df.groupby(column).size().reset_index(name=\"count\")\n",
				"\n",
				"        df__categorical_count_per_target = pd.crosstab(\n",
				"            df[column], df[target_column], normalize=\"index\"\n",
				"        )\n",
				"\n",
				"        display(df__categorical_count_per_target)\n",
				"        # df__categorical_count_per_target = df__categorical_count_per_target.loc[df__categorical_count[column]]\n",
				"\n",
				"        fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
				"\n",
				"        sns.barplot(\n",
				"            data=df__categorical_count, y=column, x=\"count\", ax=axes[0], orient=\"h\"\n",
				"        )\n",
				"        axes[0].set_title(f\"Count of {column}\")\n",
				"        axes[0].set_xlabel(\"Count\")\n",
				"        axes[0].set_ylabel(column)\n",
				"\n",
				"        df__categorical_count_per_target.plot(kind=\"barh\", stacked=True, ax=axes[1])\n",
				"\n",
				"        axes[1].set_title(f\"Proportion of {column} by {target_column}\")\n",
				"        axes[1].set_xlabel(\"Count\")\n",
				"        axes[1].set_ylabel(column)\n",
				"        # To maintain ordering\n",
				"        axes[1].invert_yaxis()\n",
				"\n",
				"        plt.tight_layout()\n",
				"\n",
				"        # Show the plots\n",
				"        plt.show()\n",
				"\n",
				"\n",
				"def numerical_eda(df: pd.DataFrame, columns: List[str], target_column: str):\n",
				"    for column in columns:\n",
				"        fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
				"\n",
				"        q1 = df[column].quantile(0.01)\n",
				"        q3 = df[column].quantile(0.99)\n",
				"\n",
				"        filtered_df = df[(df[column] >= q1) & (df[column] <= q3)]\n",
				"\n",
				"        sns.kdeplot(data=filtered_df, x=column, ax=axes[0], fill=True)\n",
				"\n",
				"        axes[0].set_title(f\"Distribution of {column}\")\n",
				"\n",
				"        sns.kdeplot(\n",
				"            data=filtered_df,\n",
				"            x=column,\n",
				"            hue=target_column,\n",
				"            ax=axes[1],\n",
				"            common_norm=False,\n",
				"            fill=True,\n",
				"        )\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 18,
			"metadata": {},
			"outputs": [],
			"source": [
				"# categorical_eda(\n",
				"#     df=df_for_eda,\n",
				"#     columns=[*categorical_columns, *boolean_columns],\n",
				"#     target_column=target_column,\n",
				"# )"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 19,
			"metadata": {},
			"outputs": [],
			"source": [
				"# numerical_eda(df=train_df, columns=numerical_columns, target_column=target_column)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 20,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Target classes: ['certain' 'likely' 'possible' 'unlikely']\n",
						"X_train_final.shape=(1064, 55)\n",
						"X_val_final.shape=(150, 55)\n",
						"X_test_final.shape=(250, 55)\n",
						"y_train_encoded.shape=(1064,)\n",
						"y_val_encoded.shape=(150,)\n",
						"y_test_encoded.shape=(250,)\n"
					]
				}
			],
			"source": [
				"import joblib\n",
				"\n",
				"from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
				"\n",
				"\n",
				"# one_hot_encoder = OneHotEncoder(sparse_output=False)\n",
				"\n",
				"# # train_df_cat_encoded = pd.get_dummies(train_df[categorical_columns])\n",
				"# train_df_cat_encoded = one_hot_encoder.fit_transform(train_df[categorical_columns])\n",
				"\n",
				"\n",
				"# train_df_cat_encoded = pd.DataFrame(\n",
				"#     train_df_cat_encoded,\n",
				"#     columns=one_hot_encoder.get_feature_names_out(categorical_columns),\n",
				"# )\n",
				"\n",
				"\n",
				"# test_df_cat_encoded = one_hot_encoder.transform(test_df[categorical_columns])\n",
				"# test_df_cat_encoded = pd.DataFrame(\n",
				"#     test_df_cat_encoded,\n",
				"#     columns=one_hot_encoder.get_feature_names_out(categorical_columns),\n",
				"# )\n",
				"\n",
				"\n",
				"# ordinal_encoder = OrdinalEncoder(\n",
				"#     categories=[\n",
				"#         [\"certain\", \"likely\", \"possible\", \"unlikely\", \"unclassified\", \"unclassifiable\"]\n",
				"#     ]\n",
				"# )\n",
				"\n",
				"# train_target_column_encoded = pd.DataFrame()\n",
				"\n",
				"# train_target_column_encoded[target_column] = ordinal_encoder.fit_transform(\n",
				"#     train_df[[target_column]]\n",
				"# ).ravel()\n",
				"\n",
				"# test_target_column_encoded = pd.DataFrame()\n",
				"\n",
				"\n",
				"# test_target_column_encoded[target_column] = ordinal_encoder.transform(\n",
				"#     test_df[[target_column]]\n",
				"# ).ravel()\n",
				"\n",
				"# Step 1: Split features and target from train, val, and test\n",
				"X_train = train_df[[*categorical_columns, *numerical_columns, *boolean_columns]]\n",
				"y_train = train_df[[target_column]]\n",
				"\n",
				"X_val = val_df[[*categorical_columns, *numerical_columns, *boolean_columns]]\n",
				"y_val = val_df[[target_column]]\n",
				"\n",
				"X_test = test_df[[*categorical_columns, *numerical_columns, *boolean_columns]]\n",
				"y_test = test_df[[target_column]]\n",
				"\n",
				"# Step 2: Define Encoders\n",
				"one_hot_encoder = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
				"# ordinal_encoder = OrdinalEncoder(\n",
				"#     categories=[\n",
				"#         [\"certain\", \"likely\", \"possible\", \"unlikely\", \"unclassified\", \"unclassifiable\"]\n",
				"#     ]\n",
				"# )\n",
				"\n",
				"ordinal_encoder = OrdinalEncoder(\n",
				"    categories=[[\"certain\", \"likely\", \"possible\", \"unlikely\"]]\n",
				")\n",
				"\n",
				"# Step 3: Fit OneHotEncoder on train set and transform train, val, test\n",
				"X_train_cat_encoded = one_hot_encoder.fit_transform(X_train[categorical_columns])\n",
				"X_val_cat_encoded = one_hot_encoder.transform(X_val[categorical_columns])\n",
				"X_test_cat_encoded = one_hot_encoder.transform(X_test[categorical_columns])\n",
				"\n",
				"# Step 4: Convert one-hot arrays to DataFrames\n",
				"cat_feature_names = one_hot_encoder.get_feature_names_out(categorical_columns)\n",
				"X_train_cat_df = pd.DataFrame(\n",
				"    X_train_cat_encoded, columns=cat_feature_names, index=X_train.index\n",
				").reset_index(drop=True)\n",
				"X_val_cat_df = pd.DataFrame(\n",
				"    X_val_cat_encoded, columns=cat_feature_names, index=X_val.index\n",
				").reset_index(drop=True)\n",
				"X_test_cat_df = pd.DataFrame(\n",
				"    X_test_cat_encoded, columns=cat_feature_names, index=X_test.index\n",
				").reset_index(drop=True)\n",
				"\n",
				"# Step 5: Concatenate all features\n",
				"X_train_final = pd.concat(\n",
				"    [\n",
				"        X_train_cat_df,\n",
				"        X_train[numerical_columns + boolean_columns].reset_index(drop=True),\n",
				"    ],\n",
				"    axis=1,\n",
				")\n",
				"X_val_final = pd.concat(\n",
				"    [X_val_cat_df, X_val[numerical_columns + boolean_columns].reset_index(drop=True)],\n",
				"    axis=1,\n",
				")\n",
				"X_test_final = pd.concat(\n",
				"    [X_test_cat_df, X_test[numerical_columns + boolean_columns].reset_index(drop=True)],\n",
				"    axis=1,\n",
				")\n",
				"\n",
				"# Step 6: Fit OrdinalEncoder on target (for classification)\n",
				"y_train_encoded = ordinal_encoder.fit_transform(y_train).ravel()\n",
				"y_val_encoded = ordinal_encoder.transform(y_val).ravel()\n",
				"y_test_encoded = ordinal_encoder.transform(y_test).ravel()\n",
				"\n",
				"# Optional: To see what the classes are\n",
				"label_classes = ordinal_encoder.categories_[0]\n",
				"print(\"Target classes:\", label_classes)\n",
				"\n",
				"print(f\"{X_train_final.shape=}\")\n",
				"print(f\"{X_val_final.shape=}\")\n",
				"print(f\"{X_test_final.shape=}\")\n",
				"\n",
				"\n",
				"print(f\"{y_train_encoded.shape=}\")\n",
				"print(f\"{y_val_encoded.shape=}\")\n",
				"print(f\"{y_test_encoded.shape=}\")\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 21,
			"metadata": {},
			"outputs": [
				{
					"data": {
						"text/plain": [
							"['known_allergy_no',\n",
							" 'known_allergy_yes',\n",
							" 'dechallenge_na',\n",
							" 'dechallenge_no',\n",
							" 'dechallenge_unknown',\n",
							" 'dechallenge_yes',\n",
							" 'rechallenge_na',\n",
							" 'rechallenge_no',\n",
							" 'rechallenge_unknown',\n",
							" 'rechallenge_yes',\n",
							" 'severity_fatal',\n",
							" 'severity_mild',\n",
							" 'severity_moderate',\n",
							" 'severity_severe',\n",
							" 'severity_unknown',\n",
							" 'is_serious_no',\n",
							" 'is_serious_yes',\n",
							" 'criteria_for_seriousness_congenital anomaly',\n",
							" 'criteria_for_seriousness_death',\n",
							" 'criteria_for_seriousness_disability',\n",
							" 'criteria_for_seriousness_hospitalisation',\n",
							" 'criteria_for_seriousness_life-threatening',\n",
							" 'action_taken_dose increased',\n",
							" 'action_taken_dose not changed',\n",
							" 'action_taken_dose reduced',\n",
							" 'action_taken_drug withdrawn',\n",
							" 'action_taken_not applicable',\n",
							" 'action_taken_unknown',\n",
							" 'outcome_death',\n",
							" 'outcome_not recovered',\n",
							" 'outcome_recovered',\n",
							" 'outcome_recovered with sequelae',\n",
							" 'outcome_recovering',\n",
							" 'outcome_unknown',\n",
							" 'num_suspected_drugs_1',\n",
							" 'num_suspected_drugs_2',\n",
							" 'num_suspected_drugs_3',\n",
							" 'patient_age',\n",
							" 'patient_bmi',\n",
							" 'rifampicin_start_to_onset_days',\n",
							" 'rifampicin_stop_to_onset_days',\n",
							" 'rifampicin_start_stop_difference',\n",
							" 'isoniazid_start_to_onset_days',\n",
							" 'isoniazid_stop_to_onset_days',\n",
							" 'isoniazid_start_stop_difference',\n",
							" 'pyrazinamide_start_to_onset_days',\n",
							" 'pyrazinamide_stop_to_onset_days',\n",
							" 'pyrazinamide_start_stop_difference',\n",
							" 'ethambutol_start_to_onset_days',\n",
							" 'ethambutol_stop_to_onset_days',\n",
							" 'ethambutol_start_stop_difference',\n",
							" 'rifampicin_suspected',\n",
							" 'isoniazid_suspected',\n",
							" 'pyrazinamide_suspected',\n",
							" 'ethambutol_suspected']"
						]
					},
					"execution_count": 21,
					"metadata": {},
					"output_type": "execute_result"
				}
			],
			"source": [
				"X_train_final.columns.to_list()"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# Feature\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 48,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Fitting estimator with 55 features.Fitting estimator with 55 features.\n",
						"\n",
						"Fitting estimator with 54 features.\n",
						"Fitting estimator with 54 features.\n",
						"Fitting estimator with 53 features.\n",
						"Fitting estimator with 52 features.\n",
						"Fitting estimator with 51 features.\n",
						"Fitting estimator with 53 features.\n",
						"Fitting estimator with 55 features.\n",
						"Fitting estimator with 50 features.\n",
						"Fitting estimator with 54 features.\n",
						"Fitting estimator with 55 features.\n",
						"Fitting estimator with 49 features.\n",
						"Fitting estimator with 55 features.\n",
						"Fitting estimator with 52 features.\n",
						"Fitting estimator with 54 features.\n",
						"Fitting estimator with 48 features.\n",
						"Fitting estimator with 54 features.\n",
						"Fitting estimator with 53 features.\n",
						"Fitting estimator with 53 features.\n",
						"Fitting estimator with 51 features.\n",
						"Fitting estimator with 47 features.\n",
						"Fitting estimator with 52 features.\n",
						"Fitting estimator with 46 features.\n",
						"Fitting estimator with 53 features.\n",
						"Fitting estimator with 52 features.\n",
						"Fitting estimator with 51 features.\n",
						"Fitting estimator with 50 features.\n",
						"Fitting estimator with 45 features.\n",
						"Fitting estimator with 51 features.\n",
						"Fitting estimator with 50 features.\n",
						"Fitting estimator with 52 features.\n",
						"Fitting estimator with 44 features.\n",
						"Fitting estimator with 50 features.\n",
						"Fitting estimator with 49 features.Fitting estimator with 49 features.\n",
						"\n",
						"Fitting estimator with 43 features.\n",
						"Fitting estimator with 48 features.\n",
						"Fitting estimator with 55 features.\n",
						"Fitting estimator with 42 features.\n",
						"Fitting estimator with 51 features.\n",
						"Fitting estimator with 49 features.\n",
						"Fitting estimator with 48 features.\n",
						"Fitting estimator with 41 features.\n",
						"Fitting estimator with 54 features.\n",
						"Fitting estimator with 47 features.\n",
						"Fitting estimator with 50 features.\n",
						"Fitting estimator with 40 features.\n",
						"Fitting estimator with 46 features.\n",
						"Fitting estimator with 53 features.\n",
						"Fitting estimator with 49 features.\n",
						"Fitting estimator with 39 features.\n",
						"Fitting estimator with 48 features.\n",
						"Fitting estimator with 47 features.\n",
						"Fitting estimator with 55 features.\n",
						"Fitting estimator with 52 features.Fitting estimator with 48 features.\n",
						"\n",
						"Fitting estimator with 38 features.\n",
						"Fitting estimator with 45 features.\n",
						"Fitting estimator with 47 features.Fitting estimator with 55 features.\n",
						"\n",
						"Fitting estimator with 37 features.\n",
						"Fitting estimator with 46 features.\n",
						"Fitting estimator with 47 features.\n",
						"Fitting estimator with 54 features.\n",
						"Fitting estimator with 44 features.\n",
						"Fitting estimator with 36 features.\n",
						"Fitting estimator with 51 features.Fitting estimator with 54 features.\n",
						"\n",
						"Fitting estimator with 46 features.\n",
						"Fitting estimator with 43 features.\n",
						"Fitting estimator with 53 features.\n",
						"Fitting estimator with 35 features.\n",
						"Fitting estimator with 53 features.\n",
						"Fitting estimator with 46 features.Fitting estimator with 45 features.\n",
						"Fitting estimator with 45 features.\n",
						"\n",
						"Fitting estimator with 34 features.\n",
						"Fitting estimator with 42 features.\n",
						"Fitting estimator with 52 features.\n",
						"Fitting estimator with 50 features.Fitting estimator with 52 features.\n",
						"Fitting estimator with 44 features.\n",
						"\n",
						"Fitting estimator with 33 features.\n",
						"Fitting estimator with 41 features.\n",
						"Fitting estimator with 51 features.Fitting estimator with 51 features.\n",
						"\n",
						"Fitting estimator with 44 features.\n",
						"Fitting estimator with 45 features.Fitting estimator with 32 features.\n",
						"Fitting estimator with 43 features.\n",
						"\n",
						"Fitting estimator with 40 features.\n",
						"Fitting estimator with 31 features.\n",
						"Fitting estimator with 50 features.\n",
						"Fitting estimator with 49 features.Fitting estimator with 50 features.\n",
						"Fitting estimator with 42 features.\n",
						"\n",
						"Fitting estimator with 39 features.\n",
						"Fitting estimator with 30 features.\n",
						"Fitting estimator with 49 features.\n",
						"Fitting estimator with 43 features.\n",
						"Fitting estimator with 44 features.\n",
						"Fitting estimator with 41 features.\n",
						"Fitting estimator with 38 features.\n",
						"Fitting estimator with 29 features.\n",
						"Fitting estimator with 49 features.\n",
						"Fitting estimator with 48 features.\n",
						"Fitting estimator with 48 features.\n",
						"Fitting estimator with 28 features.\n",
						"Fitting estimator with 37 features.\n",
						"Fitting estimator with 48 features.\n",
						"Fitting estimator with 42 features.\n",
						"Fitting estimator with 47 features.\n",
						"Fitting estimator with 40 features.\n",
						"Fitting estimator with 43 features.\n",
						"Fitting estimator with 27 features.\n",
						"Fitting estimator with 36 features.\n",
						"Fitting estimator with 46 features.\n",
						"Fitting estimator with 47 features.\n",
						"Fitting estimator with 47 features.\n",
						"Fitting estimator with 26 features.Fitting estimator with 35 features.\n",
						"\n",
						"Fitting estimator with 45 features.\n",
						"Fitting estimator with 39 features.\n",
						"Fitting estimator with 46 features.\n",
						"Fitting estimator with 42 features.\n",
						"Fitting estimator with 41 features.\n",
						"Fitting estimator with 25 features.\n",
						"Fitting estimator with 34 features.\n",
						"Fitting estimator with 46 features.\n",
						"Fitting estimator with 38 features.\n",
						"Fitting estimator with 45 features.\n",
						"Fitting estimator with 24 features.\n",
						"Fitting estimator with 44 features.\n",
						"Fitting estimator with 40 features.\n",
						"Fitting estimator with 33 features.\n",
						"Fitting estimator with 45 features.\n",
						"Fitting estimator with 23 features.\n",
						"Fitting estimator with 41 features.\n",
						"Fitting estimator with 37 features.\n",
						"Fitting estimator with 44 features.\n",
						"Fitting estimator with 44 features.\n",
						"Fitting estimator with 22 features.\n",
						"Fitting estimator with 32 features.\n",
						"Fitting estimator with 40 features.\n",
						"Fitting estimator with 39 features.\n",
						"Fitting estimator with 36 features.\n",
						"Fitting estimator with 43 features.\n",
						"Fitting estimator with 31 features.\n",
						"Fitting estimator with 39 features.\n",
						"Fitting estimator with 43 features.\n",
						"Fitting estimator with 21 features.\n",
						"Fitting estimator with 43 features.\n",
						"Fitting estimator with 38 features.\n",
						"Fitting estimator with 42 features.\n",
						"Fitting estimator with 30 features.\n",
						"Fitting estimator with 38 features.\n",
						"Fitting estimator with 42 features.\n",
						"Fitting estimator with 41 features.\n",
						"Fitting estimator with 37 features.Fitting estimator with 35 features.\n",
						"\n",
						"Fitting estimator with 37 features.\n",
						"Fitting estimator with 42 features.\n",
						"Fitting estimator with 20 features.\n",
						"Fitting estimator with 40 features.\n",
						"Fitting estimator with 36 features.\n",
						"Fitting estimator with 29 features.\n",
						"Fitting estimator with 36 features.\n",
						"Fitting estimator with 39 features.\n",
						"Fitting estimator with 41 features.\n",
						"Fitting estimator with 41 features.\n",
						"Fitting estimator with 34 features.\n",
						"Fitting estimator with 35 features.\n",
						"Fitting estimator with 19 features.\n",
						"Fitting estimator with 35 features.\n",
						"Fitting estimator with 38 features.\n",
						"Fitting estimator with 34 features.\n",
						"Fitting estimator with 28 features.\n",
						"Fitting estimator with 37 features.Fitting estimator with 34 features.\n",
						"\n",
						"Fitting estimator with 40 features.\n",
						"Fitting estimator with 33 features.\n",
						"Fitting estimator with 33 features.\n",
						"Fitting estimator with 18 features.Fitting estimator with 36 features.\n",
						"\n",
						"Fitting estimator with 40 features.\n",
						"Fitting estimator with 32 features.\n",
						"Fitting estimator with 27 features.\n",
						"Fitting estimator with 35 features.\n",
						"Fitting estimator with 31 features.Fitting estimator with 39 features.\n",
						"\n",
						"Fitting estimator with 32 features.\n",
						"Fitting estimator with 33 features.\n",
						"Fitting estimator with 34 features.\n",
						"Fitting estimator with 30 features.\n",
						"Fitting estimator with 17 features.\n",
						"Fitting estimator with 38 features.\n",
						"Fitting estimator with 33 features.\n",
						"Fitting estimator with 29 features.\n",
						"Fitting estimator with 31 features.\n",
						"Fitting estimator with 32 features.Fitting estimator with 39 features.\n",
						"\n",
						"Fitting estimator with 32 features.\n",
						"Fitting estimator with 28 features.\n",
						"Fitting estimator with 26 features.\n",
						"Fitting estimator with 16 features.\n",
						"Fitting estimator with 31 features.\n",
						"Fitting estimator with 37 features.\n",
						"Fitting estimator with 30 features.\n",
						"Fitting estimator with 31 features.\n",
						"Fitting estimator with 30 features.\n",
						"Fitting estimator with 27 features.\n",
						"Fitting estimator with 15 features.\n",
						"Fitting estimator with 38 features.\n",
						"Fitting estimator with 25 features.\n",
						"Fitting estimator with 29 features.Fitting estimator with 30 features.\n",
						"\n",
						"Fitting estimator with 36 features.Fitting estimator with 29 features.\n",
						"\n",
						"Fitting estimator with 14 features.\n",
						"Fitting estimator with 24 features.\n",
						"Fitting estimator with 26 features.\n",
						"Fitting estimator with 37 features.\n",
						"Fitting estimator with 29 features.\n",
						"Fitting estimator with 28 features.\n",
						"Fitting estimator with 28 features.\n",
						"Fitting estimator with 35 features.\n",
						"Fitting estimator with 23 features.\n",
						"Fitting estimator with 13 features.\n",
						"Fitting estimator with 25 features.\n",
						"Fitting estimator with 28 features.\n",
						"Fitting estimator with 27 features.\n",
						"Fitting estimator with 12 features.\n",
						"Fitting estimator with 22 features.\n",
						"Fitting estimator with 24 features.\n",
						"Fitting estimator with 27 features.\n",
						"Fitting estimator with 34 features.\n",
						"Fitting estimator with 36 features.\n",
						"Fitting estimator with 11 features.\n",
						"Fitting estimator with 23 features.\n",
						"Fitting estimator with 21 features.\n",
						"Fitting estimator with 26 features.\n",
						"Fitting estimator with 10 features.Fitting estimator with 27 features.\n",
						"\n",
						"Fitting estimator with 26 features.\n",
						"Fitting estimator with 22 features.\n",
						"Fitting estimator with 35 features.\n",
						"Fitting estimator with 25 features.\n",
						"Fitting estimator with 9 features.\n",
						"Fitting estimator with 21 features.\n",
						"Fitting estimator with 33 features.\n",
						"Fitting estimator with 25 features.\n",
						"Fitting estimator with 24 features.\n",
						"Fitting estimator with 20 features.\n",
						"Fitting estimator with 20 features.\n",
						"Fitting estimator with 26 features.\n",
						"Fitting estimator with 8 features.\n",
						"Fitting estimator with 34 features.\n",
						"Fitting estimator with 24 features.\n",
						"Fitting estimator with 19 features.\n",
						"Fitting estimator with 23 features.Fitting estimator with 32 features.Fitting estimator with 7 features.\n",
						"\n",
						"\n",
						"Fitting estimator with 19 features.\n",
						"Fitting estimator with 33 features.\n",
						"Fitting estimator with 25 features.\n",
						"Fitting estimator with 6 features.Fitting estimator with 23 features.\n",
						"\n",
						"Fitting estimator with 18 features.\n",
						"Fitting estimator with 22 features.Fitting estimator with 31 features.\n",
						"\n",
						"Fitting estimator with 5 features.\n",
						"Fitting estimator with 22 features.\n",
						"Fitting estimator with 18 features.\n",
						"Fitting estimator with 17 features.\n",
						"Fitting estimator with 32 features.\n",
						"Fitting estimator with 4 features.\n",
						"Fitting estimator with 24 features.\n",
						"Fitting estimator with 30 features.\n",
						"Fitting estimator with 21 features.\n",
						"Fitting estimator with 21 features.\n",
						"Fitting estimator with 3 features.\n",
						"Fitting estimator with 16 features.Fitting estimator with 31 features.\n",
						"\n",
						"Fitting estimator with 23 features.\n",
						"Fitting estimator with 29 features.\n",
						"Fitting estimator with 20 features.\n",
						"Fitting estimator with 17 features.\n",
						"Fitting estimator with 2 features.\n",
						"Fitting estimator with 15 features.\n",
						"Fitting estimator with 20 features.\n",
						"Fitting estimator with 30 features.\n",
						"Fitting estimator with 22 features.\n",
						"Fitting estimator with 28 features.\n",
						"Fitting estimator with 19 features.\n",
						"Fitting estimator with 14 features.\n",
						"Fitting estimator with 16 features.\n",
						"Fitting estimator with 21 features.\n",
						"Fitting estimator with 19 features.\n",
						"Fitting estimator with 29 features.\n",
						"Fitting estimator with 27 features.\n",
						"Fitting estimator with 13 features.\n",
						"Fitting estimator with 18 features.\n",
						"Fitting estimator with 20 features.\n",
						"Fitting estimator with 15 features.\n",
						"Fitting estimator with 28 features.\n",
						"Fitting estimator with 18 features.\n",
						"Fitting estimator with 12 features.\n",
						"Fitting estimator with 26 features.\n",
						"Fitting estimator with 19 features.\n",
						"Fitting estimator with 17 features.\n",
						"Fitting estimator with 11 features.\n",
						"Fitting estimator with 27 features.Fitting estimator with 14 features.\n",
						"\n",
						"Fitting estimator with 17 features.\n",
						"Fitting estimator with 25 features.\n",
						"Fitting estimator with 18 features.\n",
						"Fitting estimator with 10 features.\n",
						"Fitting estimator with 13 features.\n",
						"Fitting estimator with 26 features.\n",
						"Fitting estimator with 24 features.Fitting estimator with 17 features.\n",
						"\n",
						"Fitting estimator with 16 features.\n",
						"Fitting estimator with 9 features.\n",
						"Fitting estimator with 16 features.\n",
						"Fitting estimator with 55 features.\n",
						"Fitting estimator with 8 features.Fitting estimator with 12 features.\n",
						"\n",
						"Fitting estimator with 16 features.\n",
						"Fitting estimator with 15 features.Fitting estimator with 15 features.\n",
						"\n",
						"Fitting estimator with 23 features.\n",
						"Fitting estimator with 25 features.\n",
						"Fitting estimator with 7 features.\n",
						"Fitting estimator with 11 features.\n",
						"Fitting estimator with 15 features.\n",
						"Fitting estimator with 14 features.\n",
						"Fitting estimator with 54 features.\n",
						"Fitting estimator with 22 features.\n",
						"Fitting estimator with 14 features.\n",
						"Fitting estimator with 6 features.\n",
						"Fitting estimator with 24 features.\n",
						"Fitting estimator with 14 features.\n",
						"Fitting estimator with 13 features.\n",
						"Fitting estimator with 10 features.Fitting estimator with 5 features.\n",
						"\n",
						"Fitting estimator with 21 features.Fitting estimator with 53 features.\n",
						"\n",
						"Fitting estimator with 13 features.\n",
						"Fitting estimator with 12 features.\n",
						"Fitting estimator with 13 features.\n",
						"Fitting estimator with 23 features.\n",
						"Fitting estimator with 4 features.\n",
						"Fitting estimator with 9 features.\n",
						"Fitting estimator with 20 features.\n",
						"Fitting estimator with 3 features.\n",
						"Fitting estimator with 11 features.\n",
						"Fitting estimator with 52 features.\n",
						"Fitting estimator with 12 features.\n",
						"Fitting estimator with 12 features.\n",
						"Fitting estimator with 2 features.\n",
						"Fitting estimator with 8 features.\n",
						"Fitting estimator with 19 features.Fitting estimator with 10 features.\n",
						"\n",
						"Fitting estimator with 11 features.\n",
						"Fitting estimator with 11 features.\n",
						"Fitting estimator with 51 features.\n",
						"Fitting estimator with 7 features.Fitting estimator with 22 features.\n",
						"Fitting estimator with 9 features.\n",
						"\n",
						"Fitting estimator with 10 features.Fitting estimator with 18 features.\n",
						"\n",
						"Fitting estimator with 10 features.\n",
						"Fitting estimator with 8 features.\n",
						"Fitting estimator with 6 features.\n",
						"Fitting estimator with 50 features.\n",
						"Fitting estimator with 17 features.Fitting estimator with 9 features.\n",
						"\n",
						"Fitting estimator with 7 features.Fitting estimator with 9 features.\n",
						"\n",
						"Fitting estimator with 5 features.\n",
						"Fitting estimator with 8 features.\n",
						"Fitting estimator with 16 features.\n",
						"Fitting estimator with 6 features.\n",
						"Fitting estimator with 49 features.\n",
						"Fitting estimator with 8 features.\n",
						"Fitting estimator with 7 features.\n",
						"Fitting estimator with 5 features.\n",
						"Fitting estimator with 4 features.\n",
						"Fitting estimator with 15 features.\n",
						"Fitting estimator with 4 features.\n",
						"Fitting estimator with 6 features.Fitting estimator with 7 features.\n",
						"\n",
						"Fitting estimator with 3 features.\n",
						"Fitting estimator with 48 features.\n",
						"Fitting estimator with 3 features.\n",
						"Fitting estimator with 14 features.\n",
						"Fitting estimator with 5 features.\n",
						"Fitting estimator with 2 features.\n",
						"Fitting estimator with 2 features.\n",
						"Fitting estimator with 6 features.\n",
						"Fitting estimator with 4 features.Fitting estimator with 13 features.\n",
						"\n",
						"Fitting estimator with 47 features.\n",
						"Fitting estimator with 21 features.\n",
						"Fitting estimator with 55 features.\n",
						"Fitting estimator with 5 features.Fitting estimator with 3 features.\n",
						"\n",
						"Fitting estimator with 12 features.\n",
						"Fitting estimator with 2 features.\n",
						"Fitting estimator with 54 features.\n",
						"Fitting estimator with 11 features.\n",
						"Fitting estimator with 46 features.\n",
						"Fitting estimator with 20 features.\n",
						"Fitting estimator with 4 features.\n",
						"Fitting estimator with 10 features.\n",
						"Fitting estimator with 53 features.\n",
						"Fitting estimator with 3 features.\n",
						"Fitting estimator with 2 features.\n",
						"Fitting estimator with 19 features.\n",
						"Fitting estimator with 52 features.Fitting estimator with 45 features.\n",
						"\n",
						"Fitting estimator with 9 features.\n",
						"Fitting estimator with 18 features.\n",
						"Fitting estimator with 55 features.\n",
						"Fitting estimator with 44 features.\n",
						"Fitting estimator with 17 features.\n",
						"Fitting estimator with 54 features.\n",
						"Fitting estimator with 51 features.\n",
						"Fitting estimator with 55 features.\n",
						"Fitting estimator with 43 features.Fitting estimator with 16 features.\n",
						"\n",
						"Fitting estimator with 55 features.\n",
						"Fitting estimator with 8 features.\n",
						"Fitting estimator with 53 features.\n",
						"Fitting estimator with 7 features.\n",
						"Fitting estimator with 15 features.\n",
						"Fitting estimator with 42 features.\n",
						"Fitting estimator with 54 features.\n",
						"Fitting estimator with 52 features.\n",
						"Fitting estimator with 6 features.\n",
						"Fitting estimator with 50 features.\n",
						"Fitting estimator with 54 features.\n",
						"Fitting estimator with 14 features.\n",
						"Fitting estimator with 41 features.\n",
						"Fitting estimator with 5 features.\n",
						"Fitting estimator with 51 features.\n",
						"Fitting estimator with 4 features.\n",
						"Fitting estimator with 13 features.\n",
						"Fitting estimator with 40 features.\n",
						"Fitting estimator with 53 features.\n",
						"Fitting estimator with 3 features.\n",
						"Fitting estimator with 53 features.\n",
						"Fitting estimator with 55 features.\n",
						"Fitting estimator with 50 features.\n",
						"Fitting estimator with 49 features.\n",
						"Fitting estimator with 2 features.\n",
						"Fitting estimator with 12 features.\n",
						"Fitting estimator with 39 features.\n",
						"Fitting estimator with 52 features.\n",
						"Fitting estimator with 52 features.\n",
						"Fitting estimator with 11 features.\n",
						"Fitting estimator with 49 features.\n",
						"Fitting estimator with 38 features.\n",
						"Fitting estimator with 51 features.\n",
						"Fitting estimator with 51 features.\n",
						"Fitting estimator with 10 features.\n",
						"Fitting estimator with 54 features.\n",
						"Fitting estimator with 37 features.\n",
						"Fitting estimator with 48 features.\n",
						"Fitting estimator with 9 features.\n",
						"Fitting estimator with 48 features.\n",
						"Fitting estimator with 50 features.\n",
						"Fitting estimator with 50 features.\n",
						"Fitting estimator with 36 features.\n",
						"Fitting estimator with 8 features.\n",
						"Fitting estimator with 49 features.\n",
						"Fitting estimator with 47 features.\n",
						"Fitting estimator with 7 features.\n",
						"Fitting estimator with 49 features.\n",
						"Fitting estimator with 53 features.\n",
						"Fitting estimator with 35 features.\n",
						"Fitting estimator with 47 features.\n",
						"Fitting estimator with 6 features.\n",
						"Fitting estimator with 48 features.\n",
						"Fitting estimator with 48 features.\n",
						"Fitting estimator with 34 features.\n",
						"Fitting estimator with 5 features.\n",
						"Fitting estimator with 55 features.\n",
						"Fitting estimator with 46 features.\n",
						"Fitting estimator with 4 features.\n",
						"Fitting estimator with 52 features.\n",
						"Fitting estimator with 47 features.\n",
						"Fitting estimator with 47 features.\n",
						"Fitting estimator with 33 features.\n",
						"Fitting estimator with 3 features.\n",
						"Fitting estimator with 46 features.\n",
						"Fitting estimator with 45 features.Fitting estimator with 2 features.\n",
						"\n",
						"Fitting estimator with 54 features.\n",
						"Fitting estimator with 46 features.\n",
						"Fitting estimator with 46 features.\n",
						"Fitting estimator with 32 features.\n",
						"Fitting estimator with 44 features.\n",
						"Fitting estimator with 31 features.Fitting estimator with 53 features.\n",
						"\n",
						"Fitting estimator with 45 features.\n",
						"Fitting estimator with 45 features.\n",
						"Fitting estimator with 45 features.Fitting estimator with 51 features.\n",
						"\n",
						"Fitting estimator with 43 features.\n",
						"Fitting estimator with 30 features.\n",
						"Fitting estimator with 44 features.\n",
						"Fitting estimator with 52 features.Fitting estimator with 44 features.\n",
						"\n",
						"Fitting estimator with 42 features.\n",
						"Fitting estimator with 29 features.\n",
						"Fitting estimator with 43 features.\n",
						"Fitting estimator with 44 features.\n",
						"Fitting estimator with 50 features.\n",
						"Fitting estimator with 51 features.\n",
						"Fitting estimator with 43 features.\n",
						"Fitting estimator with 28 features.\n",
						"Fitting estimator with 41 features.\n",
						"Fitting estimator with 42 features.\n",
						"Fitting estimator with 43 features.\n",
						"Fitting estimator with 27 features.\n",
						"Fitting estimator with 50 features.Fitting estimator with 40 features.\n",
						"\n",
						"Fitting estimator with 41 features.Fitting estimator with 42 features.\n",
						"\n",
						"Fitting estimator with 42 features.\n",
						"Fitting estimator with 49 features.\n",
						"Fitting estimator with 26 features.\n",
						"Fitting estimator with 39 features.\n",
						"Fitting estimator with 49 features.\n",
						"Fitting estimator with 40 features.\n",
						"Fitting estimator with 41 features.\n",
						"Fitting estimator with 41 features.\n",
						"Fitting estimator with 25 features.\n",
						"Fitting estimator with 48 features.\n",
						"Fitting estimator with 38 features.\n",
						"Fitting estimator with 39 features.Fitting estimator with 24 features.\n",
						"\n",
						"Fitting estimator with 40 features.\n",
						"Fitting estimator with 48 features.\n",
						"Fitting estimator with 40 features.\n",
						"Fitting estimator with 47 features.\n",
						"Fitting estimator with 37 features.\n",
						"Fitting estimator with 23 features.\n",
						"Fitting estimator with 39 features.Fitting estimator with 38 features.\n",
						"\n",
						"Fitting estimator with 47 features.\n",
						"Fitting estimator with 39 features.\n",
						"Fitting estimator with 46 features.\n",
						"Fitting estimator with 36 features.\n",
						"Fitting estimator with 22 features.\n",
						"Fitting estimator with 38 features.Fitting estimator with 37 features.\n",
						"\n",
						"Fitting estimator with 21 features.\n",
						"Fitting estimator with 38 features.\n",
						"Fitting estimator with 35 features.\n",
						"Fitting estimator with 46 features.\n",
						"Fitting estimator with 45 features.\n",
						"Fitting estimator with 37 features.\n",
						"Fitting estimator with 36 features.\n",
						"Fitting estimator with 20 features.\n",
						"Fitting estimator with 37 features.\n",
						"Fitting estimator with 34 features.\n",
						"Fitting estimator with 45 features.\n",
						"Fitting estimator with 36 features.\n",
						"Fitting estimator with 35 features.\n",
						"Fitting estimator with 19 features.\n",
						"Fitting estimator with 44 features.\n",
						"Fitting estimator with 36 features.\n",
						"Fitting estimator with 33 features.\n",
						"Fitting estimator with 18 features.\n",
						"Fitting estimator with 35 features.\n",
						"Fitting estimator with 34 features.\n",
						"Fitting estimator with 44 features.\n",
						"Fitting estimator with 35 features.\n",
						"Fitting estimator with 32 features.\n",
						"Fitting estimator with 17 features.\n",
						"Fitting estimator with 43 features.\n",
						"Fitting estimator with 33 features.\n",
						"Fitting estimator with 34 features.\n",
						"Fitting estimator with 16 features.\n",
						"Fitting estimator with 43 features.Fitting estimator with 34 features.\n",
						"\n",
						"Fitting estimator with 31 features.\n",
						"Fitting estimator with 32 features.\n",
						"Fitting estimator with 42 features.\n",
						"Fitting estimator with 33 features.\n",
						"Fitting estimator with 15 features.\n",
						"Fitting estimator with 33 features.\n",
						"Fitting estimator with 42 features.\n",
						"Fitting estimator with 30 features.\n",
						"Fitting estimator with 31 features.\n",
						"Fitting estimator with 32 features.\n",
						"Fitting estimator with 14 features.\n",
						"Fitting estimator with 41 features.\n",
						"Fitting estimator with 32 features.\n",
						"Fitting estimator with 41 features.\n",
						"Fitting estimator with 29 features.\n",
						"Fitting estimator with 13 features.\n",
						"Fitting estimator with 31 features.\n",
						"Fitting estimator with 30 features.\n",
						"Fitting estimator with 40 features.\n",
						"Fitting estimator with 31 features.\n",
						"Fitting estimator with 12 features.\n",
						"Fitting estimator with 28 features.\n",
						"Fitting estimator with 40 features.\n",
						"Fitting estimator with 29 features.\n",
						"Fitting estimator with 30 features.\n",
						"Fitting estimator with 11 features.Fitting estimator with 39 features.\n",
						"\n",
						"Fitting estimator with 30 features.\n",
						"Fitting estimator with 28 features.Fitting estimator with 29 features.\n",
						"\n",
						"Fitting estimator with 27 features.\n",
						"Fitting estimator with 39 features.\n",
						"Fitting estimator with 10 features.\n",
						"Fitting estimator with 38 features.\n",
						"Fitting estimator with 29 features.\n",
						"Fitting estimator with 28 features.\n",
						"Fitting estimator with 27 features.\n",
						"Fitting estimator with 9 features.\n",
						"Fitting estimator with 26 features.\n",
						"Fitting estimator with 38 features.\n",
						"Fitting estimator with 28 features.\n",
						"Fitting estimator with 37 features.\n",
						"Fitting estimator with 8 features.\n",
						"Fitting estimator with 27 features.\n",
						"Fitting estimator with 26 features.\n",
						"Fitting estimator with 25 features.\n",
						"Fitting estimator with 37 features.\n",
						"Fitting estimator with 7 features.\n",
						"Fitting estimator with 26 features.\n",
						"Fitting estimator with 27 features.\n",
						"Fitting estimator with 36 features.\n",
						"Fitting estimator with 25 features.\n",
						"Fitting estimator with 24 features.\n",
						"Fitting estimator with 6 features.\n",
						"Fitting estimator with 36 features.\n",
						"Fitting estimator with 25 features.\n",
						"Fitting estimator with 26 features.\n",
						"Fitting estimator with 24 features.Fitting estimator with 5 features.\n",
						"\n",
						"Fitting estimator with 35 features.\n",
						"Fitting estimator with 23 features.\n",
						"Fitting estimator with 24 features.\n",
						"Fitting estimator with 35 features.\n",
						"Fitting estimator with 4 features.\n",
						"Fitting estimator with 25 features.\n",
						"Fitting estimator with 23 features.\n",
						"Fitting estimator with 34 features.\n",
						"Fitting estimator with 22 features.\n",
						"Fitting estimator with 3 features.\n",
						"Fitting estimator with 23 features.\n",
						"Fitting estimator with 34 features.\n",
						"Fitting estimator with 24 features.\n",
						"Fitting estimator with 2 features.Fitting estimator with 22 features.\n",
						"\n",
						"Fitting estimator with 33 features.\n",
						"Fitting estimator with 21 features.\n",
						"Fitting estimator with 22 features.\n",
						"Fitting estimator with 23 features.Fitting estimator with 33 features.\n",
						"\n",
						"Fitting estimator with 21 features.\n",
						"Fitting estimator with 32 features.\n",
						"Fitting estimator with 20 features.\n",
						"Fitting estimator with 21 features.\n",
						"Fitting estimator with 22 features.\n",
						"Fitting estimator with 20 features.\n",
						"Fitting estimator with 32 features.\n",
						"Fitting estimator with 20 features.\n",
						"Fitting estimator with 19 features.\n",
						"Fitting estimator with 31 features.Fitting estimator with 19 features.\n",
						"\n",
						"Fitting estimator with 21 features.\n",
						"Fitting estimator with 31 features.\n",
						"Fitting estimator with 18 features.\n",
						"Fitting estimator with 19 features.\n",
						"Fitting estimator with 18 features.\n",
						"Fitting estimator with 30 features.Fitting estimator with 20 features.\n",
						"\n",
						"Fitting estimator with 30 features.\n",
						"Fitting estimator with 17 features.\n",
						"Fitting estimator with 18 features.\n",
						"Fitting estimator with 17 features.\n",
						"Fitting estimator with 19 features.\n",
						"Fitting estimator with 16 features.\n",
						"Fitting estimator with 29 features.\n",
						"Fitting estimator with 17 features.\n",
						"Fitting estimator with 29 features.\n",
						"Fitting estimator with 16 features.\n",
						"Fitting estimator with 15 features.\n",
						"Fitting estimator with 18 features.\n",
						"Fitting estimator with 16 features.\n",
						"Fitting estimator with 28 features.\n",
						"Fitting estimator with 28 features.\n",
						"Fitting estimator with 15 features.Fitting estimator with 14 features.\n",
						"\n",
						"Fitting estimator with 17 features.\n",
						"Fitting estimator with 15 features.\n",
						"Fitting estimator with 27 features.\n",
						"Fitting estimator with 13 features.\n",
						"Fitting estimator with 27 features.Fitting estimator with 14 features.\n",
						"\n",
						"Fitting estimator with 16 features.\n",
						"Fitting estimator with 14 features.\n",
						"Fitting estimator with 12 features.\n",
						"Fitting estimator with 13 features.\n",
						"Fitting estimator with 26 features.\n",
						"Fitting estimator with 26 features.\n",
						"Fitting estimator with 13 features.\n",
						"Fitting estimator with 11 features.\n",
						"Fitting estimator with 15 features.\n",
						"Fitting estimator with 12 features.\n",
						"Fitting estimator with 10 features.\n",
						"Fitting estimator with 12 features.\n",
						"Fitting estimator with 25 features.\n",
						"Fitting estimator with 25 features.\n",
						"Fitting estimator with 14 features.\n",
						"Fitting estimator with 11 features.\n",
						"Fitting estimator with 9 features.\n",
						"Fitting estimator with 11 features.\n",
						"Fitting estimator with 13 features.\n",
						"Fitting estimator with 24 features.\n",
						"Fitting estimator with 24 features.\n",
						"Fitting estimator with 10 features.\n",
						"Fitting estimator with 8 features.\n",
						"Fitting estimator with 10 features.\n",
						"Fitting estimator with 12 features.\n",
						"Fitting estimator with 7 features.\n",
						"Fitting estimator with 23 features.\n",
						"Fitting estimator with 23 features.Fitting estimator with 9 features.\n",
						"\n",
						"Fitting estimator with 9 features.\n",
						"Fitting estimator with 11 features.\n",
						"Fitting estimator with 6 features.\n",
						"Fitting estimator with 8 features.\n",
						"Fitting estimator with 8 features.\n",
						"Fitting estimator with 22 features.\n",
						"Fitting estimator with 22 features.\n",
						"Fitting estimator with 5 features.\n",
						"Fitting estimator with 10 features.\n",
						"Fitting estimator with 7 features.\n",
						"Fitting estimator with 7 features.\n",
						"Fitting estimator with 4 features.\n",
						"Fitting estimator with 21 features.\n",
						"Fitting estimator with 6 features.\n",
						"Fitting estimator with 21 features.Fitting estimator with 6 features.\n",
						"\n",
						"Fitting estimator with 9 features.\n",
						"Fitting estimator with 3 features.\n",
						"Fitting estimator with 5 features.\n",
						"Fitting estimator with 5 features.\n",
						"Fitting estimator with 8 features.\n",
						"Fitting estimator with 20 features.\n",
						"Fitting estimator with 2 features.\n",
						"Fitting estimator with 20 features.\n",
						"Fitting estimator with 4 features.\n",
						"Fitting estimator with 4 features.\n",
						"Fitting estimator with 7 features.\n",
						"Fitting estimator with 3 features.Fitting estimator with 3 features.\n",
						"\n",
						"Fitting estimator with 19 features.\n",
						"Fitting estimator with 19 features.\n",
						"Fitting estimator with 6 features.\n",
						"Fitting estimator with 2 features.\n",
						"Fitting estimator with 2 features.\n",
						"Fitting estimator with 18 features.\n",
						"Fitting estimator with 5 features.\n",
						"Fitting estimator with 18 features.\n",
						"Fitting estimator with 4 features.\n",
						"Fitting estimator with 17 features.\n",
						"Fitting estimator with 17 features.\n",
						"Fitting estimator with 3 features.\n",
						"Fitting estimator with 16 features.\n",
						"Fitting estimator with 16 features.\n",
						"Fitting estimator with 2 features.\n",
						"Fitting estimator with 15 features.\n",
						"Fitting estimator with 15 features.\n",
						"Fitting estimator with 14 features.\n",
						"Fitting estimator with 14 features.\n",
						"Fitting estimator with 13 features.\n",
						"Fitting estimator with 13 features.\n",
						"Fitting estimator with 12 features.\n",
						"Fitting estimator with 12 features.\n",
						"Fitting estimator with 11 features.\n",
						"Fitting estimator with 11 features.\n",
						"Fitting estimator with 10 features.\n",
						"Fitting estimator with 10 features.\n",
						"Fitting estimator with 9 features.\n",
						"Fitting estimator with 9 features.\n",
						"Fitting estimator with 8 features.\n",
						"Fitting estimator with 8 features.\n",
						"Fitting estimator with 7 features.\n",
						"Fitting estimator with 7 features.\n",
						"Fitting estimator with 6 features.\n",
						"Fitting estimator with 6 features.\n",
						"Fitting estimator with 5 features.\n",
						"Fitting estimator with 5 features.\n",
						"Fitting estimator with 4 features.\n",
						"Fitting estimator with 4 features.\n",
						"Fitting estimator with 3 features.\n",
						"Fitting estimator with 3 features.\n",
						"Fitting estimator with 2 features.\n",
						"Fitting estimator with 2 features.\n",
						"Fitting estimator with 55 features.\n",
						"Fitting estimator with 54 features.\n",
						"Fitting estimator with 53 features.\n",
						"Fitting estimator with 52 features.\n",
						"Fitting estimator with 51 features.\n",
						"Fitting estimator with 50 features.\n",
						"Fitting estimator with 49 features.\n",
						"Fitting estimator with 48 features.\n",
						"Fitting estimator with 47 features.\n",
						"Fitting estimator with 46 features.\n",
						"Fitting estimator with 45 features.\n",
						"Fitting estimator with 44 features.\n",
						"Fitting estimator with 43 features.\n",
						"Fitting estimator with 42 features.\n",
						"Fitting estimator with 41 features.\n",
						"Fitting estimator with 40 features.\n",
						"Fitting estimator with 39 features.\n",
						"Fitting estimator with 38 features.\n",
						"Fitting estimator with 37 features.\n",
						"Fitting estimator with 36 features.\n",
						"Fitting estimator with 35 features.\n",
						"Fitting estimator with 34 features.\n",
						"Fitting estimator with 33 features.\n",
						"Fitting estimator with 32 features.\n",
						"Fitting estimator with 31 features.\n",
						"Fitting estimator with 30 features.\n",
						"Fitting estimator with 29 features.\n",
						"Fitting estimator with 28 features.\n",
						"Fitting estimator with 27 features.\n",
						"Fitting estimator with 26 features.\n",
						"Fitting estimator with 25 features.\n",
						"Fitting estimator with 24 features.\n",
						"Fitting estimator with 23 features.\n",
						"Fitting estimator with 22 features.\n",
						"Fitting estimator with 21 features.\n",
						"Fitting estimator with 20 features.\n",
						"Fitting estimator with 19 features.\n",
						"Fitting estimator with 18 features.\n",
						"Fitting estimator with 17 features.\n",
						"Fitting estimator with 16 features.\n",
						"Fitting estimator with 15 features.\n",
						"Fitting estimator with 14 features.\n",
						"Fitting estimator with 13 features.\n",
						"Optimal number of features: 12\n",
						"Optimal features: ['dechallenge_yes', 'rechallenge_yes', 'severity_fatal', 'action_taken_dose not changed', 'num_suspected_drugs_1', 'patient_bmi', 'rifampicin_start_stop_difference', 'isoniazid_start_stop_difference', 'pyrazinamide_start_to_onset_days', 'pyrazinamide_start_stop_difference', 'ethambutol_start_to_onset_days', 'ethambutol_start_stop_difference']\n"
					]
				}
			],
			"source": [
				"from sklearn.feature_selection import RFECV\n",
				"from sklearn.model_selection import RepeatedStratifiedKFold\n",
				"from sklearn.tree import DecisionTreeClassifier\n",
				"\n",
				"rfecv_cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=42)\n",
				"\n",
				"rfecv = RFECV(\n",
				"    estimator=DecisionTreeClassifier(),\n",
				"    step=1,\n",
				"    min_features_to_select=1,\n",
				"    cv=rfecv_cv,\n",
				"    scoring=\"f1_weighted\",\n",
				"    n_jobs=-1,\n",
				"    verbose=2,\n",
				")\n",
				"\n",
				"\n",
				"rfecv.fit(X_train_final, y_train_encoded)\n",
				"\n",
				"print(f\"Optimal number of features: {rfecv.n_features_}\")\n",
				"print(f\"Optimal features: {list(rfecv.get_feature_names_out())}\")\n",
				"\n",
				"prediction_columns = list(rfecv.get_feature_names_out())\n",
				"# print(rfecv.cv_results_)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 49,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"decision_tree\n",
						"------------------------------------------------------------------------------------------------------------------------------------------------------\n",
						"Fitting 15 folds for each of 3 candidates, totalling 45 fits\n",
						"[CV] END .......................................max_depth=25; total time=   0.0s\n",
						"[CV] END .......................................max_depth=25; total time=   0.0s\n",
						"[CV] END .......................................max_depth=25; total time=   0.0s[CV] END .......................................max_depth=25; total time=   0.0s\n",
						"\n",
						"[CV] END .......................................max_depth=25; total time=   0.0s\n",
						"[CV] END .......................................max_depth=25; total time=   0.0s\n",
						"[CV] END .......................................max_depth=25; total time=   0.0s\n",
						"[CV] END .......................................max_depth=25; total time=   0.0s\n",
						"[CV] END .......................................max_depth=25; total time=   0.0s\n",
						"[CV] END .......................................max_depth=25; total time=   0.0s\n",
						"[CV] END .......................................max_depth=25; total time=   0.0s\n",
						"[CV] END .......................................max_depth=25; total time=   0.0s\n",
						"[CV] END .......................................max_depth=50; total time=   0.0s\n",
						"[CV] END .......................................max_depth=50; total time=   0.0s\n",
						"[CV] END .......................................max_depth=50; total time=   0.0s\n",
						"[CV] END .......................................max_depth=50; total time=   0.0s\n",
						"[CV] END .......................................max_depth=50; total time=   0.0s\n",
						"[CV] END .......................................max_depth=50; total time=   0.0s\n",
						"[CV] END .......................................max_depth=50; total time=   0.0s\n",
						"[CV] END .......................................max_depth=25; total time=   0.0s[CV] END .......................................max_depth=50; total time=   0.0s\n",
						"\n",
						"[CV] END .......................................max_depth=50; total time=   0.0s\n",
						"[CV] END .......................................max_depth=50; total time=   0.0s\n",
						"[CV] END .......................................max_depth=50; total time=   0.0s\n",
						"[CV] END .......................................max_depth=50; total time=   0.0s\n",
						"[CV] END .......................................max_depth=50; total time=   0.0s\n",
						"[CV] END .......................................max_depth=50; total time=   0.0s\n",
						"[CV] END .......................................max_depth=25; total time=   0.0s\n",
						"[CV] END .......................................max_depth=50; total time=   0.0s\n",
						"[CV] END ......................................max_depth=100; total time=   0.0s\n",
						"[CV] END ......................................max_depth=100; total time=   0.0s\n",
						"[CV] END ......................................max_depth=100; total time=   0.0s\n",
						"[CV] END ......................................max_depth=100; total time=   0.0s\n",
						"[CV] END ......................................max_depth=100; total time=   0.0s\n",
						"[CV] END ......................................max_depth=100; total time=   0.0s\n",
						"[CV] END ......................................max_depth=100; total time=   0.0s\n",
						"[CV] END .......................................max_depth=25; total time=   0.0s\n",
						"[CV] END ......................................max_depth=100; total time=   0.0s\n",
						"[CV] END ......................................max_depth=100; total time=   0.0s\n",
						"[CV] END ......................................max_depth=100; total time=   0.0s\n",
						"[CV] END ......................................max_depth=100; total time=   0.0s\n",
						"[CV] END ......................................max_depth=100; total time=   0.0s\n",
						"[CV] END ......................................max_depth=100; total time=   0.0s\n",
						"[CV] END ......................................max_depth=100; total time=   0.0s\n",
						"[CV] END ......................................max_depth=100; total time=   0.0s\n",
						"----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
						"ada_boost\n",
						"------------------------------------------------------------------------------------------------------------------------------------------------------\n",
						"Fitting 15 folds for each of 4 candidates, totalling 60 fits\n",
						"[CV] END .................learning_rate=0.1, n_estimators=10; total time=   0.1s\n",
						"[CV] END .................learning_rate=0.1, n_estimators=10; total time=   0.1s\n",
						"[CV] END .................learning_rate=0.1, n_estimators=10; total time=   0.1s\n",
						"[CV] END .................learning_rate=0.1, n_estimators=10; total time=   0.1s\n",
						"[CV] END .................learning_rate=0.1, n_estimators=10; total time=   0.1s\n",
						"[CV] END .................learning_rate=0.1, n_estimators=10; total time=   0.1s\n",
						"[CV] END .................learning_rate=0.1, n_estimators=10; total time=   0.0s\n",
						"[CV] END .................learning_rate=0.1, n_estimators=10; total time=   0.1s\n",
						"[CV] END .................learning_rate=0.1, n_estimators=10; total time=   0.0s\n",
						"[CV] END .................learning_rate=0.1, n_estimators=10; total time=   0.0s\n",
						"[CV] END .................learning_rate=0.1, n_estimators=10; total time=   0.0s\n",
						"[CV] END .................learning_rate=0.1, n_estimators=10; total time=   0.0s\n",
						"[CV] END .................learning_rate=0.1, n_estimators=10; total time=   0.1s\n",
						"[CV] END .................learning_rate=0.1, n_estimators=10; total time=   0.1s\n",
						"[CV] END .................learning_rate=0.1, n_estimators=10; total time=   0.1s\n",
						"[CV] END .................learning_rate=0.1, n_estimators=50; total time=   0.2s\n",
						"[CV] END .................learning_rate=0.1, n_estimators=50; total time=   0.2s\n",
						"[CV] END .................learning_rate=0.1, n_estimators=50; total time=   0.2s\n",
						"[CV] END .................learning_rate=0.1, n_estimators=50; total time=   0.2s\n",
						"[CV] END .................learning_rate=0.1, n_estimators=50; total time=   0.3s\n",
						"[CV] END .................learning_rate=0.1, n_estimators=50; total time=   0.3s\n",
						"[CV] END .................learning_rate=0.1, n_estimators=50; total time=   0.3s\n",
						"[CV] END .................learning_rate=1.0, n_estimators=10; total time=   0.1s\n",
						"[CV] END .................learning_rate=0.1, n_estimators=50; total time=   0.2s\n",
						"[CV] END .................learning_rate=1.0, n_estimators=10; total time=   0.1s\n",
						"[CV] END .................learning_rate=0.1, n_estimators=50; total time=   0.2s[CV] END .................learning_rate=0.1, n_estimators=50; total time=   0.2s\n",
						"\n",
						"[CV] END .................learning_rate=1.0, n_estimators=10; total time=   0.1s\n",
						"[CV] END .................learning_rate=0.1, n_estimators=50; total time=   0.2s\n",
						"[CV] END .................learning_rate=1.0, n_estimators=10; total time=   0.0s\n",
						"[CV] END .................learning_rate=0.1, n_estimators=50; total time=   0.2s[CV] END .................learning_rate=0.1, n_estimators=50; total time=   0.2s\n",
						"\n",
						"[CV] END .................learning_rate=1.0, n_estimators=10; total time=   0.1s\n",
						"[CV] END .................learning_rate=1.0, n_estimators=10; total time=   0.0s\n",
						"[CV] END .................learning_rate=0.1, n_estimators=50; total time=   0.2s\n",
						"[CV] END .................learning_rate=1.0, n_estimators=10; total time=   0.1s\n",
						"[CV] END .................learning_rate=1.0, n_estimators=10; total time=   0.0s\n",
						"[CV] END .................learning_rate=1.0, n_estimators=10; total time=   0.0s\n",
						"[CV] END .................learning_rate=1.0, n_estimators=10; total time=   0.0s\n",
						"[CV] END .................learning_rate=1.0, n_estimators=10; total time=   0.0s\n",
						"[CV] END .................learning_rate=0.1, n_estimators=50; total time=   0.2s\n",
						"[CV] END .................learning_rate=1.0, n_estimators=10; total time=   0.0s\n",
						"[CV] END .................learning_rate=1.0, n_estimators=10; total time=   0.1s[CV] END .................learning_rate=1.0, n_estimators=10; total time=   0.0s\n",
						"\n",
						"[CV] END .................learning_rate=1.0, n_estimators=10; total time=   0.0s\n",
						"[CV] END .................learning_rate=1.0, n_estimators=50; total time=   0.2s\n",
						"[CV] END .................learning_rate=1.0, n_estimators=50; total time=   0.2s\n",
						"[CV] END .................learning_rate=1.0, n_estimators=50; total time=   0.2s\n",
						"[CV] END .................learning_rate=1.0, n_estimators=50; total time=   0.2s\n",
						"[CV] END .................learning_rate=1.0, n_estimators=50; total time=   0.2s\n",
						"[CV] END .................learning_rate=1.0, n_estimators=50; total time=   0.2s\n",
						"[CV] END .................learning_rate=1.0, n_estimators=50; total time=   0.2s\n",
						"[CV] END .................learning_rate=1.0, n_estimators=50; total time=   0.2s\n",
						"[CV] END .................learning_rate=1.0, n_estimators=50; total time=   0.2s\n",
						"[CV] END .................learning_rate=1.0, n_estimators=50; total time=   0.2s\n",
						"[CV] END .................learning_rate=1.0, n_estimators=50; total time=   0.2s\n",
						"[CV] END .................learning_rate=1.0, n_estimators=50; total time=   0.1s\n",
						"[CV] END .................learning_rate=1.0, n_estimators=50; total time=   0.2s\n",
						"[CV] END .................learning_rate=1.0, n_estimators=50; total time=   0.2s[CV] END .................learning_rate=1.0, n_estimators=50; total time=   0.2s\n",
						"\n",
						"----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
					]
				}
			],
			"source": [
				"from sklearn.metrics import classification_report\n",
				"from sklearn.model_selection import RandomizedSearchCV\n",
				"from sklearn.ensemble import AdaBoostClassifier\n",
				"\n",
				"estimators_and_param_grids = {\n",
				"    \"decision_tree\": (\n",
				"        DecisionTreeClassifier(random_state=42),\n",
				"        {\"max_depth\": [25, 50, 100]},\n",
				"    ),\n",
				"    \"ada_boost\": (\n",
				"        AdaBoostClassifier(algorithm=\"SAMME\", random_state=42),\n",
				"        {\n",
				"            \"n_estimators\": [10, 50],\n",
				"            \"learning_rate\": [0.1, 1.0],\n",
				"        },\n",
				"    ),\n",
				"    # \"xgb\": (\n",
				"    #     xgb.XGBClassifier(scale_pos_weight=1),\n",
				"    #     {\n",
				"    #         \"n_estimators\": [10, 50],\n",
				"    #         \"learning_rate\": [0.1, 1.0],\n",
				"    #         \"min_child_weight\": [1, 5],\n",
				"    #         \"gamma\": [0.5, 1, 1.5],\n",
				"    #         \"subsample\": [0.6, 0.8, 1.0],\n",
				"    #         \"colsample_bytree\": [0.6, 0.8, 1.0],\n",
				"    #         \"max_depth\": [3, 4, 5],\n",
				"    #     },\n",
				"    # ),\n",
				"}\n",
				"\n",
				"\n",
				"best_estimators = dict()\n",
				"best_estimators_and_best_param_grids = dict()\n",
				"\n",
				"cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=42)\n",
				"\n",
				"for estimator_name, estimator_and_param_grid in estimators_and_param_grids.items():\n",
				"    (estimator, param_grid) = estimator_and_param_grid\n",
				"\n",
				"    # search = GridSearchCV(\n",
				"    #     estimator=estimator, param_grid=param_grid, scoring=\"f1\", cv=cv, verbose=2\n",
				"    # )\n",
				"    print(estimator_name)\n",
				"    print(\"---\" * 50)\n",
				"\n",
				"    search = RandomizedSearchCV(\n",
				"        estimator=estimator,\n",
				"        param_distributions=param_grid,\n",
				"        cv=cv,\n",
				"        n_iter=100,\n",
				"        scoring=\"f1_weighted\",\n",
				"        verbose=2,\n",
				"        n_jobs=-1,\n",
				"    )\n",
				"\n",
				"    search.fit(X_train_final[prediction_columns], y_train_encoded)\n",
				"\n",
				"    best_estimator = search.best_estimator_\n",
				"    # best_estimators[estimator_name] = best_estimator\n",
				"    best_param_grid = search.best_params_\n",
				"\n",
				"    best_estimators_and_best_param_grids[estimator_name] = (\n",
				"        best_estimator,\n",
				"        best_param_grid,\n",
				"    )\n",
				"\n",
				"    best_estimators[estimator_name] = best_estimator\n",
				"    \n",
				"    # print(estimator_name)\n",
				"    # pprint(search.best_params_)\n",
				"\n",
				"    # # Evaluate the model on the test data\n",
				"    # accuracy = best_estimator.score(X_val, y_val)\n",
				"\n",
				"    # y_pred = best_estimator.predict(X_val)\n",
				"\n",
				"    # print(\"Accuracy:\", accuracy)\n",
				"\n",
				"    # classification_report = classification_report(y_val, y_pred)\n",
				"    # report_dict = classification_report(y_val, y_pred, output_dict=True)\n",
				"\n",
				"    # print(classification_report)\n",
				"\n",
				"    print(\"-----\" * 50)\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 50,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Classification Report for decision_tree\n",
						"================================================================================\n",
						"              precision    recall  f1-score   support\n",
						"\n",
						"     certain       0.82      0.69      0.75        13\n",
						"      likely       0.84      0.91      0.87       111\n",
						"    possible       0.88      0.79      0.83        73\n",
						"    unlikely       1.00      1.00      1.00        53\n",
						"\n",
						"    accuracy                           0.88       250\n",
						"   macro avg       0.88      0.85      0.86       250\n",
						"weighted avg       0.88      0.88      0.88       250\n",
						"\n",
						"================================================================================ \n",
						"\n",
						"Classification Report for ada_boost\n",
						"================================================================================\n",
						"              precision    recall  f1-score   support\n",
						"\n",
						"     certain       0.89      0.62      0.73        13\n",
						"      likely       0.92      0.77      0.84       111\n",
						"    possible       0.76      0.71      0.74        73\n",
						"    unlikely       0.66      1.00      0.80        53\n",
						"\n",
						"    accuracy                           0.80       250\n",
						"   macro avg       0.81      0.78      0.78       250\n",
						"weighted avg       0.82      0.80      0.80       250\n",
						"\n",
						"================================================================================ \n",
						"\n"
					]
				}
			],
			"source": [
				"for estimator_name, estimator in best_estimators.items():\n",
				"    print(f\"Classification Report for {estimator_name}\")\n",
				"    print(\"=\" * 80)\n",
				"\n",
				"    # Make predictions on the test set\n",
				"    y_pred = estimator.predict(X_test_final[prediction_columns])\n",
				"\n",
				"    # print(f\"{y_test_encoded=}\")\n",
				"    # print(f\"{y_pred=}\")\n",
				"    # Print classification report\n",
				"    label_classes = ordinal_encoder.categories_[0]\n",
				"    report = classification_report(\n",
				"        y_test_encoded, y_pred, target_names = label_classes\n",
				"    )\n",
				"    print(report)\n",
				"\n",
				"    print(\"=\" * 80, \"\\n\")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 51,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"{'0.0': {'f1-score': 0.6666666666666666,\n",
						"         'precision': 0.6,\n",
						"         'recall': 0.75,\n",
						"         'support': 8.0},\n",
						" '1.0': {'f1-score': 0.803030303030303,\n",
						"         'precision': 0.8153846153846154,\n",
						"         'recall': 0.7910447761194029,\n",
						"         'support': 67.0},\n",
						" '2.0': {'f1-score': 0.7674418604651163,\n",
						"         'precision': 0.7674418604651163,\n",
						"         'recall': 0.7674418604651163,\n",
						"         'support': 43.0},\n",
						" '3.0': {'f1-score': 1.0, 'precision': 1.0, 'recall': 1.0, 'support': 32.0},\n",
						" 'accuracy': 0.8266666666666667,\n",
						" 'macro avg': {'f1-score': 0.8092847075405215,\n",
						"               'precision': 0.7957066189624329,\n",
						"               'recall': 0.8271216591461298,\n",
						"               'support': 150.0},\n",
						" 'weighted avg': {'f1-score': 0.8275757575757575,\n",
						"                  'precision': 0.8295384615384616,\n",
						"                  'recall': 0.8266666666666667,\n",
						"                  'support': 150.0}}\n"
					]
				}
			],
			"source": [
				"(best_estimator, _) = best_estimators_and_best_param_grids[\"decision_tree\"]\n",
				"\n",
				"accuracy = best_estimator.score(X_val_final[prediction_columns], y_val_encoded)\n",
				"\n",
				"y_pred = best_estimator.predict(X_val_final[prediction_columns])\n",
				"\n",
				"pprint(classification_report(y_val_encoded, y_pred, output_dict=True))\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 52,
			"metadata": {},
			"outputs": [
				{
					"name": "stderr",
					"output_type": "stream",
					"text": [
						"Registered model 'final_ml_model' already exists. Creating a new version of this model...\n",
						"2025/05/26 16:19:58 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: final_ml_model, version 21\n",
						"Created version '21' of model 'final_ml_model'.\n"
					]
				},
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"🏃 View run decision_tree at: http://127.0.0.1:5001/#/experiments/1/runs/b9a923964f9e4548a012aa3fd6da102e\n",
						"🧪 View experiment at: http://127.0.0.1:5001/#/experiments/1\n"
					]
				},
				{
					"name": "stderr",
					"output_type": "stream",
					"text": [
						"Registered model 'final_ml_model' already exists. Creating a new version of this model...\n",
						"2025/05/26 16:20:02 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: final_ml_model, version 22\n"
					]
				},
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"🏃 View run ada_boost at: http://127.0.0.1:5001/#/experiments/1/runs/b7cfd53a8f1443a689260d90f33a9f84\n",
						"🧪 View experiment at: http://127.0.0.1:5001/#/experiments/1\n"
					]
				},
				{
					"name": "stderr",
					"output_type": "stream",
					"text": [
						"Created version '22' of model 'final_ml_model'.\n"
					]
				}
			],
			"source": [
				"from mlflow.models import infer_signature\n",
				"import mlflow\n",
				"import json\n",
				"\n",
				"for (\n",
				"    estimator_name,\n",
				"    best_estimator_and_best_param_grid,\n",
				") in best_estimators_and_best_param_grids.items():\n",
				"    (best_estimator, best_param_grid) = best_estimator_and_best_param_grid\n",
				"    # Evaluate the model on the test data\n",
				"    accuracy = best_estimator.score(X_val_final[prediction_columns], y_val_encoded)\n",
				"\n",
				"    y_pred = best_estimator.predict(X_val_final[prediction_columns])\n",
				"    label_classes = ordinal_encoder.categories_[0]\n",
				"\n",
				"    report = classification_report(y_val_encoded, y_pred, target_names=label_classes)\n",
				"    report_dict = classification_report(y_val_encoded, y_pred, output_dict=True)\n",
				"    class_report_dict = dict()\n",
				"\n",
				"    report_renaming_map = {\n",
				"        \"0.0\": \"certain\",\n",
				"        \"1.0\": \"likely\",\n",
				"        \"2.0\": \"possible\",\n",
				"        \"3.0\": \"unlikely\",\n",
				"    }\n",
				"\n",
				"    for key in report_dict.keys():\n",
				"        if key in report_renaming_map.keys():\n",
				"            class_report_dict[report_renaming_map[key]] = report_dict[key]\n",
				"\n",
				"    with mlflow.start_run(run_name=estimator_name):\n",
				"        # Parameters\n",
				"        mlflow.log_param(\"estimator_name\", estimator_name)\n",
				"        mlflow.log_params(param_grid)\n",
				"\n",
				"        # # Convert params to JSON and save as an artifact\n",
				"        # params_file_path = f\"{temp_artifacts_path}/params.json\"\n",
				"        # with open(params_file_path, \"w\") as f:\n",
				"        #     json.dump(param_grid, f, indent=4)\n",
				"\n",
				"        # Metrics\n",
				"        metrics_dict = {\n",
				"            \"accuracy\": report_dict[\"accuracy\"],\n",
				"            \"macro_avg_f1-score\": report_dict[\"macro avg\"][\"f1-score\"],\n",
				"            \"recall_class_certain\": class_report_dict[\"certain\"][\"recall\"],\n",
				"            \"recall_class_likely\": class_report_dict[\"likely\"][\"recall\"],\n",
				"            \"recall_class_possible\": class_report_dict[\"possible\"][\"recall\"],\n",
				"            \"recall_class_unlikely\": class_report_dict[\"unlikely\"][\"recall\"],\n",
				"        }\n",
				"        mlflow.log_metrics(metrics_dict)\n",
				"\n",
				"        # # Convert metrics to JSON and save as an artifact\n",
				"        # metrics_file_path = f\"{temp_artifacts_path}/metrics.json\"\n",
				"        # with open(metrics_file_path, \"w\") as f:\n",
				"        #     json.dump(metrics_dict, f, indent=4)\n",
				"\n",
				"        # Artifacts\n",
				"        ## Encoders\n",
				"        temp_artifacts_path = \"temp_artifacts\"\n",
				"\n",
				"        one_hot_encoder_path = f\"{temp_artifacts_path}/one_hot_encoder.pkl\"\n",
				"        ordinal_encoder_path = f\"{temp_artifacts_path}/ordinal_encoder.pkl\"\n",
				"        joblib.dump(one_hot_encoder, one_hot_encoder_path)\n",
				"        joblib.dump(ordinal_encoder, ordinal_encoder_path)\n",
				"\n",
				"        mlflow.log_artifact(one_hot_encoder_path, artifact_path=\"encoders\")\n",
				"        mlflow.log_artifact(ordinal_encoder_path, artifact_path=\"encoders\")\n",
				"\n",
				"        model_columns = {\n",
				"            \"categorical_columns\": categorical_columns,\n",
				"            \"numerical_columns\": numerical_columns,\n",
				"            \"date_columns\": date_columns,\n",
				"            \"boolean_columns\": boolean_columns,\n",
				"            \"prediction_columns\": prediction_columns,\n",
				"            \"columns_to_drop\": columns_to_drop,\n",
				"        }\n",
				"\n",
				"        with open(f\"{temp_artifacts_path}/model_columns.json\", \"w\") as f:\n",
				"            json.dump(model_columns, f, indent=4)\n",
				"\n",
				"        ## Scalers\n",
				"        scaler_path = f\"{temp_artifacts_path}/minmax_scaler.pkl\"\n",
				"        joblib.dump(scaler, scaler_path)\n",
				"        mlflow.log_artifact(scaler_path, artifact_path=\"scalers\")\n",
				"\n",
				"        ## Column Metadata\n",
				"        mlflow.log_artifact(\n",
				"            f\"{temp_artifacts_path}/model_columns.json\", artifact_path=\"metadata\"\n",
				"        )\n",
				"\n",
				"        # Model\n",
				"        signature = infer_signature(\n",
				"            X_train_final[prediction_columns],\n",
				"            best_estimator.predict(X_train_final[prediction_columns]),\n",
				"        )\n",
				"        # mlflow.sklearn.log_model(best_estimator, estimator_name, signature=signature)\n",
				"        # Log and register the model\n",
				"        model_info = mlflow.sklearn.log_model(\n",
				"            sk_model=best_estimator,\n",
				"            artifact_path=\"model\",\n",
				"            signature=signature,\n",
				"            registered_model_name=MLFLOW_MODEL_NAME,  # Register the model with a fixed name\n",
				"        )\n",
				"\n",
				"        # Set alias 'champion' to this model version\n",
				"        client = mlflow.MlflowClient()\n",
				"        latest_version = client.get_latest_versions(MLFLOW_MODEL_NAME, stages=[\"None\"])[\n",
				"            0\n",
				"        ].version  # Get the latest version\n",
				"        client.set_registered_model_alias(\n",
				"            MLFLOW_MODEL_NAME, MLFLOW_MODEL_ALIAS, latest_version\n",
				"        )  # Assign alias"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 53,
			"metadata": {},
			"outputs": [],
			"source": [
				"# import os\n",
				"\n",
				"# import joblib\n",
				"# from dotenv import load_dotenv\n",
				"\n",
				"# load_dotenv()\n",
				"\n",
				"# ML_MODEL_PATH = os.getenv(\"ML_MODEL_PATH\")\n",
				"# joblib.dump(best_estimators_and_best_param_grids[\"decision_tree\"][0], ML_MODEL_PATH)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 54,
			"metadata": {},
			"outputs": [],
			"source": [
				"# run_id = input(\"Run ID: \").strip()\n",
				"# model_name = input(\"Model Name: \").strip()\n",
				"# model_uri = f\"runs:/{run_id}/{model_name}\"\n",
				"\n",
				"# result = mlflow.register_model(model_uri, model_name)"
			]
		}
	],
	"metadata": {
		"kernelspec": {
			"display_name": "general",
			"language": "python",
			"name": "python3"
		},
		"language_info": {
			"codemirror_mode": {
				"name": "ipython",
				"version": 3
			},
			"file_extension": ".py",
			"mimetype": "text/x-python",
			"name": "python",
			"nbconvert_exporter": "python",
			"pygments_lexer": "ipython3",
			"version": "3.10.14"
		}
	},
	"nbformat": 4,
	"nbformat_minor": 2
}
