{
	"cells": [
		{
			"cell_type": "code",
			"execution_count": 1,
			"metadata": {},
			"outputs": [],
			"source": [
				"import warnings\n",
				"from pprint import pprint\n",
				"\n",
				"import pandas as pd\n",
				"import mlflow\n",
				"import matplotlib.pyplot as plt\n",
				"from mlflow.models import infer_signature\n",
				"import seaborn as sns\n",
				"from dotenv import load_dotenv\n",
				"import os\n",
				"from datetime import datetime\n",
				"from imblearn.over_sampling import SMOTENC\n",
				"from imblearn.under_sampling import RandomUnderSampler\n",
				"from typing import List\n",
				"import boto3\n",
				"\n",
				"\n",
				"warnings.filterwarnings(\"ignore\")\n",
				"warnings.simplefilter(\"ignore\")"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# Environment Variables\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 2,
			"metadata": {},
			"outputs": [],
			"source": [
				"dotenv_path = \"../.env\"\n",
				"load_dotenv(dotenv_path)\n",
				"\n",
				"MLFLOW_TRACKING_SERVER_HOST = os.getenv(\"MLFLOW_TRACKING_SERVER_HOST\")\n",
				"MLFLOW_TRACKING_SERVER_PORT = os.getenv(\"MLFLOW_TRACKING_SERVER_PORT\")\n",
				"MLFLOW_MODEL_NAME = os.getenv(\"MLFLOW_MODEL_NAME\")\n",
				"MLFLOW_MODEL_ALIAS = os.getenv(\"MLFLOW_MODEL_ALIAS\")\n",
				"\n",
				"MINIO_HOST = os.getenv(\"MINIO_HOST\")\n",
				"MINIO_API_PORT = os.getenv(\"MINIO_API_PORT\")\n"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# Tool Setup\n"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## Minio\n",
				"\n",
				"This helps with storing MLFlow data\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 3,
			"metadata": {},
			"outputs": [],
			"source": [
				"# Set MinIO Credentials\n",
				"os.environ[\"AWS_ACCESS_KEY_ID\"] = os.getenv(\"MINIO_ACCESS_KEY\")\n",
				"os.environ[\"AWS_SECRET_ACCESS_KEY\"] = os.getenv(\"MINIO_SECRET_ACCESS_KEY\")\n",
				"os.environ[\"AWS_DEFAULT_REGION\"] = os.getenv(\"AWS_REGION\")\n",
				"\n",
				"os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = f\"http://{MINIO_HOST}:{MINIO_API_PORT}\"\n",
				"\n",
				"\n",
				"# Test if credentials are set correctly\n",
				"s3 = boto3.client(\n",
				"    \"s3\",\n",
				"    endpoint_url=os.getenv(\"MLFLOW_S3_ENDPOINT_URL\"),\n",
				")"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## MLFlow\n",
				"\n",
				"MLOps tool that helps keep track of ML models, encoders, training data and more\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 4,
			"metadata": {},
			"outputs": [
				{
					"data": {
						"text/plain": [
							"<Experiment: artifact_location='s3://mlflow/1', creation_time=1741121925903, experiment_id='1', last_update_time=1741121925903, lifecycle_stage='active', name='4th year project', tags={}>"
						]
					},
					"execution_count": 4,
					"metadata": {},
					"output_type": "execute_result"
				}
			],
			"source": [
				"mlflow.set_tracking_uri(\n",
				"    uri=f\"http://{MLFLOW_TRACKING_SERVER_HOST}:{MLFLOW_TRACKING_SERVER_PORT}\"\n",
				")\n",
				"mlflow.set_experiment(\"4th year project\")"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# Reading Data\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 5,
			"metadata": {},
			"outputs": [],
			"source": [
				"df = pd.read_csv(\"data.csv\")"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# Grouping of columns based on data type\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 6,
			"metadata": {},
			"outputs": [],
			"source": [
				"categorical_columns = [\n",
				"    \"known_allergy\",\n",
				"    # \"description_of_reaction\",\n",
				"    \"dechallenge\",\n",
				"    \"rechallenge\",\n",
				"    \"severity\",\n",
				"    \"is_serious\",\n",
				"    \"criteria_for_seriousness\",\n",
				"    \"action_taken\",\n",
				"    \"outcome\",\n",
				"]\n",
				"\n",
				"for column in categorical_columns:\n",
				"    df[column] = df[column].astype(\"category\")\n",
				"\n",
				"\n",
				"numerical_columns = [\n",
				"    \"patient_age\",\n",
				"    \"patient_weight_kg\",\n",
				"    \"patient_height_cm\",\n",
				"]\n",
				"\n",
				"df[\"patient_bmi\"] = df[\"patient_weight_kg\"] / (\n",
				"    df[\"patient_height_cm\"] * df[\"patient_height_cm\"]\n",
				")\n",
				"\n",
				"numerical_columns.append(\"patient_bmi\")\n",
				"\n",
				"date_columns = [\n",
				"    \"patient_date_of_birth\",\n",
				"    \"date_of_onset_of_reaction\",\n",
				"    \"rifampicin_start_date\",\n",
				"    \"rifampicin_stop_date\",\n",
				"    \"isoniazid_start_date\",\n",
				"    \"isoniazid_stop_date\",\n",
				"    \"pyrazinamide_start_date\",\n",
				"    \"pyrazinamide_stop_date\",\n",
				"    \"ethambutol_start_date\",\n",
				"    \"ethambutol_stop_date\",\n",
				"    \"created_at\",\n",
				"]\n",
				"\n",
				"for column in date_columns:\n",
				"    df[column] = pd.to_datetime(df[column], errors=\"coerce\")\n",
				"\n",
				"\n",
				"# Current date for age calculation\n",
				"today = pd.to_datetime(\"today\")\n",
				"\n",
				"# Calculate age only where it's missing and dob is available\n",
				"missing_age_mask = df[\"patient_age\"].isnull() & df[\"patient_date_of_birth\"].notnull()\n",
				"\n",
				"df.loc[missing_age_mask, \"patient_age\"] = (\n",
				"    today - df.loc[missing_age_mask, \"patient_date_of_birth\"]\n",
				").dt.days // 365\n",
				"\n",
				"# Now fill any remaining missing ages (where dob was also missing) with median\n",
				"df[\"patient_age\"] = df[\"patient_age\"].fillna(df[\"patient_age\"].median())\n",
				"\n",
				"# Define drug prefixes for iteration\n",
				"drug_names = [\"rifampicin\", \"isoniazid\", \"pyrazinamide\", \"ethambutol\"]\n",
				"\n",
				"# Compute date differences in days for each drug\n",
				"for drug in drug_names:\n",
				"    start_col = f\"{drug}_start_to_onset_days\"\n",
				"    stop_col = f\"{drug}_stop_to_onset_days\"\n",
				"    start_stop_col = f\"{drug}_start_stop_difference\"\n",
				"\n",
				"    df[start_col] = (df[\"date_of_onset_of_reaction\"] - df[f\"{drug}_start_date\"]).dt.days\n",
				"    df[stop_col] = (df[\"date_of_onset_of_reaction\"] - df[f\"{drug}_stop_date\"]).dt.days\n",
				"    df[start_stop_col] = (df[f\"{drug}_stop_date\"] - df[f\"{drug}_start_date\"]).dt.days\n",
				"\n",
				"    # Add these as numerical columns\n",
				"    numerical_columns.extend([start_col, stop_col, start_stop_col])\n",
				"\n",
				"# Drop date columns\n",
				"df = df.drop(columns=date_columns)\n",
				"\n",
				"boolean_columns = [\n",
				"    \"rifampicin_suspected\",\n",
				"    \"isoniazid_suspected\",\n",
				"    \"pyrazinamide_suspected\",\n",
				"    \"ethambutol_suspected\",\n",
				"]\n",
				"\n",
				"df[\"num_suspected_drugs\"] = df[boolean_columns].sum(axis=1)\n",
				"categorical_columns.append(\"num_suspected_drugs\")\n",
				"\n",
				"target_column = \"causality_assessment_level\"\n",
				"df[target_column] = df[target_column].astype(\"category\")\n"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## Dropping unnecessary columns\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 7,
			"metadata": {},
			"outputs": [],
			"source": [
				"columns_to_drop = [\n",
				"    # Patient Info\n",
				"    \"patient_name\",\n",
				"    \"inpatient_or_outpatient_number\",\n",
				"    \"patient_address\",\n",
				"    \"ward_or_clinic\",\n",
				"    \"patient_gender\",\n",
				"    \"pregnancy_status\",\n",
				"    # Rifampicin\n",
				"    \"rifampicin_frequency_number\",\n",
				"    \"rifampicin_route\",\n",
				"    \"rifampicin_batch_no\",\n",
				"    \"rifampicin_manufacturer\",\n",
				"    \"rifampicin_dose_amount\",\n",
				"    # Isoniazid\n",
				"    \"isoniazid_frequency_number\",\n",
				"    \"isoniazid_route\",\n",
				"    \"isoniazid_batch_no\",\n",
				"    \"isoniazid_manufacturer\",\n",
				"    \"isoniazid_dose_amount\",\n",
				"    # Pyrazinamide\n",
				"    \"pyrazinamide_frequency_number\",\n",
				"    \"pyrazinamide_route\",\n",
				"    \"pyrazinamide_batch_no\",\n",
				"    \"pyrazinamide_manufacturer\",\n",
				"    \"pyrazinamide_dose_amount\",\n",
				"    # Ethambutol\n",
				"    \"ethambutol_frequency_number\",\n",
				"    \"ethambutol_route\",\n",
				"    \"ethambutol_batch_no\",\n",
				"    \"ethambutol_manufacturer\",\n",
				"    \"ethambutol_dose_amount\",\n",
				"]\n",
				"\n",
				"\n",
				"df = df.drop(columns=columns_to_drop)"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## Checking for null values\n",
				"\n",
				"ℹ️ If a row does not have `patient_date_of_birth`, it has `patient_age`\n",
				"<br>\n",
				"\n",
				"ℹ️ For the drugs, a null value might mean data is missing or not. It is not an error automatically\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 8,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"<class 'pandas.core.frame.DataFrame'>\n",
						"RangeIndex: 10000 entries, 0 to 9999\n",
						"Data columns (total 31 columns):\n",
						" #   Column                              Non-Null Count  Dtype   \n",
						"---  ------                              --------------  -----   \n",
						" 0   patient_age                         10000 non-null  float64 \n",
						" 1   known_allergy                       10000 non-null  category\n",
						" 2   patient_weight_kg                   10000 non-null  float64 \n",
						" 3   patient_height_cm                   10000 non-null  float64 \n",
						" 4   description_of_reaction             10000 non-null  object  \n",
						" 5   rifampicin_suspected                10000 non-null  bool    \n",
						" 6   isoniazid_suspected                 10000 non-null  bool    \n",
						" 7   pyrazinamide_suspected              10000 non-null  bool    \n",
						" 8   ethambutol_suspected                10000 non-null  bool    \n",
						" 9   dechallenge                         10000 non-null  category\n",
						" 10  rechallenge                         10000 non-null  category\n",
						" 11  severity                            10000 non-null  category\n",
						" 12  is_serious                          10000 non-null  category\n",
						" 13  criteria_for_seriousness            10000 non-null  category\n",
						" 14  action_taken                        10000 non-null  category\n",
						" 15  outcome                             10000 non-null  category\n",
						" 16  causality_assessment_level          10000 non-null  category\n",
						" 17  patient_bmi                         10000 non-null  float64 \n",
						" 18  rifampicin_start_to_onset_days      4155 non-null   float64 \n",
						" 19  rifampicin_stop_to_onset_days       4155 non-null   float64 \n",
						" 20  rifampicin_start_stop_difference    4155 non-null   float64 \n",
						" 21  isoniazid_start_to_onset_days       4103 non-null   float64 \n",
						" 22  isoniazid_stop_to_onset_days        4103 non-null   float64 \n",
						" 23  isoniazid_start_stop_difference     4103 non-null   float64 \n",
						" 24  pyrazinamide_start_to_onset_days    4185 non-null   float64 \n",
						" 25  pyrazinamide_stop_to_onset_days     4185 non-null   float64 \n",
						" 26  pyrazinamide_start_stop_difference  4185 non-null   float64 \n",
						" 27  ethambutol_start_to_onset_days      4148 non-null   float64 \n",
						" 28  ethambutol_stop_to_onset_days       4148 non-null   float64 \n",
						" 29  ethambutol_start_stop_difference    4148 non-null   float64 \n",
						" 30  num_suspected_drugs                 10000 non-null  int64   \n",
						"dtypes: bool(4), category(9), float64(16), int64(1), object(1)\n",
						"memory usage: 1.5+ MB\n"
					]
				}
			],
			"source": [
				"df.info()"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 9,
			"metadata": {},
			"outputs": [],
			"source": [
				"df[numerical_columns] = df[numerical_columns].fillna(-1)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 10,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"<class 'pandas.core.frame.DataFrame'>\n",
						"RangeIndex: 10000 entries, 0 to 9999\n",
						"Data columns (total 31 columns):\n",
						" #   Column                              Non-Null Count  Dtype   \n",
						"---  ------                              --------------  -----   \n",
						" 0   patient_age                         10000 non-null  float64 \n",
						" 1   known_allergy                       10000 non-null  category\n",
						" 2   patient_weight_kg                   10000 non-null  float64 \n",
						" 3   patient_height_cm                   10000 non-null  float64 \n",
						" 4   description_of_reaction             10000 non-null  object  \n",
						" 5   rifampicin_suspected                10000 non-null  bool    \n",
						" 6   isoniazid_suspected                 10000 non-null  bool    \n",
						" 7   pyrazinamide_suspected              10000 non-null  bool    \n",
						" 8   ethambutol_suspected                10000 non-null  bool    \n",
						" 9   dechallenge                         10000 non-null  category\n",
						" 10  rechallenge                         10000 non-null  category\n",
						" 11  severity                            10000 non-null  category\n",
						" 12  is_serious                          10000 non-null  category\n",
						" 13  criteria_for_seriousness            10000 non-null  category\n",
						" 14  action_taken                        10000 non-null  category\n",
						" 15  outcome                             10000 non-null  category\n",
						" 16  causality_assessment_level          10000 non-null  category\n",
						" 17  patient_bmi                         10000 non-null  float64 \n",
						" 18  rifampicin_start_to_onset_days      10000 non-null  float64 \n",
						" 19  rifampicin_stop_to_onset_days       10000 non-null  float64 \n",
						" 20  rifampicin_start_stop_difference    10000 non-null  float64 \n",
						" 21  isoniazid_start_to_onset_days       10000 non-null  float64 \n",
						" 22  isoniazid_stop_to_onset_days        10000 non-null  float64 \n",
						" 23  isoniazid_start_stop_difference     10000 non-null  float64 \n",
						" 24  pyrazinamide_start_to_onset_days    10000 non-null  float64 \n",
						" 25  pyrazinamide_stop_to_onset_days     10000 non-null  float64 \n",
						" 26  pyrazinamide_start_stop_difference  10000 non-null  float64 \n",
						" 27  ethambutol_start_to_onset_days      10000 non-null  float64 \n",
						" 28  ethambutol_stop_to_onset_days       10000 non-null  float64 \n",
						" 29  ethambutol_start_stop_difference    10000 non-null  float64 \n",
						" 30  num_suspected_drugs                 10000 non-null  int64   \n",
						"dtypes: bool(4), category(9), float64(16), int64(1), object(1)\n",
						"memory usage: 1.5+ MB\n"
					]
				}
			],
			"source": [
				"df.info()"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 11,
			"metadata": {},
			"outputs": [
				{
					"data": {
						"text/html": [
							"<div>\n",
							"<style scoped>\n",
							"    .dataframe tbody tr th:only-of-type {\n",
							"        vertical-align: middle;\n",
							"    }\n",
							"\n",
							"    .dataframe tbody tr th {\n",
							"        vertical-align: top;\n",
							"    }\n",
							"\n",
							"    .dataframe thead th {\n",
							"        text-align: right;\n",
							"    }\n",
							"</style>\n",
							"<table border=\"1\" class=\"dataframe\">\n",
							"  <thead>\n",
							"    <tr style=\"text-align: right;\">\n",
							"      <th></th>\n",
							"      <th>patient_age</th>\n",
							"      <th>known_allergy</th>\n",
							"      <th>patient_weight_kg</th>\n",
							"      <th>patient_height_cm</th>\n",
							"      <th>description_of_reaction</th>\n",
							"      <th>rifampicin_suspected</th>\n",
							"      <th>isoniazid_suspected</th>\n",
							"      <th>pyrazinamide_suspected</th>\n",
							"      <th>ethambutol_suspected</th>\n",
							"      <th>dechallenge</th>\n",
							"      <th>...</th>\n",
							"      <th>isoniazid_start_to_onset_days</th>\n",
							"      <th>isoniazid_stop_to_onset_days</th>\n",
							"      <th>isoniazid_start_stop_difference</th>\n",
							"      <th>pyrazinamide_start_to_onset_days</th>\n",
							"      <th>pyrazinamide_stop_to_onset_days</th>\n",
							"      <th>pyrazinamide_start_stop_difference</th>\n",
							"      <th>ethambutol_start_to_onset_days</th>\n",
							"      <th>ethambutol_stop_to_onset_days</th>\n",
							"      <th>ethambutol_start_stop_difference</th>\n",
							"      <th>num_suspected_drugs</th>\n",
							"    </tr>\n",
							"  </thead>\n",
							"  <tbody>\n",
							"    <tr>\n",
							"      <th>0</th>\n",
							"      <td>9.0</td>\n",
							"      <td>no</td>\n",
							"      <td>30.9</td>\n",
							"      <td>131.1</td>\n",
							"      <td>vomiting, joint pain, nausea</td>\n",
							"      <td>False</td>\n",
							"      <td>False</td>\n",
							"      <td>True</td>\n",
							"      <td>False</td>\n",
							"      <td>no</td>\n",
							"      <td>...</td>\n",
							"      <td>-1.0</td>\n",
							"      <td>-1.0</td>\n",
							"      <td>-1.0</td>\n",
							"      <td>68.0</td>\n",
							"      <td>9.0</td>\n",
							"      <td>59.0</td>\n",
							"      <td>-1.0</td>\n",
							"      <td>-1.0</td>\n",
							"      <td>-1.0</td>\n",
							"      <td>1</td>\n",
							"    </tr>\n",
							"    <tr>\n",
							"      <th>1</th>\n",
							"      <td>19.0</td>\n",
							"      <td>no</td>\n",
							"      <td>68.7</td>\n",
							"      <td>162.1</td>\n",
							"      <td>eye pain</td>\n",
							"      <td>False</td>\n",
							"      <td>False</td>\n",
							"      <td>False</td>\n",
							"      <td>True</td>\n",
							"      <td>no</td>\n",
							"      <td>...</td>\n",
							"      <td>-1.0</td>\n",
							"      <td>-1.0</td>\n",
							"      <td>-1.0</td>\n",
							"      <td>-1.0</td>\n",
							"      <td>-1.0</td>\n",
							"      <td>-1.0</td>\n",
							"      <td>9.0</td>\n",
							"      <td>-4.0</td>\n",
							"      <td>13.0</td>\n",
							"      <td>1</td>\n",
							"    </tr>\n",
							"    <tr>\n",
							"      <th>2</th>\n",
							"      <td>25.0</td>\n",
							"      <td>no</td>\n",
							"      <td>62.7</td>\n",
							"      <td>167.7</td>\n",
							"      <td>blurred vision, color blindness</td>\n",
							"      <td>False</td>\n",
							"      <td>False</td>\n",
							"      <td>False</td>\n",
							"      <td>True</td>\n",
							"      <td>yes</td>\n",
							"      <td>...</td>\n",
							"      <td>-1.0</td>\n",
							"      <td>-1.0</td>\n",
							"      <td>-1.0</td>\n",
							"      <td>-1.0</td>\n",
							"      <td>-1.0</td>\n",
							"      <td>-1.0</td>\n",
							"      <td>72.0</td>\n",
							"      <td>7.0</td>\n",
							"      <td>65.0</td>\n",
							"      <td>1</td>\n",
							"    </tr>\n",
							"    <tr>\n",
							"      <th>3</th>\n",
							"      <td>29.0</td>\n",
							"      <td>no</td>\n",
							"      <td>69.6</td>\n",
							"      <td>164.5</td>\n",
							"      <td>color blindness, eye pain</td>\n",
							"      <td>False</td>\n",
							"      <td>False</td>\n",
							"      <td>False</td>\n",
							"      <td>True</td>\n",
							"      <td>yes</td>\n",
							"      <td>...</td>\n",
							"      <td>-1.0</td>\n",
							"      <td>-1.0</td>\n",
							"      <td>-1.0</td>\n",
							"      <td>-1.0</td>\n",
							"      <td>-1.0</td>\n",
							"      <td>-1.0</td>\n",
							"      <td>62.0</td>\n",
							"      <td>7.0</td>\n",
							"      <td>55.0</td>\n",
							"      <td>1</td>\n",
							"    </tr>\n",
							"    <tr>\n",
							"      <th>4</th>\n",
							"      <td>27.0</td>\n",
							"      <td>no</td>\n",
							"      <td>63.4</td>\n",
							"      <td>161.0</td>\n",
							"      <td>joint pain, loss of appetite</td>\n",
							"      <td>False</td>\n",
							"      <td>False</td>\n",
							"      <td>True</td>\n",
							"      <td>False</td>\n",
							"      <td>yes</td>\n",
							"      <td>...</td>\n",
							"      <td>-1.0</td>\n",
							"      <td>-1.0</td>\n",
							"      <td>-1.0</td>\n",
							"      <td>66.0</td>\n",
							"      <td>10.0</td>\n",
							"      <td>56.0</td>\n",
							"      <td>-1.0</td>\n",
							"      <td>-1.0</td>\n",
							"      <td>-1.0</td>\n",
							"      <td>1</td>\n",
							"    </tr>\n",
							"  </tbody>\n",
							"</table>\n",
							"<p>5 rows × 31 columns</p>\n",
							"</div>"
						],
						"text/plain": [
							"   patient_age known_allergy  patient_weight_kg  patient_height_cm  \\\n",
							"0          9.0            no               30.9              131.1   \n",
							"1         19.0            no               68.7              162.1   \n",
							"2         25.0            no               62.7              167.7   \n",
							"3         29.0            no               69.6              164.5   \n",
							"4         27.0            no               63.4              161.0   \n",
							"\n",
							"           description_of_reaction  rifampicin_suspected  isoniazid_suspected  \\\n",
							"0     vomiting, joint pain, nausea                 False                False   \n",
							"1                         eye pain                 False                False   \n",
							"2  blurred vision, color blindness                 False                False   \n",
							"3        color blindness, eye pain                 False                False   \n",
							"4     joint pain, loss of appetite                 False                False   \n",
							"\n",
							"   pyrazinamide_suspected  ethambutol_suspected dechallenge  ...  \\\n",
							"0                    True                 False          no  ...   \n",
							"1                   False                  True          no  ...   \n",
							"2                   False                  True         yes  ...   \n",
							"3                   False                  True         yes  ...   \n",
							"4                    True                 False         yes  ...   \n",
							"\n",
							"  isoniazid_start_to_onset_days isoniazid_stop_to_onset_days  \\\n",
							"0                          -1.0                         -1.0   \n",
							"1                          -1.0                         -1.0   \n",
							"2                          -1.0                         -1.0   \n",
							"3                          -1.0                         -1.0   \n",
							"4                          -1.0                         -1.0   \n",
							"\n",
							"  isoniazid_start_stop_difference pyrazinamide_start_to_onset_days  \\\n",
							"0                            -1.0                             68.0   \n",
							"1                            -1.0                             -1.0   \n",
							"2                            -1.0                             -1.0   \n",
							"3                            -1.0                             -1.0   \n",
							"4                            -1.0                             66.0   \n",
							"\n",
							"  pyrazinamide_stop_to_onset_days pyrazinamide_start_stop_difference  \\\n",
							"0                             9.0                               59.0   \n",
							"1                            -1.0                               -1.0   \n",
							"2                            -1.0                               -1.0   \n",
							"3                            -1.0                               -1.0   \n",
							"4                            10.0                               56.0   \n",
							"\n",
							"  ethambutol_start_to_onset_days  ethambutol_stop_to_onset_days  \\\n",
							"0                           -1.0                           -1.0   \n",
							"1                            9.0                           -4.0   \n",
							"2                           72.0                            7.0   \n",
							"3                           62.0                            7.0   \n",
							"4                           -1.0                           -1.0   \n",
							"\n",
							"   ethambutol_start_stop_difference  num_suspected_drugs  \n",
							"0                              -1.0                    1  \n",
							"1                              13.0                    1  \n",
							"2                              65.0                    1  \n",
							"3                              55.0                    1  \n",
							"4                              -1.0                    1  \n",
							"\n",
							"[5 rows x 31 columns]"
						]
					},
					"execution_count": 11,
					"metadata": {},
					"output_type": "execute_result"
				}
			],
			"source": [
				"df.head()"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# Train/Val/Test Split\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 12,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"train_df.shape=(6000, 30)\n",
						"test_df.shape=(2500, 30)\n",
						"val_df.shape=(1500, 30)\n"
					]
				}
			],
			"source": [
				"from sklearn.model_selection import train_test_split\n",
				"\n",
				"X_full = df[[*categorical_columns, *boolean_columns, *numerical_columns]]\n",
				"y_full = df[target_column]\n",
				"\n",
				"X_train_and_val, X_test, y_train_and_val, y_test = train_test_split(\n",
				"    X_full, y_full, stratify=y_full, test_size=0.25\n",
				")\n",
				"\n",
				"\n",
				"X_train, X_val, y_train, y_val = train_test_split(\n",
				"    X_train_and_val,\n",
				"    y_train_and_val,\n",
				"    stratify=y_train_and_val,\n",
				"    test_size=0.2,\n",
				"    random_state=42,\n",
				")\n",
				"\n",
				"# Create the final train and validation DataFrames\n",
				"train_df = pd.concat([X_train, y_train], axis=1)\n",
				"\n",
				"val_df = pd.concat([X_val, y_val], axis=1)\n",
				"\n",
				"test_df = pd.concat([X_test, y_test], axis=1)\n",
				"\n",
				"del X_full\n",
				"del y_full\n",
				"del X_train\n",
				"del X_test\n",
				"del y_train\n",
				"del y_test\n",
				"\n",
				"print(f\"{train_df.shape=}\")\n",
				"print(f\"{test_df.shape=}\")\n",
				"print(f\"{val_df.shape=}\")\n"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# Target Class Distribution\n",
				"\n",
				"❗ Class imbalance exists. SMOTENC will be used\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 13,
			"metadata": {},
			"outputs": [
				{
					"data": {
						"text/plain": [
							"causality_assessment_level\n",
							"likely      0.4448\n",
							"possible    0.2961\n",
							"unlikely    0.2093\n",
							"certain     0.0498\n",
							"Name: proportion, dtype: float64"
						]
					},
					"execution_count": 13,
					"metadata": {},
					"output_type": "execute_result"
				}
			],
			"source": [
				"df[target_column].value_counts(normalize=True)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 14,
			"metadata": {},
			"outputs": [
				{
					"data": {
						"text/plain": [
							"causality_assessment_level\n",
							"certain     2669\n",
							"likely      2669\n",
							"possible    2669\n",
							"unlikely    2669\n",
							"Name: count, dtype: int64"
						]
					},
					"execution_count": 14,
					"metadata": {},
					"output_type": "execute_result"
				}
			],
			"source": [
				"X = train_df[[*categorical_columns, *boolean_columns, *numerical_columns]]\n",
				"y = train_df[target_column]\n",
				"\n",
				"smote_nc = SMOTENC(categorical_features=categorical_columns, random_state=42)\n",
				"\n",
				"X_smote, y_smote = smote_nc.fit_resample(X, y)\n",
				"\n",
				"\n",
				"# # Have now a dataframe with even data\n",
				"# under = RandomUnderSampler(random_state=42, sampling_strategy=0.5)\n",
				"# X_balanced, y_balanced = under.fit_resample(X_smote, y_smote)\n",
				"\n",
				"train_df = pd.concat([X_smote, y_smote], axis=1)\n",
				"\n",
				"train_df[target_column].value_counts()"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# Scale numerical columns\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 15,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"train_df.shape=(10676, 30)\n",
						"test_df.shape=(2500, 30)\n",
						"val_df.shape=(1500, 30)\n"
					]
				}
			],
			"source": [
				"from sklearn.preprocessing import MinMaxScaler\n",
				"\n",
				"\n",
				"scaler = MinMaxScaler()\n",
				"\n",
				"train_df[numerical_columns] = scaler.fit_transform(train_df[numerical_columns])\n",
				"val_df[numerical_columns] = scaler.transform(val_df[numerical_columns])\n",
				"test_df[numerical_columns] = scaler.transform(test_df[numerical_columns])\n",
				"\n",
				"print(f\"{train_df.shape=}\")\n",
				"print(f\"{test_df.shape=}\")\n",
				"print(f\"{val_df.shape=}\")\n"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# EDA\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 16,
			"metadata": {},
			"outputs": [],
			"source": [
				"df_for_eda = train_df"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 17,
			"metadata": {},
			"outputs": [],
			"source": [
				"def categorical_eda(df: pd.DataFrame, columns: List[str], target_column=str):\n",
				"    for column in columns:\n",
				"        df__categorical_count = df.groupby(column).size().reset_index(name=\"count\")\n",
				"\n",
				"        df__categorical_count_per_target = pd.crosstab(\n",
				"            df[column], df[target_column], normalize=\"index\"\n",
				"        )\n",
				"\n",
				"        display(df__categorical_count_per_target)\n",
				"        # df__categorical_count_per_target = df__categorical_count_per_target.loc[df__categorical_count[column]]\n",
				"\n",
				"        fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
				"\n",
				"        sns.barplot(\n",
				"            data=df__categorical_count, y=column, x=\"count\", ax=axes[0], orient=\"h\"\n",
				"        )\n",
				"        axes[0].set_title(f\"Count of {column}\")\n",
				"        axes[0].set_xlabel(\"Count\")\n",
				"        axes[0].set_ylabel(column)\n",
				"\n",
				"        df__categorical_count_per_target.plot(kind=\"barh\", stacked=True, ax=axes[1])\n",
				"\n",
				"        axes[1].set_title(f\"Proportion of {column} by {target_column}\")\n",
				"        axes[1].set_xlabel(\"Count\")\n",
				"        axes[1].set_ylabel(column)\n",
				"        # To maintain ordering\n",
				"        axes[1].invert_yaxis()\n",
				"\n",
				"        plt.tight_layout()\n",
				"\n",
				"        # Show the plots\n",
				"        plt.show()\n",
				"\n",
				"\n",
				"def numerical_eda(df: pd.DataFrame, columns: List[str], target_column: str):\n",
				"    for column in columns:\n",
				"        fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
				"\n",
				"        q1 = df[column].quantile(0.01)\n",
				"        q3 = df[column].quantile(0.99)\n",
				"\n",
				"        filtered_df = df[(df[column] >= q1) & (df[column] <= q3)]\n",
				"\n",
				"        sns.kdeplot(data=filtered_df, x=column, ax=axes[0], fill=True)\n",
				"\n",
				"        axes[0].set_title(f\"Distribution of {column}\")\n",
				"\n",
				"        sns.kdeplot(\n",
				"            data=filtered_df,\n",
				"            x=column,\n",
				"            hue=target_column,\n",
				"            ax=axes[1],\n",
				"            common_norm=False,\n",
				"            fill=True,\n",
				"        )\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 18,
			"metadata": {},
			"outputs": [],
			"source": [
				"# categorical_eda(\n",
				"#     df=df_for_eda,\n",
				"#     columns=[*categorical_columns, *boolean_columns],\n",
				"#     target_column=target_column,\n",
				"# )"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 19,
			"metadata": {},
			"outputs": [],
			"source": [
				"# numerical_eda(df=train_df, columns=numerical_columns, target_column=target_column)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 20,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Target classes: ['certain' 'likely' 'possible' 'unlikely']\n",
						"X_train_final.shape=(10676, 57)\n",
						"X_val_final.shape=(1500, 57)\n",
						"X_test_final.shape=(2500, 57)\n",
						"y_train_encoded.shape=(10676,)\n",
						"y_val_encoded.shape=(1500,)\n",
						"y_test_encoded.shape=(2500,)\n"
					]
				}
			],
			"source": [
				"import joblib\n",
				"\n",
				"from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
				"\n",
				"\n",
				"# one_hot_encoder = OneHotEncoder(sparse_output=False)\n",
				"\n",
				"# # train_df_cat_encoded = pd.get_dummies(train_df[categorical_columns])\n",
				"# train_df_cat_encoded = one_hot_encoder.fit_transform(train_df[categorical_columns])\n",
				"\n",
				"\n",
				"# train_df_cat_encoded = pd.DataFrame(\n",
				"#     train_df_cat_encoded,\n",
				"#     columns=one_hot_encoder.get_feature_names_out(categorical_columns),\n",
				"# )\n",
				"\n",
				"\n",
				"# test_df_cat_encoded = one_hot_encoder.transform(test_df[categorical_columns])\n",
				"# test_df_cat_encoded = pd.DataFrame(\n",
				"#     test_df_cat_encoded,\n",
				"#     columns=one_hot_encoder.get_feature_names_out(categorical_columns),\n",
				"# )\n",
				"\n",
				"\n",
				"# ordinal_encoder = OrdinalEncoder(\n",
				"#     categories=[\n",
				"#         [\"certain\", \"likely\", \"possible\", \"unlikely\", \"unclassified\", \"unclassifiable\"]\n",
				"#     ]\n",
				"# )\n",
				"\n",
				"# train_target_column_encoded = pd.DataFrame()\n",
				"\n",
				"# train_target_column_encoded[target_column] = ordinal_encoder.fit_transform(\n",
				"#     train_df[[target_column]]\n",
				"# ).ravel()\n",
				"\n",
				"# test_target_column_encoded = pd.DataFrame()\n",
				"\n",
				"\n",
				"# test_target_column_encoded[target_column] = ordinal_encoder.transform(\n",
				"#     test_df[[target_column]]\n",
				"# ).ravel()\n",
				"\n",
				"# Step 1: Split features and target from train, val, and test\n",
				"X_train = train_df[[*categorical_columns, *numerical_columns, *boolean_columns]]\n",
				"y_train = train_df[[target_column]]\n",
				"\n",
				"X_val = val_df[[*categorical_columns, *numerical_columns, *boolean_columns]]\n",
				"y_val = val_df[[target_column]]\n",
				"\n",
				"X_test = test_df[[*categorical_columns, *numerical_columns, *boolean_columns]]\n",
				"y_test = test_df[[target_column]]\n",
				"\n",
				"# Step 2: Define Encoders\n",
				"one_hot_encoder = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
				"# ordinal_encoder = OrdinalEncoder(\n",
				"#     categories=[\n",
				"#         [\"certain\", \"likely\", \"possible\", \"unlikely\", \"unclassified\", \"unclassifiable\"]\n",
				"#     ]\n",
				"# )\n",
				"\n",
				"ordinal_encoder = OrdinalEncoder(\n",
				"    categories=[[\"certain\", \"likely\", \"possible\", \"unlikely\"]]\n",
				")\n",
				"\n",
				"# Step 3: Fit OneHotEncoder on train set and transform train, val, test\n",
				"X_train_cat_encoded = one_hot_encoder.fit_transform(X_train[categorical_columns])\n",
				"X_val_cat_encoded = one_hot_encoder.transform(X_val[categorical_columns])\n",
				"X_test_cat_encoded = one_hot_encoder.transform(X_test[categorical_columns])\n",
				"\n",
				"# Step 4: Convert one-hot arrays to DataFrames\n",
				"cat_feature_names = one_hot_encoder.get_feature_names_out(categorical_columns)\n",
				"X_train_cat_df = pd.DataFrame(\n",
				"    X_train_cat_encoded, columns=cat_feature_names, index=X_train.index\n",
				").reset_index(drop=True)\n",
				"X_val_cat_df = pd.DataFrame(\n",
				"    X_val_cat_encoded, columns=cat_feature_names, index=X_val.index\n",
				").reset_index(drop=True)\n",
				"X_test_cat_df = pd.DataFrame(\n",
				"    X_test_cat_encoded, columns=cat_feature_names, index=X_test.index\n",
				").reset_index(drop=True)\n",
				"\n",
				"# Step 5: Concatenate all features\n",
				"X_train_final = pd.concat(\n",
				"    [\n",
				"        X_train_cat_df,\n",
				"        X_train[numerical_columns + boolean_columns].reset_index(drop=True),\n",
				"    ],\n",
				"    axis=1,\n",
				")\n",
				"X_val_final = pd.concat(\n",
				"    [X_val_cat_df, X_val[numerical_columns + boolean_columns].reset_index(drop=True)],\n",
				"    axis=1,\n",
				")\n",
				"X_test_final = pd.concat(\n",
				"    [X_test_cat_df, X_test[numerical_columns + boolean_columns].reset_index(drop=True)],\n",
				"    axis=1,\n",
				")\n",
				"\n",
				"# Step 6: Fit OrdinalEncoder on target (for classification)\n",
				"y_train_encoded = ordinal_encoder.fit_transform(y_train).ravel()\n",
				"y_val_encoded = ordinal_encoder.transform(y_val).ravel()\n",
				"y_test_encoded = ordinal_encoder.transform(y_test).ravel()\n",
				"\n",
				"# Optional: To see what the classes are\n",
				"label_classes = ordinal_encoder.categories_[0]\n",
				"print(\"Target classes:\", label_classes)\n",
				"\n",
				"print(f\"{X_train_final.shape=}\")\n",
				"print(f\"{X_val_final.shape=}\")\n",
				"print(f\"{X_test_final.shape=}\")\n",
				"\n",
				"\n",
				"print(f\"{y_train_encoded.shape=}\")\n",
				"print(f\"{y_val_encoded.shape=}\")\n",
				"print(f\"{y_test_encoded.shape=}\")\n"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# Feature\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 21,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Fitting estimator with 57 features.\n",
						"Fitting estimator with 57 features.\n",
						"Fitting estimator with 57 features.\n",
						"Fitting estimator with 57 features.\n",
						"Fitting estimator with 57 features.\n",
						"Fitting estimator with 57 features.\n",
						"Fitting estimator with 57 features.\n",
						"Fitting estimator with 57 features.\n",
						"Fitting estimator with 56 features.\n",
						"Fitting estimator with 56 features.\n",
						"Fitting estimator with 56 features.\n",
						"Fitting estimator with 56 features.\n",
						"Fitting estimator with 56 features.\n",
						"Fitting estimator with 56 features.\n",
						"Fitting estimator with 56 features.\n",
						"Fitting estimator with 56 features.\n",
						"Fitting estimator with 55 features.\n",
						"Fitting estimator with 55 features.\n",
						"Fitting estimator with 55 features.\n",
						"Fitting estimator with 55 features.\n",
						"Fitting estimator with 55 features.\n",
						"Fitting estimator with 55 features.\n",
						"Fitting estimator with 55 features.\n",
						"Fitting estimator with 55 features.\n",
						"Fitting estimator with 54 features.\n",
						"Fitting estimator with 54 features.\n",
						"Fitting estimator with 54 features.\n",
						"Fitting estimator with 54 features.\n",
						"Fitting estimator with 54 features.\n",
						"Fitting estimator with 54 features.\n",
						"Fitting estimator with 54 features.\n",
						"Fitting estimator with 54 features.\n",
						"Fitting estimator with 53 features.\n",
						"Fitting estimator with 53 features.\n",
						"Fitting estimator with 53 features.\n",
						"Fitting estimator with 53 features.\n",
						"Fitting estimator with 53 features.\n",
						"Fitting estimator with 53 features.\n",
						"Fitting estimator with 52 features.\n",
						"Fitting estimator with 53 features.\n",
						"Fitting estimator with 53 features.\n",
						"Fitting estimator with 52 features.\n",
						"Fitting estimator with 52 features.\n",
						"Fitting estimator with 52 features.\n",
						"Fitting estimator with 52 features.\n",
						"Fitting estimator with 52 features.\n",
						"Fitting estimator with 51 features.\n",
						"Fitting estimator with 52 features.\n",
						"Fitting estimator with 52 features.\n",
						"Fitting estimator with 51 features.\n",
						"Fitting estimator with 51 features.\n",
						"Fitting estimator with 51 features.\n",
						"Fitting estimator with 51 features.\n",
						"Fitting estimator with 51 features.\n",
						"Fitting estimator with 50 features.\n",
						"Fitting estimator with 50 features.\n",
						"Fitting estimator with 51 features.\n",
						"Fitting estimator with 50 features.\n",
						"Fitting estimator with 51 features.\n",
						"Fitting estimator with 50 features.\n",
						"Fitting estimator with 50 features.\n",
						"Fitting estimator with 50 features.\n",
						"Fitting estimator with 49 features.\n",
						"Fitting estimator with 49 features.\n",
						"Fitting estimator with 50 features.\n",
						"Fitting estimator with 49 features.\n",
						"Fitting estimator with 50 features.\n",
						"Fitting estimator with 49 features.\n",
						"Fitting estimator with 48 features.\n",
						"Fitting estimator with 48 features.\n",
						"Fitting estimator with 49 features.\n",
						"Fitting estimator with 49 features.\n",
						"Fitting estimator with 49 features.\n",
						"Fitting estimator with 48 features.\n",
						"Fitting estimator with 49 features.\n",
						"Fitting estimator with 47 features.\n",
						"Fitting estimator with 48 features.\n",
						"Fitting estimator with 48 features.\n",
						"Fitting estimator with 47 features.\n",
						"Fitting estimator with 47 features.\n",
						"Fitting estimator with 48 features.\n",
						"Fitting estimator with 48 features.\n",
						"Fitting estimator with 48 features.\n",
						"Fitting estimator with 46 features.\n",
						"Fitting estimator with 47 features.\n",
						"Fitting estimator with 46 features.\n",
						"Fitting estimator with 46 features.\n",
						"Fitting estimator with 47 features.\n",
						"Fitting estimator with 47 features.\n",
						"Fitting estimator with 47 features.\n",
						"Fitting estimator with 47 features.\n",
						"Fitting estimator with 45 features.\n",
						"Fitting estimator with 46 features.\n",
						"Fitting estimator with 45 features.\n",
						"Fitting estimator with 46 features.\n",
						"Fitting estimator with 45 features.\n",
						"Fitting estimator with 46 features.\n",
						"Fitting estimator with 46 features.\n",
						"Fitting estimator with 44 features.\n",
						"Fitting estimator with 46 features.\n",
						"Fitting estimator with 44 features.\n",
						"Fitting estimator with 45 features.\n",
						"Fitting estimator with 45 features.\n",
						"Fitting estimator with 44 features.\n",
						"Fitting estimator with 45 features.\n",
						"Fitting estimator with 45 features.\n",
						"Fitting estimator with 43 features.\n",
						"Fitting estimator with 43 features.\n",
						"Fitting estimator with 45 features.\n",
						"Fitting estimator with 44 features.\n",
						"Fitting estimator with 44 features.\n",
						"Fitting estimator with 43 features.\n",
						"Fitting estimator with 44 features.\n",
						"Fitting estimator with 42 features.\n",
						"Fitting estimator with 44 features.\n",
						"Fitting estimator with 42 features.\n",
						"Fitting estimator with 44 features.\n",
						"Fitting estimator with 43 features.\n",
						"Fitting estimator with 43 features.\n",
						"Fitting estimator with 42 features.\n",
						"Fitting estimator with 43 features.\n",
						"Fitting estimator with 41 features.\n",
						"Fitting estimator with 43 features.\n",
						"Fitting estimator with 41 features.\n",
						"Fitting estimator with 42 features.\n",
						"Fitting estimator with 42 features.\n",
						"Fitting estimator with 43 features.\n",
						"Fitting estimator with 41 features.\n",
						"Fitting estimator with 40 features.\n",
						"Fitting estimator with 42 features.\n",
						"Fitting estimator with 42 features.\n",
						"Fitting estimator with 40 features.\n",
						"Fitting estimator with 41 features.\n",
						"Fitting estimator with 41 features.\n",
						"Fitting estimator with 40 features.\n",
						"Fitting estimator with 39 features.\n",
						"Fitting estimator with 42 features.\n",
						"Fitting estimator with 41 features.\n",
						"Fitting estimator with 39 features.\n",
						"Fitting estimator with 41 features.\n",
						"Fitting estimator with 40 features.\n",
						"Fitting estimator with 40 features.\n",
						"Fitting estimator with 39 features.\n",
						"Fitting estimator with 38 features.\n",
						"Fitting estimator with 40 features.\n",
						"Fitting estimator with 38 features.\n",
						"Fitting estimator with 40 features.\n",
						"Fitting estimator with 41 features.\n",
						"Fitting estimator with 39 features.\n",
						"Fitting estimator with 39 features.\n",
						"Fitting estimator with 37 features.\n",
						"Fitting estimator with 38 features.\n",
						"Fitting estimator with 39 features.\n",
						"Fitting estimator with 37 features.\n",
						"Fitting estimator with 39 features.\n",
						"Fitting estimator with 38 features.\n",
						"Fitting estimator with 38 features.\n",
						"Fitting estimator with 40 features.\n",
						"Fitting estimator with 36 features.\n",
						"Fitting estimator with 37 features.\n",
						"Fitting estimator with 38 features.\n",
						"Fitting estimator with 36 features.\n",
						"Fitting estimator with 38 features.\n",
						"Fitting estimator with 37 features.\n",
						"Fitting estimator with 37 features.\n",
						"Fitting estimator with 36 features.\n",
						"Fitting estimator with 35 features.\n",
						"Fitting estimator with 39 features.\n",
						"Fitting estimator with 37 features.\n",
						"Fitting estimator with 35 features.\n",
						"Fitting estimator with 36 features.\n",
						"Fitting estimator with 35 features.\n",
						"Fitting estimator with 36 features.\n",
						"Fitting estimator with 34 features.\n",
						"Fitting estimator with 37 features.\n",
						"Fitting estimator with 36 features.\n",
						"Fitting estimator with 34 features.\n",
						"Fitting estimator with 38 features.\n",
						"Fitting estimator with 35 features.\n",
						"Fitting estimator with 34 features.\n",
						"Fitting estimator with 33 features.\n",
						"Fitting estimator with 36 features.\n",
						"Fitting estimator with 35 features.\n",
						"Fitting estimator with 35 features.\n",
						"Fitting estimator with 33 features.\n",
						"Fitting estimator with 34 features.\n",
						"Fitting estimator with 32 features.\n",
						"Fitting estimator with 33 features.\n",
						"Fitting estimator with 37 features.\n",
						"Fitting estimator with 35 features.\n",
						"Fitting estimator with 34 features.\n",
						"Fitting estimator with 34 features.\n",
						"Fitting estimator with 32 features.\n",
						"Fitting estimator with 33 features.\n",
						"Fitting estimator with 36 features.\n",
						"Fitting estimator with 31 features.\n",
						"Fitting estimator with 32 features.\n",
						"Fitting estimator with 34 features.\n",
						"Fitting estimator with 33 features.\n",
						"Fitting estimator with 33 features.\n",
						"Fitting estimator with 31 features.\n",
						"Fitting estimator with 32 features.\n",
						"Fitting estimator with 35 features.\n",
						"Fitting estimator with 33 features.\n",
						"Fitting estimator with 31 features.\n",
						"Fitting estimator with 32 features.\n",
						"Fitting estimator with 30 features.\n",
						"Fitting estimator with 30 features.\n",
						"Fitting estimator with 31 features.\n",
						"Fitting estimator with 32 features.\n",
						"Fitting estimator with 34 features.\n",
						"Fitting estimator with 32 features.\n",
						"Fitting estimator with 31 features.\n",
						"Fitting estimator with 29 features.\n",
						"Fitting estimator with 30 features.\n",
						"Fitting estimator with 30 features.\n",
						"Fitting estimator with 29 features.\n",
						"Fitting estimator with 31 features.\n",
						"Fitting estimator with 31 features.\n",
						"Fitting estimator with 30 features.\n",
						"Fitting estimator with 28 features.\n",
						"Fitting estimator with 29 features.\n",
						"Fitting estimator with 28 features.\n",
						"Fitting estimator with 29 features.\n",
						"Fitting estimator with 33 features.\n",
						"Fitting estimator with 30 features.\n",
						"Fitting estimator with 30 features.\n",
						"Fitting estimator with 29 features.\n",
						"Fitting estimator with 27 features.\n",
						"Fitting estimator with 27 features.\n",
						"Fitting estimator with 28 features.\n",
						"Fitting estimator with 29 features.\n",
						"Fitting estimator with 32 features.\n",
						"Fitting estimator with 28 features.\n",
						"Fitting estimator with 29 features.\n",
						"Fitting estimator with 26 features.\n",
						"Fitting estimator with 28 features.\n",
						"Fitting estimator with 26 features.\n",
						"Fitting estimator with 27 features.\n",
						"Fitting estimator with 25 features.\n",
						"Fitting estimator with 28 features.\n",
						"Fitting estimator with 31 features.\n",
						"Fitting estimator with 27 features.\n",
						"Fitting estimator with 28 features.\n",
						"Fitting estimator with 25 features.\n",
						"Fitting estimator with 26 features.\n",
						"Fitting estimator with 27 features.\n",
						"Fitting estimator with 30 features.\n",
						"Fitting estimator with 26 features.\n",
						"Fitting estimator with 24 features.\n",
						"Fitting estimator with 24 features.\n",
						"Fitting estimator with 27 features.\n",
						"Fitting estimator with 27 features.\n",
						"Fitting estimator with 25 features.\n",
						"Fitting estimator with 29 features.\n",
						"Fitting estimator with 23 features.\n",
						"Fitting estimator with 25 features.\n",
						"Fitting estimator with 26 features.\n",
						"Fitting estimator with 24 features.\n",
						"Fitting estimator with 23 features.\n",
						"Fitting estimator with 26 features.\n",
						"Fitting estimator with 26 features.\n",
						"Fitting estimator with 28 features.\n",
						"Fitting estimator with 22 features.\n",
						"Fitting estimator with 24 features.\n",
						"Fitting estimator with 25 features.\n",
						"Fitting estimator with 22 features.\n",
						"Fitting estimator with 23 features.\n",
						"Fitting estimator with 25 features.\n",
						"Fitting estimator with 25 features.\n",
						"Fitting estimator with 27 features.\n",
						"Fitting estimator with 21 features.\n",
						"Fitting estimator with 23 features.\n",
						"Fitting estimator with 21 features.\n",
						"Fitting estimator with 22 features.\n",
						"Fitting estimator with 24 features.\n",
						"Fitting estimator with 24 features.\n",
						"Fitting estimator with 24 features.\n",
						"Fitting estimator with 26 features.\n",
						"Fitting estimator with 20 features.\n",
						"Fitting estimator with 22 features.\n",
						"Fitting estimator with 21 features.\n",
						"Fitting estimator with 20 features.\n",
						"Fitting estimator with 23 features.\n",
						"Fitting estimator with 19 features.\n",
						"Fitting estimator with 25 features.\n",
						"Fitting estimator with 23 features.\n",
						"Fitting estimator with 23 features.\n",
						"Fitting estimator with 21 features.\n",
						"Fitting estimator with 20 features.\n",
						"Fitting estimator with 19 features.\n",
						"Fitting estimator with 18 features.\n",
						"Fitting estimator with 22 features.\n",
						"Fitting estimator with 24 features.\n",
						"Fitting estimator with 19 features.\n",
						"Fitting estimator with 18 features.\n",
						"Fitting estimator with 17 features.\n",
						"Fitting estimator with 22 features.\n",
						"Fitting estimator with 20 features.\n",
						"Fitting estimator with 22 features.\n",
						"Fitting estimator with 23 features.\n",
						"Fitting estimator with 21 features.\n",
						"Fitting estimator with 18 features.\n",
						"Fitting estimator with 16 features.\n",
						"Fitting estimator with 17 features.\n",
						"Fitting estimator with 21 features.\n",
						"Fitting estimator with 19 features.\n",
						"Fitting estimator with 21 features.\n",
						"Fitting estimator with 15 features.\n",
						"Fitting estimator with 22 features.\n",
						"Fitting estimator with 16 features.\n",
						"Fitting estimator with 17 features.\n",
						"Fitting estimator with 20 features.\n",
						"Fitting estimator with 18 features.\n",
						"Fitting estimator with 15 features.\n",
						"Fitting estimator with 14 features.\n",
						"Fitting estimator with 16 features.\n",
						"Fitting estimator with 21 features.\n",
						"Fitting estimator with 20 features.\n",
						"Fitting estimator with 20 features.\n",
						"Fitting estimator with 17 features.\n",
						"Fitting estimator with 13 features.\n",
						"Fitting estimator with 19 features.\n",
						"Fitting estimator with 14 features.\n",
						"Fitting estimator with 15 features.\n",
						"Fitting estimator with 20 features.\n",
						"Fitting estimator with 12 features.\n",
						"Fitting estimator with 16 features.\n",
						"Fitting estimator with 13 features.\n",
						"Fitting estimator with 19 features.\n",
						"Fitting estimator with 11 features.\n",
						"Fitting estimator with 14 features.\n",
						"Fitting estimator with 18 features.\n",
						"Fitting estimator with 12 features.\n",
						"Fitting estimator with 19 features.\n",
						"Fitting estimator with 15 features.\n",
						"Fitting estimator with 10 features.\n",
						"Fitting estimator with 19 features.\n",
						"Fitting estimator with 11 features.\n",
						"Fitting estimator with 18 features.\n",
						"Fitting estimator with 9 features.\n",
						"Fitting estimator with 14 features.\n",
						"Fitting estimator with 10 features.\n",
						"Fitting estimator with 13 features.\n",
						"Fitting estimator with 18 features.\n",
						"Fitting estimator with 17 features.\n",
						"Fitting estimator with 8 features.\n",
						"Fitting estimator with 18 features.\n",
						"Fitting estimator with 9 features.\n",
						"Fitting estimator with 7 features.\n",
						"Fitting estimator with 13 features.\n",
						"Fitting estimator with 8 features.\n",
						"Fitting estimator with 12 features.\n",
						"Fitting estimator with 6 features.\n",
						"Fitting estimator with 7 features.\n",
						"Fitting estimator with 5 features.\n",
						"Fitting estimator with 17 features.\n",
						"Fitting estimator with 16 features.\n",
						"Fitting estimator with 17 features.\n",
						"Fitting estimator with 4 features.\n",
						"Fitting estimator with 6 features.\n",
						"Fitting estimator with 12 features.\n",
						"Fitting estimator with 17 features.\n",
						"Fitting estimator with 11 features.\n",
						"Fitting estimator with 3 features.\n",
						"Fitting estimator with 5 features.\n",
						"Fitting estimator with 2 features.\n",
						"Fitting estimator with 4 features.\n",
						"Fitting estimator with 3 features.\n",
						"Fitting estimator with 2 features.\n",
						"Fitting estimator with 11 features.\n",
						"Fitting estimator with 10 features.\n",
						"Fitting estimator with 57 features.\n",
						"Fitting estimator with 15 features.\n",
						"Fitting estimator with 16 features.\n",
						"Fitting estimator with 10 features.\n",
						"Fitting estimator with 57 features.\n",
						"Fitting estimator with 9 features.\n",
						"Fitting estimator with 16 features.\n",
						"Fitting estimator with 9 features.\n",
						"Fitting estimator with 16 features.\n",
						"Fitting estimator with 8 features.\n",
						"Fitting estimator with 14 features.\n",
						"Fitting estimator with 8 features.\n",
						"Fitting estimator with 7 features.\n",
						"Fitting estimator with 15 features.\n",
						"Fitting estimator with 7 features.\n",
						"Fitting estimator with 15 features.\n",
						"Fitting estimator with 6 features.\n",
						"Fitting estimator with 56 features.\n",
						"Fitting estimator with 56 features.Fitting estimator with 15 features.\n",
						"\n",
						"Fitting estimator with 6 features.\n",
						"Fitting estimator with 13 features.\n",
						"Fitting estimator with 5 features.\n",
						"Fitting estimator with 5 features.\n",
						"Fitting estimator with 4 features.\n",
						"Fitting estimator with 14 features.\n",
						"Fitting estimator with 4 features.\n",
						"Fitting estimator with 14 features.\n",
						"Fitting estimator with 12 features.\n",
						"Fitting estimator with 3 features.\n",
						"Fitting estimator with 3 features.\n",
						"Fitting estimator with 14 features.\n",
						"Fitting estimator with 13 features.\n",
						"Fitting estimator with 2 features.\n",
						"Fitting estimator with 55 features.\n",
						"Fitting estimator with 2 features.\n",
						"Fitting estimator with 11 features.\n",
						"Fitting estimator with 13 features.\n",
						"Fitting estimator with 12 features.\n",
						"Fitting estimator with 10 features.\n",
						"Fitting estimator with 55 features.\n",
						"Fitting estimator with 11 features.\n",
						"Fitting estimator with 13 features.\n",
						"Fitting estimator with 54 features.\n",
						"Fitting estimator with 57 features.\n",
						"Fitting estimator with 10 features.\n",
						"Fitting estimator with 9 features.\n",
						"Fitting estimator with 9 features.\n",
						"Fitting estimator with 8 features.\n",
						"Fitting estimator with 57 features.\n",
						"Fitting estimator with 12 features.\n",
						"Fitting estimator with 8 features.\n",
						"Fitting estimator with 54 features.\n",
						"Fitting estimator with 12 features.\n",
						"Fitting estimator with 7 features.\n",
						"Fitting estimator with 7 features.\n",
						"Fitting estimator with 6 features.\n",
						"Fitting estimator with 5 features.\n",
						"Fitting estimator with 11 features.\n",
						"Fitting estimator with 11 features.\n",
						"Fitting estimator with 4 features.\n",
						"Fitting estimator with 6 features.\n",
						"Fitting estimator with 3 features.\n",
						"Fitting estimator with 2 features.\n",
						"Fitting estimator with 53 features.\n",
						"Fitting estimator with 10 features.\n",
						"Fitting estimator with 56 features.\n",
						"Fitting estimator with 5 features.\n",
						"Fitting estimator with 10 features.\n",
						"Fitting estimator with 57 features.\n",
						"Fitting estimator with 4 features.\n",
						"Fitting estimator with 9 features.\n",
						"Fitting estimator with 53 features.\n",
						"Fitting estimator with 3 features.\n",
						"Fitting estimator with 2 features.\n",
						"Fitting estimator with 9 features.\n",
						"Fitting estimator with 56 features.\n",
						"Fitting estimator with 8 features.\n",
						"Fitting estimator with 8 features.\n",
						"Fitting estimator with 7 features.\n",
						"Fitting estimator with 57 features.\n",
						"Fitting estimator with 52 features.\n",
						"Fitting estimator with 6 features.\n",
						"Fitting estimator with 7 features.\n",
						"Fitting estimator with 5 features.\n",
						"Fitting estimator with 4 features.\n",
						"Fitting estimator with 3 features.\n",
						"Fitting estimator with 2 features.\n",
						"Fitting estimator with 6 features.\n",
						"Fitting estimator with 5 features.\n",
						"Fitting estimator with 56 features.\n",
						"Fitting estimator with 52 features.\n",
						"Fitting estimator with 55 features.\n",
						"Fitting estimator with 4 features.\n",
						"Fitting estimator with 57 features.\n",
						"Fitting estimator with 3 features.\n",
						"Fitting estimator with 55 features.\n",
						"Fitting estimator with 2 features.\n",
						"Fitting estimator with 51 features.\n",
						"Fitting estimator with 56 features.\n",
						"Fitting estimator with 51 features.\n",
						"Fitting estimator with 55 features.\n",
						"Fitting estimator with 54 features.\n",
						"Fitting estimator with 56 features.Fitting estimator with 54 features.\n",
						"\n",
						"Fitting estimator with 50 features.\n",
						"Fitting estimator with 55 features.\n",
						"Fitting estimator with 50 features.\n",
						"Fitting estimator with 53 features.\n",
						"Fitting estimator with 54 features.\n",
						"Fitting estimator with 53 features.\n",
						"Fitting estimator with 49 features.\n",
						"Fitting estimator with 55 features.\n",
						"Fitting estimator with 54 features.\n",
						"Fitting estimator with 52 features.\n",
						"Fitting estimator with 49 features.\n",
						"Fitting estimator with 53 features.\n",
						"Fitting estimator with 48 features.\n",
						"Fitting estimator with 52 features.\n",
						"Fitting estimator with 54 features.\n",
						"Fitting estimator with 53 features.\n",
						"Fitting estimator with 51 features.\n",
						"Fitting estimator with 48 features.\n",
						"Fitting estimator with 52 features.\n",
						"Fitting estimator with 47 features.\n",
						"Fitting estimator with 51 features.Fitting estimator with 53 features.\n",
						"\n",
						"Fitting estimator with 52 features.\n",
						"Fitting estimator with 50 features.\n",
						"Fitting estimator with 47 features.\n",
						"Fitting estimator with 46 features.\n",
						"Fitting estimator with 51 features.\n",
						"Fitting estimator with 50 features.\n",
						"Fitting estimator with 52 features.\n",
						"Fitting estimator with 51 features.\n",
						"Fitting estimator with 49 features.\n",
						"Fitting estimator with 45 features.\n",
						"Fitting estimator with 46 features.\n",
						"Fitting estimator with 49 features.\n",
						"Fitting estimator with 51 features.\n",
						"Fitting estimator with 50 features.\n",
						"Fitting estimator with 48 features.\n",
						"Fitting estimator with 50 features.\n",
						"Fitting estimator with 44 features.\n",
						"Fitting estimator with 45 features.\n",
						"Fitting estimator with 48 features.\n",
						"Fitting estimator with 50 features.\n",
						"Fitting estimator with 49 features.\n",
						"Fitting estimator with 47 features.\n",
						"Fitting estimator with 49 features.\n",
						"Fitting estimator with 43 features.\n",
						"Fitting estimator with 44 features.\n",
						"Fitting estimator with 47 features.\n",
						"Fitting estimator with 48 features.\n",
						"Fitting estimator with 49 features.\n",
						"Fitting estimator with 46 features.\n",
						"Fitting estimator with 48 features.\n",
						"Fitting estimator with 42 features.\n",
						"Fitting estimator with 46 features.\n",
						"Fitting estimator with 43 features.\n",
						"Fitting estimator with 47 features.\n",
						"Fitting estimator with 45 features.\n",
						"Fitting estimator with 48 features.\n",
						"Fitting estimator with 47 features.\n",
						"Fitting estimator with 41 features.\n",
						"Fitting estimator with 45 features.\n",
						"Fitting estimator with 42 features.\n",
						"Fitting estimator with 46 features.\n",
						"Fitting estimator with 44 features.\n",
						"Fitting estimator with 46 features.\n",
						"Fitting estimator with 47 features.\n",
						"Fitting estimator with 40 features.\n",
						"Fitting estimator with 44 features.\n",
						"Fitting estimator with 41 features.\n",
						"Fitting estimator with 43 features.\n",
						"Fitting estimator with 45 features.\n",
						"Fitting estimator with 45 features.\n",
						"Fitting estimator with 46 features.\n",
						"Fitting estimator with 39 features.\n",
						"Fitting estimator with 43 features.\n",
						"Fitting estimator with 40 features.\n",
						"Fitting estimator with 42 features.\n",
						"Fitting estimator with 44 features.\n",
						"Fitting estimator with 44 features.\n",
						"Fitting estimator with 38 features.\n",
						"Fitting estimator with 45 features.\n",
						"Fitting estimator with 42 features.\n",
						"Fitting estimator with 39 features.\n",
						"Fitting estimator with 41 features.\n",
						"Fitting estimator with 43 features.\n",
						"Fitting estimator with 43 features.\n",
						"Fitting estimator with 37 features.\n",
						"Fitting estimator with 41 features.\n",
						"Fitting estimator with 44 features.\n",
						"Fitting estimator with 38 features.\n",
						"Fitting estimator with 40 features.\n",
						"Fitting estimator with 42 features.\n",
						"Fitting estimator with 42 features.\n",
						"Fitting estimator with 36 features.\n",
						"Fitting estimator with 40 features.\n",
						"Fitting estimator with 43 features.\n",
						"Fitting estimator with 37 features.\n",
						"Fitting estimator with 39 features.\n",
						"Fitting estimator with 41 features.\n",
						"Fitting estimator with 41 features.\n",
						"Fitting estimator with 35 features.\n",
						"Fitting estimator with 42 features.\n",
						"Fitting estimator with 39 features.\n",
						"Fitting estimator with 36 features.\n",
						"Fitting estimator with 38 features.\n",
						"Fitting estimator with 40 features.\n",
						"Fitting estimator with 40 features.\n",
						"Fitting estimator with 34 features.\n",
						"Fitting estimator with 41 features.\n",
						"Fitting estimator with 38 features.\n",
						"Fitting estimator with 37 features.\n",
						"Fitting estimator with 35 features.\n",
						"Fitting estimator with 39 features.\n",
						"Fitting estimator with 39 features.\n",
						"Fitting estimator with 33 features.\n",
						"Fitting estimator with 40 features.\n",
						"Fitting estimator with 37 features.\n",
						"Fitting estimator with 36 features.\n",
						"Fitting estimator with 34 features.\n",
						"Fitting estimator with 38 features.\n",
						"Fitting estimator with 38 features.\n",
						"Fitting estimator with 32 features.\n",
						"Fitting estimator with 36 features.\n",
						"Fitting estimator with 35 features.\n",
						"Fitting estimator with 39 features.\n",
						"Fitting estimator with 33 features.\n",
						"Fitting estimator with 37 features.\n",
						"Fitting estimator with 31 features.\n",
						"Fitting estimator with 37 features.\n",
						"Fitting estimator with 34 features.\n",
						"Fitting estimator with 35 features.\n",
						"Fitting estimator with 32 features.\n",
						"Fitting estimator with 38 features.\n",
						"Fitting estimator with 30 features.\n",
						"Fitting estimator with 36 features.\n",
						"Fitting estimator with 34 features.\n",
						"Fitting estimator with 33 features.\n",
						"Fitting estimator with 36 features.\n",
						"Fitting estimator with 31 features.\n",
						"Fitting estimator with 37 features.\n",
						"Fitting estimator with 29 features.\n",
						"Fitting estimator with 35 features.\n",
						"Fitting estimator with 33 features.\n",
						"Fitting estimator with 32 features.\n",
						"Fitting estimator with 35 features.\n",
						"Fitting estimator with 30 features.\n",
						"Fitting estimator with 36 features.\n",
						"Fitting estimator with 28 features.\n",
						"Fitting estimator with 34 features.\n",
						"Fitting estimator with 32 features.\n",
						"Fitting estimator with 31 features.\n",
						"Fitting estimator with 34 features.\n",
						"Fitting estimator with 29 features.\n",
						"Fitting estimator with 27 features.\n",
						"Fitting estimator with 33 features.\n",
						"Fitting estimator with 35 features.\n",
						"Fitting estimator with 31 features.\n",
						"Fitting estimator with 33 features.\n",
						"Fitting estimator with 30 features.\n",
						"Fitting estimator with 28 features.\n",
						"Fitting estimator with 32 features.\n",
						"Fitting estimator with 26 features.\n",
						"Fitting estimator with 34 features.\n",
						"Fitting estimator with 32 features.\n",
						"Fitting estimator with 30 features.\n",
						"Fitting estimator with 29 features.\n",
						"Fitting estimator with 27 features.\n",
						"Fitting estimator with 25 features.\n",
						"Fitting estimator with 31 features.\n",
						"Fitting estimator with 33 features.\n",
						"Fitting estimator with 31 features.\n",
						"Fitting estimator with 29 features.\n",
						"Fitting estimator with 28 features.\n",
						"Fitting estimator with 26 features.\n",
						"Fitting estimator with 24 features.\n",
						"Fitting estimator with 30 features.\n",
						"Fitting estimator with 32 features.\n",
						"Fitting estimator with 30 features.\n",
						"Fitting estimator with 28 features.\n",
						"Fitting estimator with 27 features.\n",
						"Fitting estimator with 25 features.\n",
						"Fitting estimator with 29 features.\n",
						"Fitting estimator with 23 features.\n",
						"Fitting estimator with 26 features.\n",
						"Fitting estimator with 31 features.\n",
						"Fitting estimator with 27 features.\n",
						"Fitting estimator with 29 features.\n",
						"Fitting estimator with 24 features.\n",
						"Fitting estimator with 28 features.\n",
						"Fitting estimator with 25 features.\n",
						"Fitting estimator with 22 features.\n",
						"Fitting estimator with 28 features.\n",
						"Fitting estimator with 30 features.\n",
						"Fitting estimator with 26 features.\n",
						"Fitting estimator with 23 features.\n",
						"Fitting estimator with 27 features.\n",
						"Fitting estimator with 24 features.\n",
						"Fitting estimator with 21 features.\n",
						"Fitting estimator with 27 features.\n",
						"Fitting estimator with 25 features.\n",
						"Fitting estimator with 29 features.\n",
						"Fitting estimator with 22 features.\n",
						"Fitting estimator with 26 features.\n",
						"Fitting estimator with 23 features.\n",
						"Fitting estimator with 26 features.\n",
						"Fitting estimator with 20 features.\n",
						"Fitting estimator with 24 features.\n",
						"Fitting estimator with 21 features.\n",
						"Fitting estimator with 25 features.\n",
						"Fitting estimator with 28 features.\n",
						"Fitting estimator with 22 features.\n",
						"Fitting estimator with 25 features.\n",
						"Fitting estimator with 23 features.\n",
						"Fitting estimator with 20 features.\n",
						"Fitting estimator with 19 features.\n",
						"Fitting estimator with 24 features.\n",
						"Fitting estimator with 21 features.\n",
						"Fitting estimator with 27 features.\n",
						"Fitting estimator with 24 features.\n",
						"Fitting estimator with 19 features.\n",
						"Fitting estimator with 18 features.\n",
						"Fitting estimator with 22 features.\n",
						"Fitting estimator with 23 features.\n",
						"Fitting estimator with 20 features.\n",
						"Fitting estimator with 26 features.\n",
						"Fitting estimator with 17 features.\n",
						"Fitting estimator with 23 features.\n",
						"Fitting estimator with 18 features.\n",
						"Fitting estimator with 21 features.\n",
						"Fitting estimator with 22 features.\n",
						"Fitting estimator with 19 features.\n",
						"Fitting estimator with 16 features.\n",
						"Fitting estimator with 22 features.\n",
						"Fitting estimator with 17 features.\n",
						"Fitting estimator with 25 features.\n",
						"Fitting estimator with 21 features.\n",
						"Fitting estimator with 18 features.\n",
						"Fitting estimator with 20 features.\n",
						"Fitting estimator with 15 features.\n",
						"Fitting estimator with 16 features.\n",
						"Fitting estimator with 24 features.\n",
						"Fitting estimator with 14 features.\n",
						"Fitting estimator with 21 features.\n",
						"Fitting estimator with 20 features.\n",
						"Fitting estimator with 17 features.\n",
						"Fitting estimator with 19 features.\n",
						"Fitting estimator with 15 features.\n",
						"Fitting estimator with 13 features.\n",
						"Fitting estimator with 16 features.\n",
						"Fitting estimator with 19 features.\n",
						"Fitting estimator with 20 features.\n",
						"Fitting estimator with 23 features.\n",
						"Fitting estimator with 12 features.\n",
						"Fitting estimator with 18 features.\n",
						"Fitting estimator with 14 features.\n",
						"Fitting estimator with 15 features.\n",
						"Fitting estimator with 11 features.\n",
						"Fitting estimator with 18 features.\n",
						"Fitting estimator with 19 features.\n",
						"Fitting estimator with 13 features.\n",
						"Fitting estimator with 10 features.\n",
						"Fitting estimator with 17 features.\n",
						"Fitting estimator with 22 features.\n",
						"Fitting estimator with 14 features.\n",
						"Fitting estimator with 9 features.\n",
						"Fitting estimator with 17 features.\n",
						"Fitting estimator with 8 features.\n",
						"Fitting estimator with 12 features.\n",
						"Fitting estimator with 18 features.\n",
						"Fitting estimator with 7 features.\n",
						"Fitting estimator with 13 features.\n",
						"Fitting estimator with 16 features.\n",
						"Fitting estimator with 6 features.\n",
						"Fitting estimator with 21 features.\n",
						"Fitting estimator with 16 features.\n",
						"Fitting estimator with 5 features.\n",
						"Fitting estimator with 11 features.\n",
						"Fitting estimator with 4 features.\n",
						"Fitting estimator with 3 features.\n",
						"Fitting estimator with 12 features.\n",
						"Fitting estimator with 2 features.\n",
						"Fitting estimator with 15 features.Fitting estimator with 17 features.\n",
						"\n",
						"Fitting estimator with 10 features.\n",
						"Fitting estimator with 15 features.\n",
						"Fitting estimator with 11 features.\n",
						"Fitting estimator with 20 features.\n",
						"Fitting estimator with 9 features.\n",
						"Fitting estimator with 14 features.\n",
						"Fitting estimator with 16 features.\n",
						"Fitting estimator with 10 features.\n",
						"Fitting estimator with 14 features.\n",
						"Fitting estimator with 8 features.\n",
						"Fitting estimator with 9 features.\n",
						"Fitting estimator with 7 features.\n",
						"Fitting estimator with 19 features.\n",
						"Fitting estimator with 13 features.\n",
						"Fitting estimator with 8 features.\n",
						"Fitting estimator with 15 features.\n",
						"Fitting estimator with 6 features.\n",
						"Fitting estimator with 13 features.\n",
						"Fitting estimator with 7 features.\n",
						"Fitting estimator with 5 features.\n",
						"Fitting estimator with 4 features.\n",
						"Fitting estimator with 6 features.\n",
						"Fitting estimator with 12 features.\n",
						"Fitting estimator with 3 features.\n",
						"Fitting estimator with 2 features.\n",
						"Fitting estimator with 5 features.\n",
						"Fitting estimator with 12 features.Fitting estimator with 4 features.\n",
						"\n",
						"Fitting estimator with 14 features.\n",
						"Fitting estimator with 18 features.\n",
						"Fitting estimator with 3 features.\n",
						"Fitting estimator with 2 features.\n",
						"Fitting estimator with 11 features.\n",
						"Fitting estimator with 11 features.\n",
						"Fitting estimator with 13 features.\n",
						"Fitting estimator with 10 features.\n",
						"Fitting estimator with 17 features.\n",
						"Fitting estimator with 10 features.\n",
						"Fitting estimator with 12 features.\n",
						"Fitting estimator with 9 features.\n",
						"Fitting estimator with 8 features.\n",
						"Fitting estimator with 16 features.\n",
						"Fitting estimator with 9 features.\n",
						"Fitting estimator with 11 features.\n",
						"Fitting estimator with 7 features.\n",
						"Fitting estimator with 6 features.\n",
						"Fitting estimator with 8 features.\n",
						"Fitting estimator with 15 features.\n",
						"Fitting estimator with 5 features.\n",
						"Fitting estimator with 10 features.\n",
						"Fitting estimator with 4 features.\n",
						"Fitting estimator with 3 features.\n",
						"Fitting estimator with 7 features.\n",
						"Fitting estimator with 2 features.\n",
						"Fitting estimator with 9 features.\n",
						"Fitting estimator with 14 features.\n",
						"Fitting estimator with 8 features.\n",
						"Fitting estimator with 6 features.\n",
						"Fitting estimator with 7 features.\n",
						"Fitting estimator with 5 features.\n",
						"Fitting estimator with 6 features.\n",
						"Fitting estimator with 13 features.\n",
						"Fitting estimator with 5 features.\n",
						"Fitting estimator with 4 features.\n",
						"Fitting estimator with 4 features.\n",
						"Fitting estimator with 3 features.\n",
						"Fitting estimator with 2 features.\n",
						"Fitting estimator with 12 features.\n",
						"Fitting estimator with 3 features.\n",
						"Fitting estimator with 11 features.\n",
						"Fitting estimator with 2 features.\n",
						"Fitting estimator with 10 features.\n",
						"Fitting estimator with 9 features.\n",
						"Fitting estimator with 8 features.\n",
						"Fitting estimator with 7 features.\n",
						"Fitting estimator with 6 features.\n",
						"Fitting estimator with 5 features.\n",
						"Fitting estimator with 4 features.\n",
						"Fitting estimator with 3 features.\n",
						"Fitting estimator with 2 features.\n",
						"Fitting estimator with 57 features.\n",
						"Fitting estimator with 56 features.\n",
						"Fitting estimator with 55 features.\n",
						"Fitting estimator with 54 features.\n",
						"Fitting estimator with 53 features.\n",
						"Fitting estimator with 52 features.\n",
						"Fitting estimator with 51 features.\n",
						"Fitting estimator with 50 features.\n",
						"Fitting estimator with 49 features.\n",
						"Fitting estimator with 48 features.\n",
						"Fitting estimator with 47 features.\n",
						"Fitting estimator with 46 features.\n",
						"Fitting estimator with 45 features.\n",
						"Fitting estimator with 44 features.\n",
						"Fitting estimator with 43 features.\n",
						"Fitting estimator with 42 features.\n",
						"Fitting estimator with 41 features.\n",
						"Fitting estimator with 40 features.\n",
						"Fitting estimator with 39 features.\n",
						"Fitting estimator with 38 features.\n",
						"Fitting estimator with 37 features.\n",
						"Fitting estimator with 36 features.\n",
						"Fitting estimator with 35 features.\n",
						"Fitting estimator with 34 features.\n",
						"Fitting estimator with 33 features.\n",
						"Fitting estimator with 32 features.\n",
						"Fitting estimator with 31 features.\n",
						"Fitting estimator with 30 features.\n",
						"Fitting estimator with 29 features.\n",
						"Fitting estimator with 28 features.\n",
						"Fitting estimator with 27 features.\n",
						"Fitting estimator with 26 features.\n",
						"Fitting estimator with 25 features.\n",
						"Fitting estimator with 24 features.\n",
						"Fitting estimator with 23 features.\n",
						"Fitting estimator with 22 features.\n",
						"Optimal number of features: 21\n",
						"Optimal features: ['dechallenge_no', 'dechallenge_yes', 'rechallenge_yes', 'severity_fatal', 'num_suspected_drugs_1', 'patient_age', 'patient_weight_kg', 'patient_height_cm', 'patient_bmi', 'rifampicin_start_to_onset_days', 'rifampicin_stop_to_onset_days', 'rifampicin_start_stop_difference', 'isoniazid_start_to_onset_days', 'isoniazid_stop_to_onset_days', 'isoniazid_start_stop_difference', 'pyrazinamide_start_to_onset_days', 'pyrazinamide_stop_to_onset_days', 'pyrazinamide_start_stop_difference', 'ethambutol_start_to_onset_days', 'ethambutol_stop_to_onset_days', 'ethambutol_start_stop_difference']\n"
					]
				}
			],
			"source": [
				"from sklearn.feature_selection import RFECV\n",
				"from sklearn.model_selection import RepeatedStratifiedKFold\n",
				"from sklearn.tree import DecisionTreeClassifier\n",
				"\n",
				"rfecv_cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=42)\n",
				"\n",
				"rfecv = RFECV(\n",
				"    estimator=DecisionTreeClassifier(),\n",
				"    step=1,\n",
				"    min_features_to_select=1,\n",
				"    cv=rfecv_cv,\n",
				"    scoring=\"f1_weighted\",\n",
				"    n_jobs=-1,\n",
				"    verbose=2,\n",
				")\n",
				"\n",
				"\n",
				"rfecv.fit(X_train_final, y_train_encoded)\n",
				"\n",
				"print(f\"Optimal number of features: {rfecv.n_features_}\")\n",
				"print(f\"Optimal features: {list(rfecv.get_feature_names_out())}\")\n",
				"\n",
				"prediction_columns = list(rfecv.get_feature_names_out())\n",
				"# print(rfecv.cv_results_)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 22,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"decision_tree\n",
						"------------------------------------------------------------------------------------------------------------------------------------------------------\n",
						"Fitting 15 folds for each of 3 candidates, totalling 45 fits\n",
						"[CV] END .......................................max_depth=25; total time=   0.1s\n",
						"[CV] END .......................................max_depth=25; total time=   0.1s\n",
						"[CV] END .......................................max_depth=25; total time=   0.1s\n",
						"[CV] END .......................................max_depth=25; total time=   0.1s\n",
						"[CV] END .......................................max_depth=25; total time=   0.2s\n",
						"[CV] END .......................................max_depth=25; total time=   0.2s\n",
						"[CV] END .......................................max_depth=25; total time=   0.2s\n",
						"[CV] END .......................................max_depth=25; total time=   0.2s\n",
						"[CV] END .......................................max_depth=25; total time=   0.1s\n",
						"[CV] END .......................................max_depth=25; total time=   0.1s\n",
						"[CV] END .......................................max_depth=25; total time=   0.1s\n",
						"[CV] END .......................................max_depth=25; total time=   0.2s\n",
						"[CV] END .......................................max_depth=25; total time=   0.1s\n",
						"[CV] END .......................................max_depth=25; total time=   0.1s\n",
						"[CV] END .......................................max_depth=25; total time=   0.2s\n",
						"[CV] END .......................................max_depth=50; total time=   0.2s\n",
						"[CV] END .......................................max_depth=50; total time=   0.1s\n",
						"[CV] END .......................................max_depth=50; total time=   0.1s\n",
						"[CV] END .......................................max_depth=50; total time=   0.1s\n",
						"[CV] END .......................................max_depth=50; total time=   0.1s\n",
						"[CV] END .......................................max_depth=50; total time=   0.1s\n",
						"[CV] END .......................................max_depth=50; total time=   0.1s\n",
						"[CV] END .......................................max_depth=50; total time=   0.1s\n",
						"[CV] END .......................................max_depth=50; total time=   0.2s\n",
						"[CV] END .......................................max_depth=50; total time=   0.1s\n",
						"[CV] END .......................................max_depth=50; total time=   0.1s\n",
						"[CV] END .......................................max_depth=50; total time=   0.1s\n",
						"[CV] END .......................................max_depth=50; total time=   0.1s\n",
						"[CV] END .......................................max_depth=50; total time=   0.1s\n",
						"[CV] END .......................................max_depth=50; total time=   0.1s\n",
						"[CV] END ......................................max_depth=100; total time=   0.1s\n",
						"[CV] END ......................................max_depth=100; total time=   0.1s\n",
						"[CV] END ......................................max_depth=100; total time=   0.1s\n",
						"[CV] END ......................................max_depth=100; total time=   0.1s\n",
						"[CV] END ......................................max_depth=100; total time=   0.1s\n",
						"[CV] END ......................................max_depth=100; total time=   0.1s\n",
						"[CV] END ......................................max_depth=100; total time=   0.1s\n",
						"[CV] END ......................................max_depth=100; total time=   0.1s\n",
						"[CV] END ......................................max_depth=100; total time=   0.1s\n",
						"[CV] END ......................................max_depth=100; total time=   0.1s\n",
						"[CV] END ......................................max_depth=100; total time=   0.1s\n",
						"[CV] END ......................................max_depth=100; total time=   0.1s\n",
						"[CV] END ......................................max_depth=100; total time=   0.1s\n",
						"[CV] END ......................................max_depth=100; total time=   0.1s\n",
						"[CV] END ......................................max_depth=100; total time=   0.1s\n",
						"----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
						"ada_boost\n",
						"------------------------------------------------------------------------------------------------------------------------------------------------------\n",
						"Fitting 15 folds for each of 4 candidates, totalling 60 fits\n",
						"[CV] END .................learning_rate=0.1, n_estimators=10; total time=   0.2s\n",
						"[CV] END .................learning_rate=0.1, n_estimators=10; total time=   0.2s\n",
						"[CV] END .................learning_rate=0.1, n_estimators=10; total time=   0.2s\n",
						"[CV] END .................learning_rate=0.1, n_estimators=10; total time=   0.2s\n",
						"[CV] END .................learning_rate=0.1, n_estimators=10; total time=   0.2s\n",
						"[CV] END .................learning_rate=0.1, n_estimators=10; total time=   0.2s\n",
						"[CV] END .................learning_rate=0.1, n_estimators=10; total time=   0.2s\n",
						"[CV] END .................learning_rate=0.1, n_estimators=10; total time=   0.3s\n",
						"[CV] END .................learning_rate=0.1, n_estimators=10; total time=   0.2s\n",
						"[CV] END .................learning_rate=0.1, n_estimators=10; total time=   0.2s\n",
						"[CV] END .................learning_rate=0.1, n_estimators=10; total time=   0.2s\n",
						"[CV] END .................learning_rate=0.1, n_estimators=10; total time=   0.3s\n",
						"[CV] END .................learning_rate=0.1, n_estimators=10; total time=   0.2s\n",
						"[CV] END .................learning_rate=0.1, n_estimators=10; total time=   0.3s\n",
						"[CV] END .................learning_rate=0.1, n_estimators=10; total time=   0.3s\n",
						"[CV] END .................learning_rate=0.1, n_estimators=50; total time=   1.1s\n",
						"[CV] END .................learning_rate=0.1, n_estimators=50; total time=   1.0s\n",
						"[CV] END .................learning_rate=0.1, n_estimators=50; total time=   1.0s\n",
						"[CV] END .................learning_rate=0.1, n_estimators=50; total time=   1.1s\n",
						"[CV] END .................learning_rate=0.1, n_estimators=50; total time=   1.0s\n",
						"[CV] END .................learning_rate=0.1, n_estimators=50; total time=   1.0s\n",
						"[CV] END .................learning_rate=0.1, n_estimators=50; total time=   1.0s\n",
						"[CV] END .................learning_rate=0.1, n_estimators=50; total time=   1.3s\n",
						"[CV] END .................learning_rate=1.0, n_estimators=10; total time=   0.2s\n",
						"[CV] END .................learning_rate=1.0, n_estimators=10; total time=   0.3s\n",
						"[CV] END .................learning_rate=0.1, n_estimators=50; total time=   0.9s\n",
						"[CV] END .................learning_rate=1.0, n_estimators=10; total time=   0.2s\n",
						"[CV] END .................learning_rate=0.1, n_estimators=50; total time=   0.9s\n",
						"[CV] END .................learning_rate=0.1, n_estimators=50; total time=   1.1s\n",
						"[CV] END .................learning_rate=0.1, n_estimators=50; total time=   1.0s\n",
						"[CV] END .................learning_rate=1.0, n_estimators=10; total time=   0.2s\n",
						"[CV] END .................learning_rate=0.1, n_estimators=50; total time=   1.1s\n",
						"[CV] END .................learning_rate=0.1, n_estimators=50; total time=   1.0s\n",
						"[CV] END .................learning_rate=1.0, n_estimators=10; total time=   0.2s\n",
						"[CV] END .................learning_rate=0.1, n_estimators=50; total time=   1.2s\n",
						"[CV] END .................learning_rate=1.0, n_estimators=10; total time=   0.2s\n",
						"[CV] END .................learning_rate=1.0, n_estimators=10; total time=   0.2s\n",
						"[CV] END .................learning_rate=1.0, n_estimators=10; total time=   0.2s\n",
						"[CV] END .................learning_rate=1.0, n_estimators=10; total time=   0.2s\n",
						"[CV] END .................learning_rate=1.0, n_estimators=10; total time=   0.2s\n",
						"[CV] END .................learning_rate=1.0, n_estimators=10; total time=   0.3s\n",
						"[CV] END .................learning_rate=1.0, n_estimators=10; total time=   0.3s\n",
						"[CV] END .................learning_rate=1.0, n_estimators=10; total time=   0.3s\n",
						"[CV] END .................learning_rate=1.0, n_estimators=10; total time=   0.2s\n",
						"[CV] END .................learning_rate=1.0, n_estimators=10; total time=   0.3s\n",
						"[CV] END .................learning_rate=1.0, n_estimators=50; total time=   1.2s\n",
						"[CV] END .................learning_rate=1.0, n_estimators=50; total time=   1.2s\n",
						"[CV] END .................learning_rate=1.0, n_estimators=50; total time=   1.2s\n",
						"[CV] END .................learning_rate=1.0, n_estimators=50; total time=   1.3s\n",
						"[CV] END .................learning_rate=1.0, n_estimators=50; total time=   1.3s\n",
						"[CV] END .................learning_rate=1.0, n_estimators=50; total time=   1.3s\n",
						"[CV] END .................learning_rate=1.0, n_estimators=50; total time=   1.5s\n",
						"[CV] END .................learning_rate=1.0, n_estimators=50; total time=   1.3s\n",
						"[CV] END .................learning_rate=1.0, n_estimators=50; total time=   1.0s\n",
						"[CV] END .................learning_rate=1.0, n_estimators=50; total time=   0.9s\n",
						"[CV] END .................learning_rate=1.0, n_estimators=50; total time=   1.0s\n",
						"[CV] END .................learning_rate=1.0, n_estimators=50; total time=   1.0s\n",
						"[CV] END .................learning_rate=1.0, n_estimators=50; total time=   0.9s\n",
						"[CV] END .................learning_rate=1.0, n_estimators=50; total time=   0.9s\n",
						"[CV] END .................learning_rate=1.0, n_estimators=50; total time=   0.8s\n",
						"----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
					]
				}
			],
			"source": [
				"from sklearn.metrics import classification_report\n",
				"from sklearn.model_selection import RandomizedSearchCV\n",
				"from sklearn.ensemble import AdaBoostClassifier\n",
				"\n",
				"estimators_and_param_grids = {\n",
				"    \"decision_tree\": (\n",
				"        DecisionTreeClassifier(random_state=42),\n",
				"        {\"max_depth\": [25, 50, 100]},\n",
				"    ),\n",
				"    \"ada_boost\": (\n",
				"        AdaBoostClassifier(algorithm=\"SAMME\", random_state=42),\n",
				"        {\n",
				"            \"n_estimators\": [10, 50],\n",
				"            \"learning_rate\": [0.1, 1.0],\n",
				"        },\n",
				"    ),\n",
				"    # \"xgb\": (\n",
				"    #     xgb.XGBClassifier(scale_pos_weight=1),\n",
				"    #     {\n",
				"    #         \"n_estimators\": [10, 50],\n",
				"    #         \"learning_rate\": [0.1, 1.0],\n",
				"    #         \"min_child_weight\": [1, 5],\n",
				"    #         \"gamma\": [0.5, 1, 1.5],\n",
				"    #         \"subsample\": [0.6, 0.8, 1.0],\n",
				"    #         \"colsample_bytree\": [0.6, 0.8, 1.0],\n",
				"    #         \"max_depth\": [3, 4, 5],\n",
				"    #     },\n",
				"    # ),\n",
				"}\n",
				"\n",
				"\n",
				"best_estimators = dict()\n",
				"best_estimators_and_best_param_grids = dict()\n",
				"\n",
				"cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=42)\n",
				"\n",
				"for estimator_name, estimator_and_param_grid in estimators_and_param_grids.items():\n",
				"    (estimator, param_grid) = estimator_and_param_grid\n",
				"\n",
				"    # search = GridSearchCV(\n",
				"    #     estimator=estimator, param_grid=param_grid, scoring=\"f1\", cv=cv, verbose=2\n",
				"    # )\n",
				"    print(estimator_name)\n",
				"    print(\"---\" * 50)\n",
				"\n",
				"    search = RandomizedSearchCV(\n",
				"        estimator=estimator,\n",
				"        param_distributions=param_grid,\n",
				"        cv=cv,\n",
				"        n_iter=100,\n",
				"        scoring=\"f1_weighted\",\n",
				"        verbose=2,\n",
				"        n_jobs=-1,\n",
				"    )\n",
				"\n",
				"    search.fit(X_train_final[prediction_columns], y_train_encoded)\n",
				"\n",
				"    best_estimator = search.best_estimator_\n",
				"    # best_estimators[estimator_name] = best_estimator\n",
				"    best_param_grid = search.best_params_\n",
				"\n",
				"    best_estimators_and_best_param_grids[estimator_name] = (\n",
				"        best_estimator,\n",
				"        best_param_grid,\n",
				"    )\n",
				"\n",
				"    best_estimators[estimator_name] = best_estimator\n",
				"    \n",
				"    # print(estimator_name)\n",
				"    # pprint(search.best_params_)\n",
				"\n",
				"    # # Evaluate the model on the test data\n",
				"    # accuracy = best_estimator.score(X_val, y_val)\n",
				"\n",
				"    # y_pred = best_estimator.predict(X_val)\n",
				"\n",
				"    # print(\"Accuracy:\", accuracy)\n",
				"\n",
				"    # classification_report = classification_report(y_val, y_pred)\n",
				"    # report_dict = classification_report(y_val, y_pred, output_dict=True)\n",
				"\n",
				"    # print(classification_report)\n",
				"\n",
				"    print(\"-----\" * 50)\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 23,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Classification Report for decision_tree\n",
						"================================================================================\n",
						"              precision    recall  f1-score   support\n",
						"\n",
						"     certain       0.80      0.85      0.82       125\n",
						"      likely       0.89      0.87      0.88      1112\n",
						"    possible       0.84      0.86      0.85       740\n",
						"    unlikely       1.00      1.00      1.00       523\n",
						"\n",
						"    accuracy                           0.89      2500\n",
						"   macro avg       0.88      0.89      0.89      2500\n",
						"weighted avg       0.89      0.89      0.89      2500\n",
						"\n",
						"================================================================================ \n",
						"\n",
						"Classification Report for ada_boost\n",
						"================================================================================\n",
						"              precision    recall  f1-score   support\n",
						"\n",
						"     certain       0.73      0.82      0.77       125\n",
						"      likely       0.92      0.77      0.84      1112\n",
						"    possible       0.80      0.81      0.81       740\n",
						"    unlikely       0.76      1.00      0.86       523\n",
						"\n",
						"    accuracy                           0.83      2500\n",
						"   macro avg       0.80      0.85      0.82      2500\n",
						"weighted avg       0.84      0.83      0.83      2500\n",
						"\n",
						"================================================================================ \n",
						"\n"
					]
				}
			],
			"source": [
				"for estimator_name, estimator in best_estimators.items():\n",
				"    print(f\"Classification Report for {estimator_name}\")\n",
				"    print(\"=\" * 80)\n",
				"\n",
				"    # Make predictions on the test set\n",
				"    y_pred = estimator.predict(X_test_final[prediction_columns])\n",
				"\n",
				"    # print(f\"{y_test_encoded=}\")\n",
				"    # print(f\"{y_pred=}\")\n",
				"    # Print classification report\n",
				"    label_classes = ordinal_encoder.categories_[0]\n",
				"    report = classification_report(\n",
				"        y_test_encoded, y_pred, target_names = label_classes\n",
				"    )\n",
				"    print(report)\n",
				"\n",
				"    print(\"=\" * 80, \"\\n\")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 24,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"{'0.0': {'f1-score': 0.8051948051948052,\n",
						"         'precision': 0.7848101265822784,\n",
						"         'recall': 0.8266666666666667,\n",
						"         'support': 75.0},\n",
						" '1.0': {'f1-score': 0.8771665410700829,\n",
						"         'precision': 0.8818181818181818,\n",
						"         'recall': 0.8725637181409296,\n",
						"         'support': 667.0},\n",
						" '2.0': {'f1-score': 0.8484848484848485,\n",
						"         'precision': 0.8456375838926175,\n",
						"         'recall': 0.8513513513513513,\n",
						"         'support': 444.0},\n",
						" '3.0': {'f1-score': 1.0, 'precision': 1.0, 'recall': 1.0, 'support': 314.0},\n",
						" 'accuracy': 0.8906666666666667,\n",
						" 'macro avg': {'f1-score': 0.8827115486874342,\n",
						"               'precision': 0.8780664730732695,\n",
						"               'recall': 0.8876454340397368,\n",
						"               'support': 1500.0},\n",
						" 'weighted avg': {'f1-score': 0.8907913106737524,\n",
						"                  'precision': 0.8909977160098136,\n",
						"                  'recall': 0.8906666666666667,\n",
						"                  'support': 1500.0}}\n"
					]
				}
			],
			"source": [
				"(best_estimator, _) = best_estimators_and_best_param_grids[\"decision_tree\"]\n",
				"\n",
				"accuracy = best_estimator.score(X_val_final[prediction_columns], y_val_encoded)\n",
				"\n",
				"y_pred = best_estimator.predict(X_val_final[prediction_columns])\n",
				"\n",
				"pprint(classification_report(y_val_encoded, y_pred, output_dict=True))\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 25,
			"metadata": {},
			"outputs": [
				{
					"name": "stderr",
					"output_type": "stream",
					"text": [
						"Registered model 'final_ml_model' already exists. Creating a new version of this model...\n",
						"2025/05/20 02:38:40 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: final_ml_model, version 13\n",
						"Created version '13' of model 'final_ml_model'.\n"
					]
				},
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"🏃 View run decision_tree at: http://127.0.0.1:5001/#/experiments/1/runs/7febb2273ac548d0976aa3ba8afd315b\n",
						"🧪 View experiment at: http://127.0.0.1:5001/#/experiments/1\n"
					]
				},
				{
					"name": "stderr",
					"output_type": "stream",
					"text": [
						"Registered model 'final_ml_model' already exists. Creating a new version of this model...\n",
						"2025/05/20 02:38:46 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: final_ml_model, version 14\n",
						"Created version '14' of model 'final_ml_model'.\n"
					]
				},
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"🏃 View run ada_boost at: http://127.0.0.1:5001/#/experiments/1/runs/b1d6c07e6cb1427fa552ffe52d938a58\n",
						"🧪 View experiment at: http://127.0.0.1:5001/#/experiments/1\n"
					]
				}
			],
			"source": [
				"from mlflow.models import infer_signature\n",
				"import mlflow\n",
				"import json\n",
				"\n",
				"for (\n",
				"    estimator_name,\n",
				"    best_estimator_and_best_param_grid,\n",
				") in best_estimators_and_best_param_grids.items():\n",
				"    (best_estimator, best_param_grid) = best_estimator_and_best_param_grid\n",
				"    # Evaluate the model on the test data\n",
				"    accuracy = best_estimator.score(X_val_final[prediction_columns], y_val_encoded)\n",
				"\n",
				"    y_pred = best_estimator.predict(X_val_final[prediction_columns])\n",
				"    label_classes = ordinal_encoder.categories_[0]\n",
				"\n",
				"    report = classification_report(y_val_encoded, y_pred, target_names=label_classes)\n",
				"    report_dict = classification_report(y_val_encoded, y_pred, output_dict=True)\n",
				"    class_report_dict = dict()\n",
				"\n",
				"    report_renaming_map = {\n",
				"        \"0.0\": \"certain\",\n",
				"        \"1.0\": \"likely\",\n",
				"        \"2.0\": \"possible\",\n",
				"        \"3.0\": \"unlikely\",\n",
				"    }\n",
				"\n",
				"    for key in report_dict.keys():\n",
				"        if key in report_renaming_map.keys():\n",
				"            class_report_dict[report_renaming_map[key]] = report_dict[key]\n",
				"\n",
				"    with mlflow.start_run(run_name=estimator_name):\n",
				"        # Parameters\n",
				"        mlflow.log_param(\"estimator_name\", estimator_name)\n",
				"        mlflow.log_params(param_grid)\n",
				"\n",
				"        # # Convert params to JSON and save as an artifact\n",
				"        # params_file_path = f\"{temp_artifacts_path}/params.json\"\n",
				"        # with open(params_file_path, \"w\") as f:\n",
				"        #     json.dump(param_grid, f, indent=4)\n",
				"\n",
				"        # Metrics\n",
				"        metrics_dict = {\n",
				"            \"accuracy\": report_dict[\"accuracy\"],\n",
				"            \"macro_avg_f1-score\": report_dict[\"macro avg\"][\"f1-score\"],\n",
				"            \"recall_class_certain\": class_report_dict[\"certain\"][\"recall\"],\n",
				"            \"recall_class_likely\": class_report_dict[\"likely\"][\"recall\"],\n",
				"            \"recall_class_possible\": class_report_dict[\"possible\"][\"recall\"],\n",
				"            \"recall_class_unlikely\": class_report_dict[\"unlikely\"][\"recall\"],\n",
				"        }\n",
				"        mlflow.log_metrics(metrics_dict)\n",
				"\n",
				"        # # Convert metrics to JSON and save as an artifact\n",
				"        # metrics_file_path = f\"{temp_artifacts_path}/metrics.json\"\n",
				"        # with open(metrics_file_path, \"w\") as f:\n",
				"        #     json.dump(metrics_dict, f, indent=4)\n",
				"\n",
				"        # Artifacts\n",
				"        ## Encoders\n",
				"        temp_artifacts_path = \"temp_artifacts\"\n",
				"\n",
				"        one_hot_encoder_path = f\"{temp_artifacts_path}/one_hot_encoder.pkl\"\n",
				"        ordinal_encoder_path = f\"{temp_artifacts_path}/ordinal_encoder.pkl\"\n",
				"        joblib.dump(one_hot_encoder, one_hot_encoder_path)\n",
				"        joblib.dump(ordinal_encoder, ordinal_encoder_path)\n",
				"\n",
				"        mlflow.log_artifact(one_hot_encoder_path, artifact_path=\"encoders\")\n",
				"        mlflow.log_artifact(ordinal_encoder_path, artifact_path=\"encoders\")\n",
				"\n",
				"        model_columns = {\n",
				"            \"categorical_columns\": categorical_columns,\n",
				"            \"numerical_columns\": numerical_columns,\n",
				"            \"date_columns\": date_columns,\n",
				"            \"boolean_columns\": boolean_columns,\n",
				"            \"prediction_columns\": prediction_columns,\n",
				"        }\n",
				"\n",
				"        with open(f\"{temp_artifacts_path}/model_columns.json\", \"w\") as f:\n",
				"            json.dump(model_columns, f, indent=4)\n",
				"\n",
				"        ## Scalers\n",
				"        scaler_path = f\"{temp_artifacts_path}/minmax_scaler.pkl\"\n",
				"        joblib.dump(scaler, scaler_path)\n",
				"        mlflow.log_artifact(scaler_path, artifact_path=\"scalers\")\n",
				"\n",
				"        ## Column Metadata\n",
				"        mlflow.log_artifact(\n",
				"            f\"{temp_artifacts_path}/model_columns.json\", artifact_path=\"metadata\"\n",
				"        )\n",
				"\n",
				"        # Model\n",
				"        signature = infer_signature(\n",
				"            X_train_final[prediction_columns],\n",
				"            best_estimator.predict(X_train_final[prediction_columns]),\n",
				"        )\n",
				"        # mlflow.sklearn.log_model(best_estimator, estimator_name, signature=signature)\n",
				"        # Log and register the model\n",
				"        model_info = mlflow.sklearn.log_model(\n",
				"            sk_model=best_estimator,\n",
				"            artifact_path=\"model\",\n",
				"            signature=signature,\n",
				"            registered_model_name=MLFLOW_MODEL_NAME,  # Register the model with a fixed name\n",
				"        )\n",
				"\n",
				"        # Set alias 'champion' to this model version\n",
				"        client = mlflow.MlflowClient()\n",
				"        latest_version = client.get_latest_versions(MLFLOW_MODEL_NAME, stages=[\"None\"])[\n",
				"            0\n",
				"        ].version  # Get the latest version\n",
				"        client.set_registered_model_alias(\n",
				"            MLFLOW_MODEL_NAME, MLFLOW_MODEL_ALIAS, latest_version\n",
				"        )  # Assign alias"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 26,
			"metadata": {},
			"outputs": [],
			"source": [
				"# import os\n",
				"\n",
				"# import joblib\n",
				"# from dotenv import load_dotenv\n",
				"\n",
				"# load_dotenv()\n",
				"\n",
				"# ML_MODEL_PATH = os.getenv(\"ML_MODEL_PATH\")\n",
				"# joblib.dump(best_estimators_and_best_param_grids[\"decision_tree\"][0], ML_MODEL_PATH)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 27,
			"metadata": {},
			"outputs": [],
			"source": [
				"# run_id = input(\"Run ID: \").strip()\n",
				"# model_name = input(\"Model Name: \").strip()\n",
				"# model_uri = f\"runs:/{run_id}/{model_name}\"\n",
				"\n",
				"# result = mlflow.register_model(model_uri, model_name)"
			]
		}
	],
	"metadata": {
		"kernelspec": {
			"display_name": "general",
			"language": "python",
			"name": "python3"
		},
		"language_info": {
			"codemirror_mode": {
				"name": "ipython",
				"version": 3
			},
			"file_extension": ".py",
			"mimetype": "text/x-python",
			"name": "python",
			"nbconvert_exporter": "python",
			"pygments_lexer": "ipython3",
			"version": "3.10.14"
		}
	},
	"nbformat": 4,
	"nbformat_minor": 2
}
